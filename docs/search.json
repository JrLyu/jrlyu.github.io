[
  {
    "objectID": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html",
    "href": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html",
    "title": "1 Linear Classification",
    "section": "",
    "text": "feature vector: \\(\\va x=\\mqty[x_1&x_2&\\cdots&x_d]^\\top\\in\\R^d\\). \\(\\R^d\\) is called the feature space.\nlabel: \\(y\\in\\qty{-1,+1}\\), binary.\ntraining set of labeled examples: \\[D=\\qty{\\va x^{(i)},y^{(i)}}_{i=1}^N\\]\nclassifier: \\[h:\\R^d\\to\\qty{-1,+1}.\\]\n\nGola: select the best \\(h\\) from a set of possible classifiers \\(\\mathcal{H}\\) that would (the ability to generalization).\nWe will solve this goal by a learning algorithm, typically an optimization problem \\(\\wrt D\\)."
  },
  {
    "objectID": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#machine-learning-terminology",
    "href": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#machine-learning-terminology",
    "title": "1 Linear Classification",
    "section": "",
    "text": "feature vector: \\(\\va x=\\mqty[x_1&x_2&\\cdots&x_d]^\\top\\in\\R^d\\). \\(\\R^d\\) is called the feature space.\nlabel: \\(y\\in\\qty{-1,+1}\\), binary.\ntraining set of labeled examples: \\[D=\\qty{\\va x^{(i)},y^{(i)}}_{i=1}^N\\]\nclassifier: \\[h:\\R^d\\to\\qty{-1,+1}.\\]\n\nGola: select the best \\(h\\) from a set of possible classifiers \\(\\mathcal{H}\\) that would (the ability to generalization).\nWe will solve this goal by a learning algorithm, typically an optimization problem \\(\\wrt D\\)."
  },
  {
    "objectID": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#linear-classifer-through-origin",
    "href": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#linear-classifer-through-origin",
    "title": "1 Linear Classification",
    "section": "Linear Classifer (Through Origin)",
    "text": "Linear Classifer (Through Origin)\n\n\n\n\n\n\n\nDefinition 1 (Thresholded Linear Mapping from Feature Vectors to Labels) \\[\nh(\\va x; \\va\\theta)=\\begin{cases}+1\\quad\\text{if }\\va\\theta\\cdot\\va x&gt;0,\\\\-1\\quad\\text{if }\\va\\theta\\cdot\\va x&lt;0\\end{cases},\n\\] where \\(\\va\\theta\\in\\R^d\\) is the parameter vector, and \\(\\va\\theta=\\mqty[\\theta_1,\\theta_2,\\dots,\\theta_d]^\\top\\).\nOne can also write it using the \\(\\operatorname{sign}\\) function: \\[\nh(\\va x;\\va\\theta)=\\operatorname{sign}(\\va\\theta\\cdot\\va x)=\\begin{cases}\n+1\\quad\\text{if }\\va\\theta\\cdot\\va x&gt;0,\\\\\n0\\quad\\text{if }\\va\\theta\\cdot\\va x=0,\\\\\n-1\\quad\\text{if }\\va\\theta\\cdot\\va x&lt;0.\n\\end{cases}.\n\\]\n\n\n\n\n\nRecall: dot product: \\[\n\\va\\theta\\cdot\\va x=\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_dx_d=\\sum_{j=1}^d\\theta_jx_j,\n\\] a linear combination of input features.\nIn \\(h(\\va x;\\va\\theta)\\), different \\(\\va\\theta\\)’s produce (potentially) different labelings for the same \\(\\va x\\).\n\n\nGraphical Representation\n\n\n\n\n\n\nFigure 1: Decision Boundary\n\n\n\n\nHowever, what happens on this \\(90^\\circ\\) line? We call this line the decision boundary, which separates the two classes. Recall: \\[\n\\va\\theta\\cdot\\va x=\\norm{\\va\\theta}\\cdot\\norm{\\va x}\\cdot\\cos 90^\\circ=0.\n\\]\nView the decision boundary as a hyperplane in \\(\\R^d\\).\n\nDoes the length of \\(\\va\\theta\\) matter? No.\nDoes the direction of \\(\\va\\theta\\) matter? Yes."
  },
  {
    "objectID": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#linear-classifier-with-offset",
    "href": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#linear-classifier-with-offset",
    "title": "1 Linear Classification",
    "section": "Linear Classifier with Offset",
    "text": "Linear Classifier with Offset\n\n\n\n\n\n\n\nDefinition 2 (Linear Classifier with Offset) \\[\nh(\\va x;\\va\\theta,b)=\\operatorname{sign}(\\va\\theta\\cdot\\va x+b),\n\\] where \\(\\va x\\in\\R^d\\), \\(\\va\\theta\\in\\R^d\\), and \\(b\\in\\R\\). \\(b\\) is called the offset or intercept.\n\n\n\n\n\nGraphical Representation\n\n\n\n\n\n\nFigure 2: Linear Classifier with Offset\n\n\n\n\nNote that the signed distance from \\(\\va\\theta\\cdot\\va x=0\\) to the hyperplane \\(\\va\\theta\\cdot\\va x+b=0\\) is given by: \\[\n\\dfrac{-b}{\\norm{\\va\\theta}}.\n\\]\n\n\nProof. \n\nPick a point on old decision boundary \\(\\va x^{(1)}\\) satisfies \\[\\va\\theta\\cdot\\va x^{(1)}=0.\\]\nPick a point on the new decision boundary \\(\\va x^{(2)}\\) satisfies \\[\\va\\theta\\cdot\\va x^{(2)}+b=0\\implies\\va\\theta\\va x^{(2)}=-b.\\]\nLet \\(\\va v=\\va x^{(2)}-\\va x^{(1)}.\\)\nNow, project \\(\\va v\\) into direction of \\(\\va\\theta\\): \\[\n\\operatorname{proj}_{\\va\\theta}\\va v=\\qty(\\va v\\cdot\\dfrac{\\va\\theta}{\\norm{\\va\\theta}})\\dfrac{\\va\\theta}{\\norm{\\va\\theta}}.\n\\] Note: \\(\\dfrac{\\va\\theta}{\\norm{\\va\\theta}}\\) is the unit vector in the direction of \\(\\va\\theta\\).\nTherefore, the signed sitance is given by: \\[\n\\va v\\cdot\\dfrac{\\va\\theta}{\\norm{\\va\\theta}}=\\dfrac{\\qty(\\va x^{(2)}-\\va x^{(1)})\\cdot\\va\\theta}{\\norm{\\va\\theta}}=\\dfrac{\\va x^{(2)}\\cdot\\va\\theta-\\va x^{(1)}\\cdot\\va\\theta}{\\norm{\\va\\theta}}=\\dfrac{-b}{\\norm{\\va\\theta}}.\n\\]"
  },
  {
    "objectID": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#training-error",
    "href": "notes/cs334/01-Linear-Classification/01-Linear-Classification.html#training-error",
    "title": "1 Linear Classification",
    "section": "Training Error",
    "text": "Training Error\n\nIntuition: we want \\(\\va\\theta\\) that works well on training data \\(D\\).\n\n\n\n\n\n\n\n\nRemark 1. We’ve restricted the class of possible clasassifiers to linear classifiers, reducing the chance of overfitting.\n\n\n\n\n\n\n\n\n\n\n\nDefinition 3 (Training Error and Learning Algorithms) The training error (\\(\\epsilon\\)) is the fraction of training examples for which the classifier produces wrong labels: \\[\n\\epsilon_N(\\va \\theta)=\\dfrac{1}{N}\\sum_{i=1}^N\\1\\qty{y^{(i)}\\neq h\\qty(\\va x^{(i)};\\va\\theta)},\n\\] where \\(\\1\\{\\cdot\\}\\) returns \\(1\\) if true and \\(0\\) if false.\nAn equivalent form is: \\[\n\\epsilon_N(\\va \\theta)=\\dfrac{1}{N}\\sum_{i=1}^N\\1\\{{\\color{orange}{\\underbrace{y^{(i)}\\qty(\\va\\theta\\cdot\\va x^{(i)})}_{\\substack{y^(i)\\text{ and }\\va\\theta\\cdot\\va x^{(i)}\\\\\\text{ have opposite signs}}}}}{\\color{green}{\\overbrace{\\leq 0}^{\\substack{\\text{points on the decision boundary}\\\\\\text{are considered misclassified}}}}}\\}\n\\]\n\n\n\n\n\nGoal: Find \\(\\displaystyle\\va\\theta^*=\\argmin_{\\va\\theta}\\epsilon_N\\qty(\\va\\theta)\\).\nHow:\n\nIn general, this is not easy to solve (it’s NP-hard).\nFor now, we will consider a special case: linearly separable data.\n\n\n\n\n\n\n\n\n\nDefinition 4 (Linear Separable) Training examples \\(D=\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N\\) are linearly separable through the origin if \\(\\exists\\ \\va\\theta\\) such that \\[\ny^{(i)}\\qty(\\va\\theta\\cdot\\va x^{(i)})&gt;0\\quad\\forall\\ i=1,\\dots, N\n\\]\n\n\n\n\n\n\n\n\n\n\n\nRemark 2. This assumption of linear separability is NOT testable.\n\n\n\n\n\nPerceptron Algorithm\n\nThe perceptron algorithm is a mistaken-driven algorithm. It starts with \\(\\va\\theta=\\va 0\\) (the zero vector), and then tries to update \\(\\va\\theta\\) to correct any mistakes.\n\n\n\n\\begin{algorithm} \\caption{Perceptron (Through Origin)} \\begin{algorithmic} \\Procedure{Perceptron}{$D=\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N$} \\State $k=0$; $\\va\\theta^{(0)}=\\va 0$ \\While{not all points are correctly classified} \\For{$i=1,\\dots, N$} \\State \\Comment{$\\color{green}\\text{if mistake}$} \\If{$y^{(i)}\\qty(\\va\\theta^{(k)}\\cdot\\va x^{(i)})\\leq 0$} \\State $\\va\\theta^{(k+1)}=\\va\\theta^{(k)}+y^{(i)}\\va x^{(i)}$ \\State $k++$ \\EndIf \\EndFor \\EndWhile \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\n\n\nTheorem 1 (Existence of Perceptron Solution) The perceptron algorithm (Algorithm 1) converges after a finite number of mistkaes if the training examples are linearly separable through the origin.\n\n\n\n\n\nHowever, :\n\nSolution is not unique\nMay need to loop through the dataset more than once, or not use some points at all.\n\n\n\n\n\\begin{algorithm} \\caption{Perceptron (With Offset)} \\begin{algorithmic} \\Procedure{Perceptron}{$D=\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N$} \\State $k=0$; $\\va\\theta^{(0)}=\\va 0$; $b^{(0)}=0$ \\While{not all points are correctly classified} \\For{$i=1,\\dots, N$} \\State \\Comment{$\\color{green}\\text{if mistake}$} \\If{$y^{(i)}\\qty(\\va\\theta^{(k)}\\cdot\\va x^{(i)}+b^{(k)})\\leq 0$} \\State $\\va\\theta^{(k+1)}=\\va\\theta^{(k)}+y^{(i)}\\va x^{(i)}$ \\State $b^{(k+1)}=b^{(k)}+y^{(i)}$ \\State $k++$ \\EndIf \\EndFor \\EndWhile \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\n\nProof. Produce augmented vecotrs: \\[\\va x'=\\mqty[1, \\va x]^\\top\\quad\\text{and}\\quad\\va\\theta'=\\mqty[b,\\va\\theta]^\\top.\\] Then, we have implicit offset formula: \\[\\va\\theta'\\cdot\\va x'=b+\\va\\theta\\cdot\\va x.\\] Apply Algorithm 1 to \\(\\va x'\\) and \\(\\va\\theta'\\): \\[\n\\begin{aligned}\n\\va\\theta'^{(k+1)}&=\\va\\theta'^{(k)}+y^{(i)}\\va x'^{(i)}\\\\\n\\mqty[b^{(k+1)},\\va\\theta^{(k+1)}]&=\\mqty[b^{(k)},\\va\\theta^{(k)}]+y^{(i)}\\mqty[1,\\va x^{(i)}]\\\\\n\\implies \\va\\theta^{(k+1)}&=\\va\\theta^{(k)}+y^{(i)}\\va x^{(i)}\\\\\nb^{(k+1)}&=b^{(k)}+y^{(i)}.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/cs377.html",
    "href": "notes/cs377.html",
    "title": "CS 377 Database Systems",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n1 The Relational Model\n\n\n\n\n\n\nDatabase\n\n\nRelational Model\n\n\n\nThis lecture discusses the relational model, which is the foundation of modern database systems.\n\n\n\n\n\nAug 28, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n2 Relational Algebra\n\n\n\n\n\n\nDatabase\n\n\nRelational Model\n\n\nRelational Algebra\n\n\n\nThis lecture discusses the relational algebra, which is the foundation of modern database systems. Topics include select, project, and join operators.\n\n\n\n\n\nSep 8, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n3 SQL Introduction\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\n\nThis note introduces SQL, the Structured Query Language, which is used to interact with databases. We will cover basic queries, the use of *, AS, conditions, and ORDER BY in SQL.\n\n\n\n\n\nSep 10, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n4 SQL Aggregation\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nAggregation\n\n\n\nThis lecture discusses SQL Aggregation, including computing on a column, GROUP BY, and HAVING clauses.\n\n\n\n\n\nSep 14, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n5 SQL Set Operations\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nSet Operations\n\n\n\nThis lecture discusses SQL set operations, including UNION, INTERSECT, and EXCEPT. It also covers the difference between bag and set semantics in SQL.\n\n\n\n\n\nSep 18, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n6 SQL Join\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nJoin\n\n\n\nThis lecture discusses the different types of joins in SQL, including inner, outer, and cross joins. It also covers the dangers of using NATURAL JOIN and the best practices for using joins in SQL.\n\n\n\n\n\nSep 28, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n7 SQL NULL\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nJoin\n\n\nNULL\n\n\n\nThis lecture discusses the concept of NULL values in SQL, including how to represent missing information and inapplicable attributes. It also covers how to check for NULL values and the impact of NULL values on arithmetic expressions, comparison operators, and aggregation.\n\n\n\n\n\nOct 8, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n8 SQL Subqueries\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nSubqueries\n\n\n\nThis lecture discusses subqueries in SQL, including subqueries in a FROM clause, subqueries in a WHERE clause, and the scope of subqueries. It also covers special cases of subqueries, such as when the subquery returns NULL or multiple values.\n\n\n\n\n\nOct 18, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n9 SQL DDL\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nDDL\n\n\n\nThis lecture discusses Database Modification Language in SQL, including Insert, Delete, Update, and Create operations. It also covers SQL Schemas, Types, Keys, and Foreign Keys.\n\n\n\n\n\nOct 28, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n10 JDBC\n\n\n\n\n\n\nCoding\n\n\nSQL\n\n\nDatabase\n\n\nJava\n\n\nJDBC\n\n\n\nThis lecture discusses how to embed SQL in Java using JDBC. It covers the JDBC API, SQL Injection, and Prepared Statements.\n\n\n\n\n\nOct 30, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n11 ER Design\n\n\n\n\n\n\nDatabase\n\n\nDatabase Design\n\n\nER Design\n\n\n\nThis lecture discusses Entity-Relationship (ER) design, which is a technique for designing databases. It covers the ER model, ER diagrams, and the process of converting ER diagrams to relational schemas.\n\n\n\n\n\nNov 10, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n12 Database Design Theory: Normalization\n\n\n\n\n\n\nDatabase\n\n\nDatabase Design\n\n\nDB Design Theory\n\n\nBCNF\n\n\nNormalization\n\n\nFunctional Dependencies\n\n\nClosure Test\n\n\nFD Projection\n\n\n\nThis lecture discusses the concept of normalization in database design theory. The lecture covers functional dependencies, closure test, and FD projection. It finally introduces the concept of BCNF.\n\n\n\n\n\nNov 18, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n13 NOSQL: Not Only SQL\n\n\n\n\n\n\nDatabase\n\n\nNOSQL\n\n\n\nThis lecture introduces the concept of NOSQL databases and their applications.\n\n\n\n\n\nDec 4, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes/nonlinearOpt.html",
    "href": "notes/nonlinearOpt.html",
    "title": "Nonlinear Optimization",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes/Calc3.html",
    "href": "notes/Calc3.html",
    "title": "Multivariable Calculus/Calculus 3",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/NumericalAnalysis2.html",
    "href": "notes/NumericalAnalysis2.html",
    "title": "PhD-Level Numerical Analysis I (Numerical Linear Algebra)",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes/ODE.html",
    "href": "notes/ODE.html",
    "title": "Ordinary Differential Equations",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs377/05-sql-set-operations/05-SQL-Set-Operations.html",
    "href": "notes/cs377/05-sql-set-operations/05-SQL-Set-Operations.html",
    "title": "5 SQL Set Operations",
    "section": "",
    "text": "A table can have duplicate tuples, unless this would violate an integrity constraint.\nAnd SELECT-FROM-WHERE (SFW) statements leave duplicates in, unless you say not to!\nWhy?\n\nGetting rid of duplicates is expensive!\nWe may want the duplicates because they tell us how many times something occurred.\n\n\n\n\n\nSQL treats tables as “bags” (or “multisets”) rather than sets.\nBags are just like sets, but duplicates are allowed.\n\n\n\n\n\n\n\nTip 1: Example: Bag Semantics\n\n\n\n\n\n\n\\(\\{6, 2, 7, 1, 9\\}\\) is a set and a bag\n\\(\\{6, 2, 7, 1, 9, 1\\}\\) is not a set but a bag\n\n\n\n\n\nLet sets, order doesn’t matter: \\(\\{6, 2, 7, 1, 9, 1\\}=\\{1, 1, 2, 6, 7, 9\\}\\)\nOperations \\(\\cap\\), \\(\\cup\\), and \\(-\\) with bags:\n\nFor \\(\\cap\\), \\(\\cup\\), and \\(-\\) the number of occurrences of a tuple in the result requires some thought.\nSuppose tuple \\(t\\) occurs:\n\n\\(m\\) times in relation \\(R\\), and\n\\(n\\) times in relation \\(S\\)\n\n\n\n\n\n\nOperation\nNumber of Occurrences of \\(t\\) in tuples\n\n\n\n\n\\(R\\cap S\\)\n\\(\\min(m,n)\\)\n\n\n\\(R\\cup S\\)\n\\(m+n\\)\n\n\n\\(R-S\\)\n\\(\\max(m-n,0)\\)\n\n\n\n\n\\(\\cap\\), \\(\\cup\\), and \\(-\\) in SQL:\n\n(&lt;subquery&gt;) UNION (&lt;subquery&gt;)\n(&lt;subquery&gt;) INTERSECT (&lt;subquery&gt;)\n(&lt;subquery&gt;) EXCEPT (&lt;subquery&gt;)\n\nThe parentheses () are mandatory\nThe operands must be queries; you can’t simply use a relation name.\n\n\n\n\n\n\n\nTip 2: Example: Set Operations in SQL\n\n\n\n\n\n(SELECT sid\n FROM Took\n WHERE grade &gt; 95)\n    UNION\n(SELECT sid\n FROM Took\n WHERE grade &lt; 50);\n\n\n\n\nBag vs. Set Semantics: which is used and when\n\nA SELECT-FROM-WHERE statement uses bag semantics by default.\n\nDuplicates are kept in the result\n\nThe set (INTERSECT/UNION/EXCEPT) operations use set semantics by default\n\nDuplicates are eliminated from the result\n\n\nMotivation: Efficiency\n\nWhen doing projection, it is easier not to eliminate duplicate\n\nJust work one tuple at a time\n\nFor intersection or difference, it is most efficient to sort the relations first.\n\nAt that point you may was well eliminate the duplicates anyway\n\n\nHowever, we can control which semantic is used.\n\nWe can force the result of a SFW query to be a set by using SELECT DISTINCT\nWe can force the result of a set operation to be a bag by using ALL.\n\n\n\n\n\n\n\n\nTip 3: Example: Force to Use Set Operations in SQL\n\n\n\n\n\n(SELECT sid\n FROM Took\n WHERE grade &gt; 95)\n    UNION ALL\n(SELECT sid\n FROM Took\n WHERE grade &lt; 50);\n\n\n\n\n\n\n\n\n\nTip 4: Example: Comparison of Set and Bag Semantics\n\n\n\n\n\n\nA single occurrence of a value for x in B wipes out all occurrences of it from A:\n\n(SELECT x FROM A) EXCEPT (SELECT x FROM B)\n\nWith EXCEPT ALL, we match up the value one by one:\n\n(SELECT x FROM A) EXCEPT (SELECT x FROM B)"
  },
  {
    "objectID": "notes/cs377/05-sql-set-operations/05-SQL-Set-Operations.html#duplicates-in-sql",
    "href": "notes/cs377/05-sql-set-operations/05-SQL-Set-Operations.html#duplicates-in-sql",
    "title": "5 SQL Set Operations",
    "section": "",
    "text": "A table can have duplicate tuples, unless this would violate an integrity constraint.\nAnd SELECT-FROM-WHERE (SFW) statements leave duplicates in, unless you say not to!\nWhy?\n\nGetting rid of duplicates is expensive!\nWe may want the duplicates because they tell us how many times something occurred.\n\n\n\n\n\nSQL treats tables as “bags” (or “multisets”) rather than sets.\nBags are just like sets, but duplicates are allowed.\n\n\n\n\n\n\n\nTip 1: Example: Bag Semantics\n\n\n\n\n\n\n\\(\\{6, 2, 7, 1, 9\\}\\) is a set and a bag\n\\(\\{6, 2, 7, 1, 9, 1\\}\\) is not a set but a bag\n\n\n\n\n\nLet sets, order doesn’t matter: \\(\\{6, 2, 7, 1, 9, 1\\}=\\{1, 1, 2, 6, 7, 9\\}\\)\nOperations \\(\\cap\\), \\(\\cup\\), and \\(-\\) with bags:\n\nFor \\(\\cap\\), \\(\\cup\\), and \\(-\\) the number of occurrences of a tuple in the result requires some thought.\nSuppose tuple \\(t\\) occurs:\n\n\\(m\\) times in relation \\(R\\), and\n\\(n\\) times in relation \\(S\\)\n\n\n\n\n\n\nOperation\nNumber of Occurrences of \\(t\\) in tuples\n\n\n\n\n\\(R\\cap S\\)\n\\(\\min(m,n)\\)\n\n\n\\(R\\cup S\\)\n\\(m+n\\)\n\n\n\\(R-S\\)\n\\(\\max(m-n,0)\\)\n\n\n\n\n\\(\\cap\\), \\(\\cup\\), and \\(-\\) in SQL:\n\n(&lt;subquery&gt;) UNION (&lt;subquery&gt;)\n(&lt;subquery&gt;) INTERSECT (&lt;subquery&gt;)\n(&lt;subquery&gt;) EXCEPT (&lt;subquery&gt;)\n\nThe parentheses () are mandatory\nThe operands must be queries; you can’t simply use a relation name.\n\n\n\n\n\n\n\nTip 2: Example: Set Operations in SQL\n\n\n\n\n\n(SELECT sid\n FROM Took\n WHERE grade &gt; 95)\n    UNION\n(SELECT sid\n FROM Took\n WHERE grade &lt; 50);\n\n\n\n\nBag vs. Set Semantics: which is used and when\n\nA SELECT-FROM-WHERE statement uses bag semantics by default.\n\nDuplicates are kept in the result\n\nThe set (INTERSECT/UNION/EXCEPT) operations use set semantics by default\n\nDuplicates are eliminated from the result\n\n\nMotivation: Efficiency\n\nWhen doing projection, it is easier not to eliminate duplicate\n\nJust work one tuple at a time\n\nFor intersection or difference, it is most efficient to sort the relations first.\n\nAt that point you may was well eliminate the duplicates anyway\n\n\nHowever, we can control which semantic is used.\n\nWe can force the result of a SFW query to be a set by using SELECT DISTINCT\nWe can force the result of a set operation to be a bag by using ALL.\n\n\n\n\n\n\n\n\nTip 3: Example: Force to Use Set Operations in SQL\n\n\n\n\n\n(SELECT sid\n FROM Took\n WHERE grade &gt; 95)\n    UNION ALL\n(SELECT sid\n FROM Took\n WHERE grade &lt; 50);\n\n\n\n\n\n\n\n\n\nTip 4: Example: Comparison of Set and Bag Semantics\n\n\n\n\n\n\nA single occurrence of a value for x in B wipes out all occurrences of it from A:\n\n(SELECT x FROM A) EXCEPT (SELECT x FROM B)\n\nWith EXCEPT ALL, we match up the value one by one:\n\n(SELECT x FROM A) EXCEPT (SELECT x FROM B)"
  },
  {
    "objectID": "notes/cs377/05-sql-set-operations/05-SQL-Set-Operations.html#views",
    "href": "notes/cs377/05-sql-set-operations/05-SQL-Set-Operations.html#views",
    "title": "5 SQL Set Operations",
    "section": "Views",
    "text": "Views\n\nThe idea\n\nA view is a relation defined in terms of stored tables (called base tables) and possibly also other views.\nAccess a view like any base table.\nTwo kinds of view:\n\nVirtual: no tuples are stored; view is just a query for constructing the relation when needed.\nMaterialized: actually constructed and stored. Expensive to maintain.\n\nViews are particularly important when you want to give different access rights (i.e. permissions) to different users viewing data in your tables!\n\n\n\n\n\n\n\nTip 5: Example: Application of Views\n\n\n\n\n\nCanvas student page vs. instructor page\n\n\n\n\n\n\n\n\n\nTip 6: Example: Creating a View\n\n\n\n\n\n\nA view for students who earned an 80 or higher in a CSC course:\n\nCREATE VIEW topresults AS\n    SELECT firstname, surname, cnum\n    FROM Student, Took, Offering\n    WHERE\n        Student.sid = Took.sid AND\n        Took.oid = Offering.oid AND\n        grade &gt;= 80 AND dept = 'CSC';\n\n\n\n\n\nUses of Views\n\nBreak down a large query\nProvide another way of looking at the same data, e.g. for one category of user\nWrap commonly used complex queries"
  },
  {
    "objectID": "notes/cs377/07-sql-null/07-SQL-NULL.html",
    "href": "notes/cs377/07-sql-null/07-SQL-NULL.html",
    "title": "7 SQL NULL",
    "section": "",
    "text": "Missing Information:\n\nMissing value.\n\nE.g., we know a student has some email address, but we don’t know what it is.\n\nInapplicable attribute.\n\nE.g., the value of attribute spouse for a person who is single.\n\n\nRepresenting missing information:\n\nOne possibility: use a special value as a placeholder. E.g.,\n\nIf age unknown, use -1.\nIf StNum unknown, use 999999999.\n\nPros and cons?\n\nBetter solution: use a value not in any domain. We call this a null value.\nTuples in SQL relations can have NULL as a value for one or more components.\n\n\nCheck for NULL values\n\nYou can compare an attribute value to NULL with\n\nIS NULL\nIS NOT NULL\n\n\n\n\n\n\n\n\n\nTip 1: Example: Check for NULL values\n\n\n\n\n\nSELECT *\nFROM Course\nWHERE breadth IS NULL;\n\n\n\n\nNote: do not use WHERE breadth = NULL;\n\n\n\n\nAssume \\(x\\) is NULL\nArithmetic expression: Result is always NULL\n\n\n\n\n\n\n\nTip 2: Example: Arithmetic with NULL\n\n\n\n\n\n\\[x+\\texttt{grade}=\\texttt{NULL}\\] \\[x*0=\\texttt{NULL}\\] \\[x-x=\\texttt{NULL}\\]\n\n\n\n\nComparison operators (\\(&gt;\\), \\(&lt;\\), \\(=\\), \\(\\dots\\)): Result is UNKNOWN (neither TRUE nor FALSE)\n\n\n\n\n\n\n\nTip 3: Example: Comparison with NULL\n\n\n\n\n\n\\[x&lt;32 \\quad\\texttt{ --&gt; UNKNOWN}\\]\n\n\n\n\nThis UNKNOWN is a truth-value\nTruth-values in SQL are: TRUE, FALSE, UNKNOWN (a 3-value truth value system!)\n\nLogic with UNKNOWN: \\[\\begin{aligned}\n\\texttt{UNKNOWN} \\lor\\texttt{FALSE}&\\equiv\\texttt{UNKNOWN}\\\\\n\\texttt{UNKNOWN} \\lor\\texttt{TRUE}&\\equiv\\texttt{TRUE}\\\\\n\\texttt{UNKNOWN} \\land\\texttt{FALSE}&\\equiv\\texttt{FALSE}\\\\\n\\texttt{UNKNOWN} \\land\\texttt{TRUE}&\\equiv\\texttt{UNKNOWN}\\\\\n\\neg\\texttt{UNKNOWN}&\\equiv\\texttt{UNKONWN}\n\\end{aligned}\\]\nA tuple is in a query result \\(\\iff\\) the result of the WHERE clause is TRUE.\n\n\n\n\n\n\n“Aggregation ignores NULL.”\n\nNULL never contributes to a sum, average, or count, and can never be the minimum or maximum of a column (unless every value is NULL).\n\nIf ALL values are NULL in a column, then the result of the aggregation is NULL.\nException: COUNT of an empty set is 0. (think of COUNT(columnName) as a function that counts the non-null values in that column.)\n\n\n\n\n\n\n\nTip 4: Example: Aggregation with NULL\n\n\n\n\n\n\nR&S&T are defined as:\n\n R             |      S             |       T\n   x           |          x         |            x\n -----         |        -----       |          -----\n NULL          |        NULL        |\n 1             |                    |\n\nCOUNT()\n\nCOUNT(R.*)=2 and COUNT(R.x)=1\nCOUNT(S.*)=1 and COUNT(S.x)=0\nCOUNT(T.*)=0 and COUNT(T.x)=0\n\nOther aggregates:\n\nMIN(R.x)=1 and MAX(R.x)=1\nMIN(S.x)=NULL and MAX(S.x)=NULL\nMIN(T.x)=NULL and MAX(T.x)=NULL\n\n\n\n\n\n\n\n\n\nNULL is treated differently by the set operators UNION, EXCEPT, and INTERSECT than it is in search conditions.\nWhen comparing rows, set operators treat NULL values as equal to each other.\nIn contrast, when NULL is compared to NULL in a search condition the result is UNKNOWN (not true)."
  },
  {
    "objectID": "notes/cs377/07-sql-null/07-SQL-NULL.html#null-values-in-sql",
    "href": "notes/cs377/07-sql-null/07-SQL-NULL.html#null-values-in-sql",
    "title": "7 SQL NULL",
    "section": "",
    "text": "Missing Information:\n\nMissing value.\n\nE.g., we know a student has some email address, but we don’t know what it is.\n\nInapplicable attribute.\n\nE.g., the value of attribute spouse for a person who is single.\n\n\nRepresenting missing information:\n\nOne possibility: use a special value as a placeholder. E.g.,\n\nIf age unknown, use -1.\nIf StNum unknown, use 999999999.\n\nPros and cons?\n\nBetter solution: use a value not in any domain. We call this a null value.\nTuples in SQL relations can have NULL as a value for one or more components.\n\n\nCheck for NULL values\n\nYou can compare an attribute value to NULL with\n\nIS NULL\nIS NOT NULL\n\n\n\n\n\n\n\n\n\nTip 1: Example: Check for NULL values\n\n\n\n\n\nSELECT *\nFROM Course\nWHERE breadth IS NULL;\n\n\n\n\nNote: do not use WHERE breadth = NULL;\n\n\n\n\nAssume \\(x\\) is NULL\nArithmetic expression: Result is always NULL\n\n\n\n\n\n\n\nTip 2: Example: Arithmetic with NULL\n\n\n\n\n\n\\[x+\\texttt{grade}=\\texttt{NULL}\\] \\[x*0=\\texttt{NULL}\\] \\[x-x=\\texttt{NULL}\\]\n\n\n\n\nComparison operators (\\(&gt;\\), \\(&lt;\\), \\(=\\), \\(\\dots\\)): Result is UNKNOWN (neither TRUE nor FALSE)\n\n\n\n\n\n\n\nTip 3: Example: Comparison with NULL\n\n\n\n\n\n\\[x&lt;32 \\quad\\texttt{ --&gt; UNKNOWN}\\]\n\n\n\n\nThis UNKNOWN is a truth-value\nTruth-values in SQL are: TRUE, FALSE, UNKNOWN (a 3-value truth value system!)\n\nLogic with UNKNOWN: \\[\\begin{aligned}\n\\texttt{UNKNOWN} \\lor\\texttt{FALSE}&\\equiv\\texttt{UNKNOWN}\\\\\n\\texttt{UNKNOWN} \\lor\\texttt{TRUE}&\\equiv\\texttt{TRUE}\\\\\n\\texttt{UNKNOWN} \\land\\texttt{FALSE}&\\equiv\\texttt{FALSE}\\\\\n\\texttt{UNKNOWN} \\land\\texttt{TRUE}&\\equiv\\texttt{UNKNOWN}\\\\\n\\neg\\texttt{UNKNOWN}&\\equiv\\texttt{UNKONWN}\n\\end{aligned}\\]\nA tuple is in a query result \\(\\iff\\) the result of the WHERE clause is TRUE.\n\n\n\n\n\n\n“Aggregation ignores NULL.”\n\nNULL never contributes to a sum, average, or count, and can never be the minimum or maximum of a column (unless every value is NULL).\n\nIf ALL values are NULL in a column, then the result of the aggregation is NULL.\nException: COUNT of an empty set is 0. (think of COUNT(columnName) as a function that counts the non-null values in that column.)\n\n\n\n\n\n\n\nTip 4: Example: Aggregation with NULL\n\n\n\n\n\n\nR&S&T are defined as:\n\n R             |      S             |       T\n   x           |          x         |            x\n -----         |        -----       |          -----\n NULL          |        NULL        |\n 1             |                    |\n\nCOUNT()\n\nCOUNT(R.*)=2 and COUNT(R.x)=1\nCOUNT(S.*)=1 and COUNT(S.x)=0\nCOUNT(T.*)=0 and COUNT(T.x)=0\n\nOther aggregates:\n\nMIN(R.x)=1 and MAX(R.x)=1\nMIN(S.x)=NULL and MAX(S.x)=NULL\nMIN(T.x)=NULL and MAX(T.x)=NULL\n\n\n\n\n\n\n\n\n\nNULL is treated differently by the set operators UNION, EXCEPT, and INTERSECT than it is in search conditions.\nWhen comparing rows, set operators treat NULL values as equal to each other.\nIn contrast, when NULL is compared to NULL in a search condition the result is UNKNOWN (not true)."
  },
  {
    "objectID": "notes/NumericalAnalysis1.html",
    "href": "notes/NumericalAnalysis1.html",
    "title": "Undergraduate-Level Numerical Analysis",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes/Proofs.html#proof-practice",
    "href": "notes/Proofs.html#proof-practice",
    "title": "IB Math AA HL Notes",
    "section": "Proof Practice",
    "text": "Proof Practice"
  },
  {
    "objectID": "notes/Calc2.html",
    "href": "notes/Calc2.html",
    "title": "Calculus 2",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs334.html",
    "href": "notes/cs334.html",
    "title": "CS 334 Machine Learning",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n1 Linear Classification\n\n\n\n\n\n\nLinear Cassification\n\n\nLoss Function\n\n\nTraining Error\n\n\nPerceptron\n\n\n\nThis lecture discusses the linear classification, a fundamental concept in machine learning. It introduces loss functions, training error, and the perceptron algorithm.\n\n\n\n\n\nJan 23, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n2 Gradient Descent on Classification\n\n\n\n\n\n\nClassification\n\n\nGradient Descent\n\n\nHinge Loss\n\n\n\nThis lecture discusses the gradient descent algorithm and its application to classification problem.It introduces the hinge loss function and the update rule for gradient descent.\n\n\n\n\n\nJan 28, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n3 Linear Regression\n\n\n\n\n\n\nLinear Regreesion\n\n\nGradient Descent\n\n\nSquared Loss\n\n\nLeast Squares\n\n\nNormal Equation\n\n\n\nThis lecture discusses the linear regression, a fundamental concept in machine learning. It introduces the squared loss function and the update rule for gradient descent. It also derived the closed-form solution for linear regression using matrix notation.\n\n\n\n\n\nJan 30, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n4 Regularization\n\n\n\n\n\n\nRegularization\n\n\nBias-Variance Tradeoff\n\n\nRidge Regression\n\n\nLasso Regression\n\n\nElastic Net\n\n\n\nThis lecture starts from the bias-variance tradeoff, and then introduces regularization as a way to control the tradeoff. We will discuss the \\(L_2\\) regularization (Ridge Regression), \\(L_1\\) regularization (Lasso Regression), and Elastic Net.\n\n\n\n\n\nFeb 4, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n5 Logistic Regression\n\n\n\n\n\n\nLogistic Regression\n\n\nClassification\n\n\nSigmoid Function\n\n\n\nThis lecture introduces the logistic regression model, which is used for binary classification. We will discuss the sigmoid function, the likelihood function, and the cost function.\n\n\n\n\n\nFeb 6, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n6 Model Selection and Model Assessment\n\n\n\n\n\n\nModel Selection\n\n\nModel Assessment\n\n\nClassification Metrics\n\n\nRegression Metrics\n\n\nCross Validation\n\n\n\nThis lecture discusses the model assessment and model selection process. We will cover classification performance metrics, regression metrics, model assessment process, and model selection.\n\n\n\n\n\nFeb 11, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n7 Feature Selection and Kernels\n\n\n\n\n\n\nFeature Engineering\n\n\nFeature Selection\n\n\nKernels\n\n\n\nThis lecture discusses the feature selection and kernel methods. We will cover feature engineering and selection methods, kernel methods, and kernel tricks.\n\n\n\n\n\nFeb 18, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n8 Decision Trees and Random Forest\n\n\n\n\n\n\nDecision Trees\n\n\nEnsemble Methods\n\n\nRandom Forest\n\n\n\nThis lecture discusses the basics od decision trees including how to build a decision tree. It also introduces ensemble methods and discusses the random forest algorithm as an example of ensemble methods.\n\n\n\n\n\nMar 6, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n9 Boosting\n\n\n\n\n\n\nBoosting\n\n\nAdaBoost\n\n\nEnsemble Methods\n\n\n\nThis lecture discusses Boosting, a powerful ensemble learning technique that combines weak learners to create a strong learner.\n\n\n\n\n\nMar 20, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n10 Introduction to Neural Networks\n\n\n\n\n\n\nNeural Networks\n\n\nBackpropagation\n\n\nActivation Functions\n\n\n\nThis lecture discusses the basics of neural networks, including their architecture, activation functions, and training process. It also covers the concept of backpropagation and its role in optimizing neural networks.\n\n\n\n\n\nMar 25, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n11 Convolutional Neural Networks\n\n\n\n\n\n\nNeural Networks\n\n\nCNNs\n\n\nImage Processing\n\n\nDeep Learning\n\n\n\nThis lecture discusses the architecture and functioning of Convolutional Neural Networks (CNNs), including their layers, operations, and applications in image processing and computer vision. It also covers the concept of pooling layers and their role in reducing dimensionality.\n\n\n\n\n\nApr 1, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n12 Recurrent Neural Networks\n\n\n\n\n\n\nNeural Networks\n\n\nRecurrent Neural Networks\n\n\nLSTM\n\n\nDeep Learning\n\n\n\nThis lecture discusses the basics of recurrent neural networks (RNNs), including their architecture, training process, and applications. It also covers the concept of long short-term memory (LSTM) networks and their role in handling sequential data.\n\n\n\n\n\nApr 7, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n13 Reinforcement Learning\n\n\n\n\n\n\nReinforcement Learning\n\n\nMulti-Armed Bandit\n\n\nExploration-Exploitation\n\n\n\nThis lecture discusses the basics of reinforcement learning, including the concepts of agents, environments, rewards, and policies. It also covers the exploration-exploitation trade-off and multi-armed bandit problem.\n\n\n\n\n\nApr 13, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n14 Recommender Systems\n\n\n\n\n\n\nRecommender Systems\n\n\nCollaborative Filtering\n\n\nMatrix Factorization\n\n\n\nThis lecture discusses the basics of recommender systems, focusing on collaborative filtering. It introduces the nearest neighbor algorithm and matrix factorization techniques, including low-rank approximation via alternative minimization algorithm.\n\n\n\n\n\nApr 15, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n15 Clustering\n\n\n\n\n\n\nClustering\n\n\nUnsupervised Learning\n\n\nK-means\n\n\n\nThis lecture discusses the basics of clustering, focusing on the k-means algorithm. It covers the algorithm’s initialization, convergence, and the concept of local minima.\n\n\n\n\n\nApr 20, 2025\n\n\nJiuru Lyu\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "My Blogs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nPolynomial Representation of Arnoldi\n\n\n\nNumerical Analysis\n\n\nIterative Method\n\n\nLinear Algebra\n\n\nArnoldi\n\n\n\nI’m recently learning about the Arnoldi’s method, and the textbook mentioned that the it can be viewed from a polynomial approximation point of view. However, I think the…\n\n\n\nJiuru Lyu\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "photo.html",
    "href": "photo.html",
    "title": "Photograph",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "High School Level Math\n\nIB Math AA HL Notes\n\n\n\nCollege Level Math\n\nMath Fundamentals\n\nCalculus II\nMultivariable Calculus/Advanced Calculus/Calculus III\nLinear Algebra\nMathematical Proofs\nProof Practice\n\n\n\nApplied Mathematics\n\nOrdinary Differential Equations\nNonlinear Optimization\nUndergraduate-Level Numerical Analysis\nNumerical ODEs and PDEs\nPhD-Level Numerical Analysis I (Numerical Linear Algebra)\nPhD-Level Numerical Analysis II\n\n\n\nPure Mathematics\n\nLinear Algebra Done Right\nReal Analysis\n\n\n\nData Science, Statistics, and Causal Inference\n\nIntroduction to Causal Inference\nGoogle Data Analytics Learning Notes\nMathematical Statistics – Propability Theory\nMathematical Statistics – Statistical Inference\nCausal Designs and Inference\nMachine Learning\n\n\n\n\nComputer Science\n\nObject-Oriented Programming & Introduction to Data Structures\nIntroduction to Data Structure and Algorithms\nDatabase Systems\n\n\n\nOther Fields\n\nIntroduction to Sociology\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jiuru Lyu",
    "section": "",
    "text": "Hi! My name is Jiuru Lyu, and I am a junior at Emory University studying Applied Mathematics. In my leisure time, I enjoy coffee brewing, traveling, photography, and commercial aviation."
  },
  {
    "objectID": "notes/cs334/02-Gradient-Descent-on-Classification/02-Gradient-Descent-on-Classification.html",
    "href": "notes/cs334/02-Gradient-Descent-on-Classification/02-Gradient-Descent-on-Classification.html",
    "title": "2 Gradient Descent on Classification",
    "section": "",
    "text": "Goal: Learning to classify non-linearly separable data (by considering a different objective function)."
  },
  {
    "objectID": "notes/cs334/02-Gradient-Descent-on-Classification/02-Gradient-Descent-on-Classification.html#objective-function-and-hinge-loss",
    "href": "notes/cs334/02-Gradient-Descent-on-Classification/02-Gradient-Descent-on-Classification.html#objective-function-and-hinge-loss",
    "title": "2 Gradient Descent on Classification",
    "section": "Objective Function and Hinge Loss",
    "text": "Objective Function and Hinge Loss\n\n\n\n\n\n\n\nDefinition 1 (Objective Function for Perceptron Algorithm) \\[\n\\epsilon_{N}(\\va\\theta)=\\sum_{i=1}^N\\1\\qty{-y^{(i)}(\\va\\theta\\cdot\\va x^{(i)})\\leq0},\n\\] for conciseness, we assume the offset parameter is implicity. Note that the empirical risk is \\[\nR_N(\\va\\theta)=\\frac{1}{N}\\sum_{i=1}^N\\operatorname{loss}\\qty(y^{(i)}\\qty(\\va\\theta\\cdot\\va x^{(i)})),\n\\] so, training error is a special case of empirical risk.\n\n\n\n\n\nPreviously, we were using “zero-one loss”. Let \\(z=y(\\va\\theta\\cdot\\va x)\\), then the zero-one loss is \\[\n\\operatorname{loss}_{0-1}(z)=\\1\\qty{z\\leq0}=\\begin{cases}1\\quad&\\text{if }z\\leq 0\\\\0\\quad&\\text{o.w}\\end{cases}.\n\\]\n\nThe graph of the zero-one loss is shown below:\n\n\n\n\n\n\nFigure 1: Zero One Loss\n\n\n\n\nHowever, there are some issues with the zero-one loss:\n\nNot continuous at \\(z=0\\).\nNot differentiable at \\(z=0\\).\nNot convex.\n\nDue to these issues, direct minimization of empirical risk with \\(0-1\\) loss is chanllenging for the general case (NP-hard).\n\n\n\n\n\n\n\nTip 1: Calculus Refresher\n\n\n\n\n\n\nContinuous: A function \\(f\\) is continuous at \\(x_0\\) if \\[\\lim_{x\\to x_0}f(x)=f(x_0)\\].\nDifferentiable: A function \\(f\\) is differentiable at \\(x_0\\) if the following limit exists: \\[\\lim_{h\\to 0}\\frac{f(x_0+h)-f(x_0)}{h}\\] Also, Differentiable \\(\\implies\\) continuous.\nConvex/concave up: \\[f(\\lambda x+(1-\\lambda)y)\\leq\\lambda f(x)+(1-\\lambda)f(y).\\]\n\n\n\n\n\n\n\nFigure 2: Convex Function\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1 (Motivation of Hinge Loss: Misclassification)  \n\n\n\n\n\n\nFigure 3: Misclassification on Non-Linearly Separable Data\n\n\n\n\nLoss (or cost) associated with the ==misclassification== of these points is identified under \\(0-1\\) loss. Then, loss is \\(1\\) for each misclassified point.\nHowever, these two misclassifications are not equally bad.\nWe need a loss function that treats these mistakes differently.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 2 \\[\n\\operatorname{loss}_h(z)=\\max\\qty{0,1-z}=\\begin{cases}1-z\\quad&\\text{if }z\\leq 1\\\\0\\quad&\\text{if }z&gt;1\\end{cases}\n\\]\nThe graph of the hinge loss is shown below:\n\n\n\n\n\n\nFigure 4: Hinge Loss\n\n\n\n\n\n\n\n\nProperties of hinge loss:\n\nNon-negative.\nIf \\(z=y\\qty(\\va\\theta\\cdot\\va x)&lt;1\\), we incur a non-zero cost.\nThis forces predictions to be more than just correct, but we need \\[y\\qty(\\va\\theta\\cdot\\va x)\\geq 1.\\] Note, previously, we only imposed \\(y\\qty(\\va\\theta\\cdot\\va x)&gt;0\\).\n\n\n\n\n\n\n\n\n\nRemark 1 (What does \\(z=y\\qty(\\va\\theta\\cdot\\va x)\\) tell us?). \n\nSign: correct (\\(&gt;0\\)) or wrong (\\(&lt;0\\)).\nMagnitude: how wrong (the larger, the more wrong). \\[\n\\abs{y\\qty(\\va\\theta\\cdot\\va x)}=\\abs{y}\\cdot\\abs{\\va\\theta\\cdot\\va x},\n\\] where \\(\\abs{y}=1\\) since \\(y\\in{-1,+1}\\) and \\(\\dfrac{\\abs{\\va\\theta\\cdot\\va x}}{\\norm{\\va\\theta}}\\) is the distance from the point to the decision boundary.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 3 (Empirical Risk with Hinge Loss) \\[\nR_N(\\va\\theta)=\\dfrac{1}{N}\\sum_{i=1}^N\\max\\qty{0, 1-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}}\n\\] Why is it better/easier to minimize? - Continuous - (Sub)differentiable - Convex \\(\\implies\\) We can use a simple algorithm to minimize it: Gradient Descent."
  },
  {
    "objectID": "notes/cs334/02-Gradient-Descent-on-Classification/02-Gradient-Descent-on-Classification.html#gradient-descent",
    "href": "notes/cs334/02-Gradient-Descent-on-Classification/02-Gradient-Descent-on-Classification.html#gradient-descent",
    "title": "2 Gradient Descent on Classification",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\nGradient:\n\nUnivariate case: \\(f:\\R\\to\\R\\), \\(y=f(x)\\). Its derivative is \\(f'(x)=\\dsst\\dv{x} f(x)\\). \\(f'(x)\\) represents the rate of change:\n\n\\(f'(x)&gt;0\\): increasing\n\\(f'(x)=0\\): a critical point\n\\(f'(x)&lt;0\\): decreasing.\n\nMultivariate case: \\(f:\\R^d\\to\\R\\), \\(y=f(\\va x)=f(x_1,x_2,\\dots,x_d)\\). Its gradient is \\[\\grad_{\\va x} f(\\va x)=\\mqty[\\dsst\\pdv{x_1} f(\\va x),\\dots,\\dsst\\pdv{x_d} f(\\va x)]^\\top.\\] The gradient points in the direction of the steepest ascent.\n\nGradient Descent (GD):\n\nSuppose we want to minimize some \\(f(\\va\\theta)\\) with respect to \\(\\va\\theta\\). We know gradient \\(\\grad_{\\va\\theta}f(\\va\\theta)\\) points in the direction of steepest increase.\nIdea: start somewhere, and take small steps in the opposite direction as gradient.\n\n\n\n\n\\begin{algorithm} \\caption{Gradient Descent (GD)} \\begin{algorithmic} \\State $k=0$; $\\va\\theta^{(0)}=\\va 0$ \\While{not converged} \\State $\\va\\theta^{(k+1)}=\\va\\theta^{(k)}-\\underbrace{\\eta_k}_{\\substack{\\text{learning}\\\\\\text{rate}}}\\overbrace{\\eval{\\grad_{\\va\\theta} f(\\va\\theta)}_{\\va\\theta=\\va\\theta^{(k)}}}^{\\substack{\\text{evaluate gradient}\\\\\\text{at current }\\va\\theta}}$ \\State $k++$ \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\n\nImprove GD (Algorithm 1): Stochastic Gradient Descnet (SGD):\n\nIn GD (Algorithm 1), we need to compute the gradient over the entire dataset. This can be expensive for large datasets.\nIn SGD (Algorithm 2), we compute the gradient for each data point and update \\(\\va\\theta\\) accordingly.\n\n\n\n\n\\begin{algorithm} \\caption{Stochastic Gradient Descent (SGD)} \\begin{algorithmic} \\State $k=0$; $\\va\\theta^{(0)}=\\va 0$ \\While{not converged} \\State randomly shuffle points \\For{$i=1,\\dots, N$} \\State $\\va\\theta^{(k+1)}=\\va\\theta^{(k)}-\\eta_k\\eval{\\grad_{\\va\\theta}\\operatorname{loss}(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})}_{\\va\\theta=\\va\\theta^{(k)}}$ \\State $k++$ \\EndFor \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\n\nGradient for Hinge Loss: \\[\n\\operatorname{loss}_h(z)=\\max\\qty{0,1-y\\va\\theta\\cdot\\va x}\n\\]\n\n\\(\\boxed{\\text{Case I}}\\) If \\(y^{(i)}\\va\\theta\\cdot\\va x^{(i)}\\geq 1\\): loss is zero. Already at minimum. No update.\n\\(\\boxed{\\text{Case II}}\\) If \\(y^{(i)}\\va\\theta\\cdot\\va x^{(i)}&lt;1\\): loss is \\[1-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}\\] Note that \\(\\va\\theta\\cdot\\va x=\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_dx_d\\), we have \\[\n\\grad_{\\va\\theta}(\\va\\theta\\cdot\\va x)=\\mqty[x_1,x_2,\\dots,x_d]^\\top=\\va x.\n\\] So, the gradient is \\[\n\\begin{aligned}\n\\grad_{\\va\\theta}\\operatorname{loss}_h(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})&=\\grad_{\\va\\theta}(1-y^{(i)}\\va\\theta\\cdot\\va x)\\\\\n&=0-y^{(i)}\\grad_{\\va\\theta}(\\va\\theta\\cdot\\va x)\\\\\n&=-y^{(i)}\\va x^{(i)}.\n\\end{aligned}\n\\]\nSo, in Algorithm 2, the update rule is\n\\[\n\\begin{aligned}\n\\va\\theta^{(k+1)}&=\\va\\theta^{(k)}-\\eta_k\\eval{\\grad_{\\va\\theta}\\operatorname{loss}(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})}_{\\va\\theta=\\va\\theta^{(k)}}\\\\\n&=\\va\\theta^{(k)}+\\eta_ky^{(i)}\\va x^{(i)}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nRemark 2 (Why shuffle points in SGD?). \n\nRemove the effect of any unintended/aritifical ordering in the dataset.\nFaster convergence\n\n\n\n\n\n\nStopping criteria\n\nCheck if empirical risk stops decreasing.\nCheck if parameter vector stop changing.\nNote: make \\(\\operatorname{loss}=0\\) does not work here since the data is not perfectly linearly separable. \n\nLearning rate/Step size/\\(\\eta\\):\n\nToo small: slow convergence.\nToo large: overshot & never converge\nA hyperparameter that can (and should) be tuned.\nMay set \\(\\eta\\) as a constant or a function of \\(k\\). For example, \\[\\eta_k=\\dfrac{1}{k}.\\]\n\n\n\n\n\n\n\n\n\nTheorem 1 (GD (Algorithm 1) and SGD (Algorithm 2) Convergence Theorem)  \n\nWith appropriate learning rate \\(\\eta\\), if \\(R_N(\\va\\theta)\\) is convex, (S)GD will converge to the global minimum almost surely.\nSGD is a general algorithm that can be applied to non-convex functions as well, in which case it converges to a local minimum.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 4 (Robbins-Monro Conditions) A good learning rate ensures convergence satisfying the Robbins-Monro conditions: \\[\n\\sum_{k=1}^\\infty\\eta_k=\\infty\\quad\\text{and}\\quad\\sum_{k=1}^\\infty\\eta_k^2&lt;\\infty.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nRemark 3 (Differentiability of Loss Function). \\(R_N(\\va\\theta)\\) with hinge loss is not everywhere differentiable since it si piecewise linear. What do we do? - When differentiable, use gradient. - When sub-differentiable, choose any gradient around the kink."
  },
  {
    "objectID": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html",
    "href": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html",
    "title": "3 Linear Regression",
    "section": "",
    "text": "Goal: Given data \\(\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N\\), find a linear model \\[\nf(\\va x;\\va\\theta)=\\va\\theta\\cdot\\va x,\n\\] such that minimizes the empirical loss."
  },
  {
    "objectID": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#the-loss-function",
    "href": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#the-loss-function",
    "title": "3 Linear Regression",
    "section": "The Loss Function",
    "text": "The Loss Function\n\n\n\n\n\n\n\nDefinition 1 (Squared Loss Function) The empirical loss for linear regression is defined by \\[\nR_N(\\va\\theta)=\\dfrac{1}{N}\\sum_{i=1}^N\\operatorname{loss}\\qty(y^{(i)}, \\va\\theta\\cdot\\va x^{(i)}),\n\\] where loss is the squared loss: \\[\n\\operatorname{loss}(z)=\\dfrac{z^2}{2}.\n\\]\nThis loss function is continuous, differentiable, and convex.\nHere is a graph of the squared loss function:\n\n\n\n\n\n\nFigure 1: Squared Loss\n\n\n\nIntuition: we permits small discrepancies but penalizes large deviations."
  },
  {
    "objectID": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#ordinary-least-squares-ols",
    "href": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#ordinary-least-squares-ols",
    "title": "3 Linear Regression",
    "section": "Ordinary Least Squares (OLS)",
    "text": "Ordinary Least Squares (OLS)\n\nWe will minimize the empirical loss with squared loss, i.e., \\[\nR_N(\\va\\theta)=\\dfrac{1}{N}\\sum_{i=1}^N\\dfrac{\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})^2}{2},\n\\] using SGD algorithm\nRecall the gradient descent update rule: \\[\n\\va\\theta^{(k+1)}=\\va\\theta^{(k)}-\\eta_k\\eval{\\grad_{\\va\\theta}\\operatorname{loss}(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})}_{\\va\\theta=\\va\\theta^{(k)}}\n\\]\n\nIn OLS case, we have \\[\n\\begin{aligned}\n\\grad_{\\va\\theta}\\operatorname{loss}(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})&=\\grad_{\\va\\theta}\\dfrac{\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})^2}{2}\\\\\n&=-\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})\\va x^{(i)}.\n\\end{aligned}\n\\]\nSo, the update rule is \\[\n\\va\\theta^{(k+1)}=\\va\\theta^{(k)}+\\eta_k\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})\\va x^{(i)}.\n\\]\n\n\n\\begin{algorithm} \\caption{SGD for Least Squares Regression} \\begin{algorithmic} \\State $k=0$; $\\va\\theta^{(0)}=\\va 0$ \\While{not converged} \\State randomly shuffle points \\For{$i=1,\\dots, N$} \\State $\\va\\theta^{(k+1)}=\\va\\theta^{(k)}+\\eta_k\\eval{\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})\\va x^{(i)}}_{\\va\\theta=\\va\\theta^{(k)}}$ \\State $k++$ \\EndFor \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\n\n\nRemark 1 (Compare with Hinge Loss Classification). \n\nWe make updates on every data points\nStopping criteria, learning rate, shuffling, etc., are the same."
  },
  {
    "objectID": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#closed-form-solution",
    "href": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#closed-form-solution",
    "title": "3 Linear Regression",
    "section": "Closed-Form Solution",
    "text": "Closed-Form Solution\n\nSince \\(R_N(\\va\\theta)\\) with squared loss is a covex function and differentiable everywhere, we can try to minimize it analytically by setting the gradient to \\(0\\).\nRewrite empirical risk in matrix notation: \\[\nX=\\mqty[-&\\va x^{(1)\\top}&-\\\\&\\vdots&\\\\-&\\va x^{(N)\\top}&-]_{N\\times d}\\quad\\text{and}\\quad \\va y=\\mqty[y^{(1)}\\\\\\vdots\\\\y^{(N)}]_{N\\times 1}.\n\\] Then, the empirical risk is \\[\n\\begin{aligned}\nR_N(\\va\\theta)=\\dfrac{1}{2}\\dfrac{1}{N}\\sum_{i=1}^N\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})^2&=\\dfrac{1}{2N}\\qty(X\\va\\theta-\\va y)^\\top\\qty(X\\va\\theta-\\va y)\\\\\n&=\\dfrac{1}{2N}\\qty(\\va\\theta^\\top X^\\top X\\va\\theta-2\\va\\theta^\\top (X^\\top\\va y)+\\va y^\\top\\va y).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nTip 1: Commonly Used Differentiation Rules\n\n\n\n\n\n\n\n\n\\(f(\\va x)\\)\n\\(\\grad_{\\va x}f(\\va x)\\)\n\n\n\n\n\\(\\va v^\\top\\va x\\)\n\\(\\va v\\)\n\n\n\\(\\va x^\\top\\va x\\)\n\\(2\\va x\\)\n\n\n\\(\\va x^\\top A\\va x\\)\n\\((A+A^\\top)\\va x\\) 1\n\n\n\n\n\n\n\nTherefore, the gradient of \\(R_N(\\va\\theta)\\) is\n\n\\[\n\\begin{aligned}\n\\grad_{\\va\\theta}R_N(\\va\\theta)&=\\dfrac{1}{2N}\\qty(2X^\\top X\\va\\theta-2(X^\\top\\va y))\\\\\n&=\\dfrac{1}{N}\\qty(X^\\top X\\va\\theta-X^\\top\\va y).\n\\end{aligned}\n\\]\n\nSet gradient to \\(0\\), we have\n\n\\[\n\\begin{aligned}\n\\grad_{\\va\\theta}R_N(\\va\\theta)&=0\\\\\n\\dfrac{1}{N}\\qty(X^\\top X\\va\\theta-X^\\top\\va y)&=0\\\\\nX^\\top X\\va\\theta-X^\\top\\va y&=0\\\\\nX^\\top X\\va\\theta&=X^\\top\\va y\\\\\n\\va\\theta^*&=\\qty(X^\\top X)^{-1}X^\\top\\va y.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nRemark 2 (Normal Equation and Inveritibility). \n\nThe solutions is called the Normal Equation or the OLS solution.\nOLS solution \\(\\va\\theta^*=\\qty(X^\\top X)^{-1}X^\\top\\va y.\\) exists only when \\(X^\\top X\\) is invertible.\nInvertibility of \\(X^\\top X\\): “Gram matrix”\n\nWhy might it be non-invertible/singular/degenerate? \\[\\rank(X^\\top X)\\leq\\rank(X)\\leq\\min\\qty{N,d}\\]\n\nIf \\(d&gt;N\\), then \\(\\rank(X^\\top X)\\leq N&lt;d\\). Since \\(X^\\top X\\in\\R^{d\\times d}\\), we know \\(X^\\top X\\) is not full rank, and thus non-invertible.\nFor example, if we have duplicated features, say \\(x_1=x_2\\), then if \\(\\mqty[\\theta_1,\\theta_2]\\) is a solution, then \\(\\mqty[\\theta_1-c,\\theta_2+c]\\) is also a solution.\n\nWhat to do if \\(X^\\top X\\) is not invertible?\n\nMonro-Penrose Pseudo-Inverse: \\[\\va\\theta^*=(X^\\top X)^{\\dagger}X^\\top \\va y=X^{\\dagger}\\va y\\]\nRegularization: See next lecture."
  },
  {
    "objectID": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#footnotes",
    "href": "notes/cs334/03-Linear-Regression/03-Linear-Regression.html#footnotes",
    "title": "3 Linear Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf \\(A\\) is symmetric, then \\(\\grad_{\\va x}f(\\va x)=2A\\va x\\).↩︎"
  },
  {
    "objectID": "notes/cs334/04-Regularization/04-Regulairzation.html",
    "href": "notes/cs334/04-Regularization/04-Regulairzation.html",
    "title": "4 Regularization",
    "section": "",
    "text": "Polynomial regression:\n\nInstead of only using \\(\\phi(x)=[1,x]^\\top\\) , we can add higher dimension terms of feature: \\[\\phi(x)=[1,x,x^2,x^3,\\dots]^\\top\\]\nHowever, if we get too far, we will encounter overfitting.\n\nOverfitting and Underfitting:\n\nIf we optimize \\(R(\\va\\theta, D)\\), \\(R(\\va\\theta, D_\\text{test})\\) can be learge due to:\n\n\n\n\n\nUnderfitting\nOverfitting\n\n\n\n\nBias\nVariance\n\n\nApproximation error\nEstimation error\n\n\nPoor on training set\nGood on training set\n\n\nPoor on test set\nPoor on test set\n\n\nAdding more data will not help\nAdding more data will help\n\n\n\n\n\n\n\n\n\nFigure 1: Model Complexity vs. Error: Bias-Variance Tradeoff\n\n\n\n\nSources of Bias:\n\nModel class too small: unable to represent the underlying relationship\nModels are “too global” (e.g., constant output, single linear separator)\n\nReduing Bias: Use more complex models\n\nInteraction terms\nAdd more features\nKernels\nAlgorithm-specific approaches\n\nSources of Variance:\n\nNoise in labels or features\nModels are too “local” – sensitive to small changes in feature values\nTraining dataset too small.\n\nReducing Variance: Collect more data, or less complex models\n\nDrop interaction terms\nRegualrization\nFeature selection\nDon’t use kernels\nEnsemble\n\nBalancing Bias and Variance: Generalizable Model\n\nBut how to control the tradeoff? Regularization."
  },
  {
    "objectID": "notes/cs334/04-Regularization/04-Regulairzation.html#introduction-bias-variance-tradeoff",
    "href": "notes/cs334/04-Regularization/04-Regulairzation.html#introduction-bias-variance-tradeoff",
    "title": "4 Regularization",
    "section": "",
    "text": "Polynomial regression:\n\nInstead of only using \\(\\phi(x)=[1,x]^\\top\\) , we can add higher dimension terms of feature: \\[\\phi(x)=[1,x,x^2,x^3,\\dots]^\\top\\]\nHowever, if we get too far, we will encounter overfitting.\n\nOverfitting and Underfitting:\n\nIf we optimize \\(R(\\va\\theta, D)\\), \\(R(\\va\\theta, D_\\text{test})\\) can be learge due to:\n\n\n\n\n\nUnderfitting\nOverfitting\n\n\n\n\nBias\nVariance\n\n\nApproximation error\nEstimation error\n\n\nPoor on training set\nGood on training set\n\n\nPoor on test set\nPoor on test set\n\n\nAdding more data will not help\nAdding more data will help\n\n\n\n\n\n\n\n\n\nFigure 1: Model Complexity vs. Error: Bias-Variance Tradeoff\n\n\n\n\nSources of Bias:\n\nModel class too small: unable to represent the underlying relationship\nModels are “too global” (e.g., constant output, single linear separator)\n\nReduing Bias: Use more complex models\n\nInteraction terms\nAdd more features\nKernels\nAlgorithm-specific approaches\n\nSources of Variance:\n\nNoise in labels or features\nModels are too “local” – sensitive to small changes in feature values\nTraining dataset too small.\n\nReducing Variance: Collect more data, or less complex models\n\nDrop interaction terms\nRegualrization\nFeature selection\nDon’t use kernels\nEnsemble\n\nBalancing Bias and Variance: Generalizable Model\n\nBut how to control the tradeoff? Regularization."
  },
  {
    "objectID": "notes/cs334/04-Regularization/04-Regulairzation.html#regularization",
    "href": "notes/cs334/04-Regularization/04-Regulairzation.html#regularization",
    "title": "4 Regularization",
    "section": "Regularization",
    "text": "Regularization\n\n\n\n\n\n\n\nDefinition 1 (Regularization Training Error) A “knob” for controlling model complexity: \\[\nJ(\\va\\theta)=\\underbrace{R_N(\\va\\theta)}_\\text{emiprical risk}+\\underbrace{\\lambda\\Omega(\\va\\theta)}_\\text{regularization term},\n\\] where \\(\\lambda\\) is the regularization strength, \\(\\lambda&gt;0\\), and \\(\\Omega(\\va\\theta)\\) is the regularizer/regularization penalty.\nThe regularization strength \\(\\lambda\\) balances: - How well we fit the data, and - Complexity of model.\nThen, our goal is to \\(\\displaystyle\\min_{\\va\\theta}J(\\va\\theta)\\).\n\n\n\n\n\nCommon Regularizer:\n\n\\(L_2\\): Ridge Regression \\[\\Omega(\\va\\theta)=\\dfrac{\\|\\va\\theta\\|_2^2}{2}=\\dfrac{1}{2}\\sum_{j=1}^d\\theta_j^2\\]\n\\(L_1\\): Lasso Regression \\[\\Omega(\\va\\theta)=\\|\\va\\theta\\|_1=\\sum_{j=1}^d\\abs{\\theta_j}\\]\nElastic net: \\[\\Omega(\\va\\theta)=\\lambda_2\\|\\va\\theta\\|_2^2+\\lambda_1\\|\\va\\theta\\|_1\\]\n\nEffect of Regularization:\n\nWhen minimizing \\(J(\\va\\theta)\\), we are still trying to minimize \\(R_N(\\va\\theta)\\), but at the same time, minimize \\(\\Omega(\\va\\theta)\\)\n\nPush parameters to small values\nResist setting parameters away from default of \\(0\\) unless data strong suggest otherwise.\n\nWhy are small values in \\(\\va\\theta\\) good?\n\nLimit effect of small perturbations in individual factors on putput.\nIf \\(\\theta_j=0\\) exactly, then \\(j\\)-th parameter is effective unused \\(\\implies\\) feature selection.\nOccam’s Razor (\\(13\\)-th century philosopher, William of Ockham): “When you have two competing hypotheses, the simpler one is preferred.”\n\n\nRidge Regression (\\(L_2\\)-Regularized Linear Regression) \\[J(\\va\\theta)=\\sum_{i=1}^N\\dfrac{(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})^2}{2}+\\lambda\\dfrac{\\|\\va\\theta\\|_2^2}{2},\\] where \\(\\dfrac{1}{N}\\) is absorbed into \\(\\lambda\\).\n\nSGD: \\[\\grad_{\\va\\theta}\\qty(\\dfrac{\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})^2}{2}+\\lambda\\dfrac{\\|\\va\\theta\\|_2^2}{2})\\] gradient of squared \\(L_2\\) norm: \\(\\|\\va\\theta\\|_2^2=\\theta_1^2+\\cdots+\\theta_d^2=\\va\\theta\\cdot\\va\\theta\\). So, \\[\\pdv{\\theta_j}\\qty(\\|\\va\\theta\\|_2^2)=2\\theta_j.\\] Then, we have \\[\n\\begin{aligned}\n  \\grad_{\\va\\theta}\\qty(\\|\\va\\theta\\|_2^2)=\\grad_{\\va\\theta}(\\va\\theta\\cdot\\va\\theta)&=\\mqty[\\displaystyle\\pdv{\\theta_1}\\qty(\\|\\va\\theta\\|_2^2),\\dots,\\pdv{\\theta_d}\\qty(\\|\\va\\theta\\|_2^2)]\\\\\n  &=\\mqty[2\\theta_1,2\\theta_2,\\dots,2\\theta_d]\\\\\n  &=2\\va\\theta.\n\\end{aligned}\n\\] Therefore, \\[\n\\grad_{\\va\\theta}\\qty(\\dfrac{\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})^2}{2}+\\lambda\\dfrac{\\|\\va\\theta\\|_2^2}{2})=-\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})\\va x^{(i)}+\\lambda\\va\\theta.\n\\] Hence, the SGD update rule is \\[\n\\begin{aligned}\n\\va\\theta^{(k+1)}=\\va\\theta^{(k)}-\\eta_k\\eval{\\qty[-\\qty(y^{(i)}-\\va\\theta\\cdot\\va x^{(i)})\\va x^{(i)}+\\lambda\\va\\theta]}_{\\va\\theta=\\va\\theta^{(k)}}\\\\\n&=\\va\\theta^{(k)}+\\eta_k\\qty(y^{(i)}-\\va\\theta^{(k)}\\cdot\\va x^{(i)})\\va x^{(i)}-\\eta_k\\lambda\\va\\theta^{(k)}\\\\\n&=\\underbrace{(1-\\eta_k\\lambda)}_{\\text{between }0\\text{ and }1}\\va\\theta^{(k)}+\\underbrace{\\eta_k\\qty(y^{(i)}-\\va\\theta^{(k)}\\cdot\\va x^{(i)})\\va x^{(i)}}_\\text{same as before}.\n\\end{aligned}\n\\] The term \\(1-\\eta_k\\lambda\\) shrinks parameters towards \\(0\\) in each update.\nClosed Form Solution: \\[\n\\begin{aligned}\nJ(\\va\\theta)&=\\dfrac{1}{2}(X\\va\\theta-\\va y)^\\top(X\\va\\theta-\\va y)+\\dfrac{\\lambda}{2}\\va\\theta^\\top\\va\\theta\\\\\n\\grad_{\\va\\theta} J(\\va\\theta)&=(XX)\\va\\theta-X^\\top y+\\lambda\\va\\theta\\\\\n&=(XX+\\lambda I_d)\\va\\theta-X^\\top y=0\\\\\n\\va\\theta^*&=(\\underbrace{XX+\\lambda I_d}_\\text{always invertible})^{-1}X^\\top y.\n\\end{aligned}\n\\]\n\nGeometric Interpretation of Regularization: \\[\n\\va\\theta^*=\\argmin_{\\va\\theta}R_N(\\va\\theta)+\\lambda\\Omega(\\va\\theta) \\iff \\min_{\\va\\theta}R_N(\\va\\theta)\\quad\\text{s.t.}\\quad\\Omega(\\va\\theta)\\leq B.\n\\]\n\nWe can transfer a constrained optimization problem to an unconstrained one by adding a penalty term.\nThey are equivalent by the Lagrange multiplier.\n\n\n\n\n\n\n\n\nFigure 2: Geometric Interpretation of Regularization\n\n\n\n\nWhere is the optimal soltuion of the constrained optimization problem? The solution is the intersection of the level set of \\(R_N(\\va\\theta)\\) and the level set of \\(\\Omega(\\va\\theta)\\).\nMethod of Lagrange Multtiplier:\n\nThe pint where the level curve of function to minimize is tangent to (or just touching) the constraint.\n\nIntuition: two forces play\n\n\\(\\Omega(\\va\\theta)\\leq B\\): shrink \\(\\va\\theta\\) towards winthin the constraint\n\\(\\min R_N(\\va\\theta)\\): move \\(\\va\\theta\\) towards the uncosntraied minimizer.\n\n\\(L_2\\) regularization will make parameters generally small.\n\\(L_1\\) regularization will make parameters sparse, and make some parameters exeactly \\(0\\).\n\n\n\n\n\n\n\n\nRemark 1 (Remarks on Regularization). \n\nIf there is an offset/intercept, this coefficient is usually left unpenalized (depending on the implementation).\n\nIf we write \\(\\va\\theta\\cdot\\va x+b\\) explicity, no penalty on \\(b\\).\nIf we write augmented parameters, then we penalize \\(b\\).\n\nRegularization can be “unfair” if features are on the different scales. So, we need feature pre-procesing (e.g., centering and normalization).\nPratical usage of regression: sklearn\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nsklearn.linear_model.LinearRegression\nclosed form solution (wrapper of scipy.linalg.lstsq that uses SVD)\n\n\nsklearn.linear_model.Ridge\nRidge regressionm, can select solver (SGD, SVD, etc.)\n\n\nsklearn.linear_model.Lasso\nLasso regression, coordinate descent\n\n\nsklearn.linear_model.ElasticNet\nElastic net, coordinate descent\n\n\nsklearn.linear_model.SGDRegressor\ngeneric SGD, mix and match different loss and regularizers\n\n\n\n\nPratical use of linear classification: sklearn\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nsklearn.linear_model.LogisticRegression\nlogistic regression, can select solver (SGD, Newton-CG, etc.)\n\n\nsklearn.linear_model.SGDClassifier\ngeneric SGD, mix and match different loss and regularizers\n\n\nsklearn.linear_model.Perceptron\nperceptron, SGD with hinge loss\n\n\nsklearn.svm.LinearSVC\nlinear SVM, hinge loss (support vector machine)\n\n\nsklearn.svm.SVC\nnon-linear SVM, kernel trick"
  },
  {
    "objectID": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html",
    "href": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html",
    "title": "5 Logistic Regression",
    "section": "",
    "text": "The problem: Given binar labels \\(y\\in\\qty{-1,+1}\\). We want to predict the probability of positive class, \\(\\hat y\\in[0, 1]\\).\nHow to make a linear model output a probability? We already have \\(\\va\\theta\\cdot\\va x\\in(-\\infty,\\infty)\\).\n\nApply a sequashing function: \\(\\sigma(\\va\\theta\\cdot\\va x)\\in[0,1]:\\R\\to[0,1]\\).\nWe will use a sigmoid function*: \\[\\sigma(z)=\\dfrac{1}{1+e^{-z}}\\]\n\nRange of sigmoid:\n\nfor \\(z\\to\\infty\\), \\(\\sigma(z)\\to 1\\)\nfor \\(z\\to-\\infty\\), \\(\\sigma(z)\\to 0\\)\n\\(\\sigma(0)=0.5\\)\n\nUseful properties:\n\n\\(\\sigma(-z)=1-\\sigma(z)\\)\n\\(\\sigma'(z)=\\sigma(z)(1-\\sigma(z))\\)\ncontinuous\ndifferentiable\nnot convex\n\n\n\n\n\n\n\n\n\n\nFigure 1: Sigmoid Function"
  },
  {
    "objectID": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html#motivation",
    "href": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html#motivation",
    "title": "5 Logistic Regression",
    "section": "",
    "text": "The problem: Given binar labels \\(y\\in\\qty{-1,+1}\\). We want to predict the probability of positive class, \\(\\hat y\\in[0, 1]\\).\nHow to make a linear model output a probability? We already have \\(\\va\\theta\\cdot\\va x\\in(-\\infty,\\infty)\\).\n\nApply a sequashing function: \\(\\sigma(\\va\\theta\\cdot\\va x)\\in[0,1]:\\R\\to[0,1]\\).\nWe will use a sigmoid function*: \\[\\sigma(z)=\\dfrac{1}{1+e^{-z}}\\]\n\nRange of sigmoid:\n\nfor \\(z\\to\\infty\\), \\(\\sigma(z)\\to 1\\)\nfor \\(z\\to-\\infty\\), \\(\\sigma(z)\\to 0\\)\n\\(\\sigma(0)=0.5\\)\n\nUseful properties:\n\n\\(\\sigma(-z)=1-\\sigma(z)\\)\n\\(\\sigma'(z)=\\sigma(z)(1-\\sigma(z))\\)\ncontinuous\ndifferentiable\nnot convex\n\n\n\n\n\n\n\n\n\n\nFigure 1: Sigmoid Function"
  },
  {
    "objectID": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html#logistic-regression",
    "href": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html#logistic-regression",
    "title": "5 Logistic Regression",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\nLogistic Regression: \\[\nh(\\va x;\\va\\theta)=\\sigma(\\va\\theta\\cdot\\va x)=\\dfrac{1}{1+e^{-\\va\\theta\\cdot\\va x}}\n\\]\nHow to train this classifier? What loss function should we use?\n\nWhat we want: \\(\\sigma(\\va\\theta\\cdot\\va x)\\) should be the probability of positive class: \\(\\P[y=+1\\mid\\va x]\\).\nIdea: If \\(\\sigma(\\va\\theta\\cdot\\va x)\\) is truely the probability, then we can use it to wrtie down the likelihood of the training data \\(\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N\\).\n\nFor each example \\(\\va x^{(i)}\\), the likelihood of seeing its label to be \\(y^{(i)}\\) is \\[\n\\P[y=y^{(i)}\\mid \\va x^{(i)};\\va\\theta]=\\begin{cases}\\sigma(\\va\\theta\\cdot\\va x^{(i)})&\\quad\\text{if }y^{(i)}=+1\\\\\\underbrace{1-\\sigma(\\va\\theta\\cdot\\va x^{(i)})}_{=\\sigma(-\\va\\theta\\cdot\\va x^{(i)})}&\\quad\\text{if }y^{(i)}=-1\\end{cases}=\\sigma(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})\n\\]\nSince each training example is generated independently, \\[\\P\\qty[\\qty{y^{(i)}}_{i=1}^N\\mid\\qty{\\va x^{(i)}}_{i=1}^N;\\va\\theta]=\\prod_{i=1}^N\\sigma(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})=\\prod_{i=1}^N\\dfrac{1}{1+e^{-y^(i)\\va\\theta\\cdot\\va x}}\\]\n\nGoal: Find \\(\\va\\theta^*\\) such that maximizes the likelihood of the training data: \\[\\va\\theta^*=\\argmax_{\\va\\theta}\\prod_{i=1}^N\\dfrac{1}{1+e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}}}\\]\n\nTake the log: \\(\\prod\\to\\sum\\): \\[\\argmax_{\\va\\theta}\\log\\prod_{i=1}^N\\dfrac{1}{1+e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}}}=\\argmax_{\\va\\theta}\\sum_{i=1}^N\\log\\qty(\\dfrac{1}{1+e^{-y^{(i)\\va\\theta\\cdot\\va x^{(i)}}}})\\]\nTake the negative: \\[\\argmax_{\\va\\theta}\\sum_{i=1}^N\\mathrm{loss}=\\argmin{\\va\\theta}\\qty(\\sum_{i=1}^N-\\log\\qty(\\dfrac{1}{1+e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}}}))=\\argmin_{\\va\\theta}\\sum_{i=1}^N\\log\\qty(1+e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}})\\]\n\n\n\n\n\n\n\n\n\n\nDefinition 1 (Logistic Loss:) \\[\\mathrm{loss}_\\text{log}\\qty(\\va x^{(i)}, y^{(i)};\\va\\theta)=\\log\\qty(1+e^{-y^{(i)}\\va\\theta\\cdot\\va x})\\]\n\n\n\n\n\n\nFigure 2: Logistic Loss\n\n\n\nThis loss is: - continuous - Differentiable, and - Convex\nSo, we can use SGD to minimize it."
  },
  {
    "objectID": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html#sgd-update-rule",
    "href": "notes/cs334/05-Logistic-Regression/05-Logistic-Regression.html#sgd-update-rule",
    "title": "5 Logistic Regression",
    "section": "SGD Update Rule",
    "text": "SGD Update Rule\n\\[\n\\begin{aligned}\n\\grad_{\\va\\theta}\\log\\qty(1+e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}})&=\\dfrac{1}{1+e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}}}\\qty(e^{-y^{(i)}\\va\\theta\\cdot\\va x^{(i)}})\\grad_{\\va\\theta}\\qty(-y^{(i)}\\va\\theta\\cdot\\va x^{(i)})\\\\\n&=\\dfrac{1}{e^{y^{(i)}\\va\\theta\\cdot\\va x^{(i)}}+1}\\qty(-y^{(i)}\\va x^{(i)})\\\\\n&=\\sigma\\qty(-y^{(i)}\\va\\theta\\cdot\\va x^{(i)})\\qty(-y^{(i)}\\va x^{(i)})\\\\\n&=-y^{(i)}\\va x^{(i)}\\qty(1-\\sigma(y^{(i)}\\va\\theta\\cdot\\va x^{(i)})).\n\\end{aligned}\n\\]\nSo, the update rule is: \\[\n\\begin{aligned}\n\\va\\theta^{(k+1)}&=\\va\\theta^{(k)}-\\eta_k\\eval{\\qty[-y^{(i)}\\va x^{(i)}\\qty(1-\\sigma(y^{(i)}\\va\\theta\\cdot\\va x^{(i)}))]}_{\\va\\theta=\\va\\theta^{(k)}}\\\\\n&=\\va\\theta^{(k)}+\\eta_ky^{(i)}\\va x^{(i)}\\qty(1-\\sigma(y^{(i)}\\va\\theta^{(k)}\\cdot\\va x^{(i)}))\n\\end{aligned}\n\\]\n\nThere’s no closed-form solution for logistic regression in general case. However, since the empirical risk function is convex, \\(\\exists\\) unique global minimum. When there are linearly dependent (redundant) feature, there are infinitely many equally good local minima.\nIf the data is linear separable, \\(\\|\\va\\theta\\|=\\infty\\) is bad. So, we need to add regularization."
  },
  {
    "objectID": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html",
    "href": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html",
    "title": "6 Model Selection and Model Assessment",
    "section": "",
    "text": "Given \\(\\hat y=h(\\va x;\\va\\theta)\\) and \\(D=\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N\\), \\(\\va x^{(i)}\\in\\R^d\\) and \\(y^{(i)}\\in\\qty{-1,+1}\\).\n\nMisclassification error: \\[\\dfrac{1}{N}\\sum_{i=1}^N\\1[\\hat y^{(i)}\\neq y^{(i)}].\\]\nAccuracy: \\[\\dfrac{1}{N}\\sum_{i=1}^N\\1[\\hat y^{(i)}=y^{(i)}].\\]\nWhat’s wrong with accuracy: It can be misleading when we have disproportional groups. E.g., rare disease.\n\nConfusion Matrix and Classification Metrics:\n\n\n\n\n\nPredicted (\\(-\\))\nPredicted (\\(+\\))\n\n\n\n\nActual (\\(-\\))\nTrue Negative (TN)\nFalse Positive (FP) Type I Error\n\n\nActual (\\(+\\))\nFalse Negative (FN) Type II Error\nTrue Positive (TP)\n\n\n\n\nAccuracy: \\(\\dfrac{TP+TN}{N}\\)\nSensitivity / True Positive Rate (TRR) / Recall: \\(\\dfrac{TP}{TP+FN}\\).\nSpecificity / True Negative Rate (TNR): \\(\\dfrac{TN}{TN+FP}\\).\nFalse Positive Rate (FPR): \\(\\dfrac{FP}{TN+FP}=1-\\text{specificity}\\).\nPrecision / Positive Predictive Value (PPV): \\(\\dfrac{TP}{TP+FP}\\).\n\n\n\n\n\n\n\n\nRemark 1. If we predict everything to be positive, \\(TN=FB=0\\). Then, - Accuracy: \\(\\dfrac{TP}{N}\\). - Sensitivity: \\(1\\). - Specificity: \\(0\\). - False Positive Rate: \\(1\\). - Precision: \\(\\dfrac{TP}{N}\\).\n\n\n\n\n\nComposite Metrics: Trade-offs:\n\nBalanced Accuracy: mean of sensitivity and specificity. \\[\\dfrac{1}{2}\\qty(\\dfrac{TP}{TP+FN}+\\dfrac{TN}{TN+FP})\\]\nF1 Score: harmonic mean of precision and recall \\[2\\dfrac{\\cdot\\text{Precision}\\cdot\\text{Recall}}{\\text{Precision}+\\text{Recall}}\\]\n\nDiscrimination Thresholds: \n\nReceiver Operating Characteristic (ROC) Curve: TPR vs. FPR. \n\nEach point on the ROC curve corresponds to a threshold / a decision boundary.\nEach point represents a differenet trade-off between FPR and TPR.\nProperties of ROC:\n\nSlope is always upward.\nTwo non-intersecting curves means one model dominate the other.\nPerfect prediction vs. random prediction \nROC shows the trade-off between sensitivity and specificity.\nbut still not a very good summary metric: it is not a single number.\n\n\nAread under the ROC Curve (AUROC, ROC-AUC):\n\nCalculated using the trapezoid rule: sklearn.metrics.auc(x, y).\nIntuitive meaning: Given two randomly chosen examples, one positive and one negative, the probability of ranking positive example higher than the negative example.\n\\(AUC=1\\) for perfect prediction, \\(0.5\\) for random prediction.\n\\(AUC&gt;0.9\\): excellent prediction, but consider information leakage.\n\\(AUC\\approx0.8\\): good prediction.\n\\(AUC&lt;0.5\\): something is rong.\n\nPrecision-Recall Curve and AUPRC:\n\nA high AUPRC represents both higher recall and precision.\nROC curves should be used when there are rounghly equal numbers of observations for each class.\nPrecision-Recall curves may be used when there is a moderate to large class imbalance.\n\n\nClassifier Probability Calibration:\n\nWhen a model produce a probability of positive class, is that number actually a meaningful probability?\nFor example, if my model predicts 90% for a set of examples, does that mean 90% of those examples ahve label \\(+1\\)?\n\nMultiple classes metrics:\n\nAccuracy: \\[ACC=\\dfrac{TP1+TP2+TP3+\\cdots}{Total}\\]\nMacro-average precision: \\[PRE_\\text{macro}=\\dfrac{PRE_1+PRE_2+\\cdots+PRE_n}{n}\\]\nMicro-average precision (should not use): \\[PRE_\\text{micro}=\\dfrac{TP1+TP2+TP3+\\cdots}{TP1+TP2+TP3+\\cdots+FP1+FP2+FP3+\\cdots}\\]"
  },
  {
    "objectID": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#classification-performance",
    "href": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#classification-performance",
    "title": "6 Model Selection and Model Assessment",
    "section": "",
    "text": "Given \\(\\hat y=h(\\va x;\\va\\theta)\\) and \\(D=\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N\\), \\(\\va x^{(i)}\\in\\R^d\\) and \\(y^{(i)}\\in\\qty{-1,+1}\\).\n\nMisclassification error: \\[\\dfrac{1}{N}\\sum_{i=1}^N\\1[\\hat y^{(i)}\\neq y^{(i)}].\\]\nAccuracy: \\[\\dfrac{1}{N}\\sum_{i=1}^N\\1[\\hat y^{(i)}=y^{(i)}].\\]\nWhat’s wrong with accuracy: It can be misleading when we have disproportional groups. E.g., rare disease.\n\nConfusion Matrix and Classification Metrics:\n\n\n\n\n\nPredicted (\\(-\\))\nPredicted (\\(+\\))\n\n\n\n\nActual (\\(-\\))\nTrue Negative (TN)\nFalse Positive (FP) Type I Error\n\n\nActual (\\(+\\))\nFalse Negative (FN) Type II Error\nTrue Positive (TP)\n\n\n\n\nAccuracy: \\(\\dfrac{TP+TN}{N}\\)\nSensitivity / True Positive Rate (TRR) / Recall: \\(\\dfrac{TP}{TP+FN}\\).\nSpecificity / True Negative Rate (TNR): \\(\\dfrac{TN}{TN+FP}\\).\nFalse Positive Rate (FPR): \\(\\dfrac{FP}{TN+FP}=1-\\text{specificity}\\).\nPrecision / Positive Predictive Value (PPV): \\(\\dfrac{TP}{TP+FP}\\).\n\n\n\n\n\n\n\n\nRemark 1. If we predict everything to be positive, \\(TN=FB=0\\). Then, - Accuracy: \\(\\dfrac{TP}{N}\\). - Sensitivity: \\(1\\). - Specificity: \\(0\\). - False Positive Rate: \\(1\\). - Precision: \\(\\dfrac{TP}{N}\\).\n\n\n\n\n\nComposite Metrics: Trade-offs:\n\nBalanced Accuracy: mean of sensitivity and specificity. \\[\\dfrac{1}{2}\\qty(\\dfrac{TP}{TP+FN}+\\dfrac{TN}{TN+FP})\\]\nF1 Score: harmonic mean of precision and recall \\[2\\dfrac{\\cdot\\text{Precision}\\cdot\\text{Recall}}{\\text{Precision}+\\text{Recall}}\\]\n\nDiscrimination Thresholds: \n\nReceiver Operating Characteristic (ROC) Curve: TPR vs. FPR. \n\nEach point on the ROC curve corresponds to a threshold / a decision boundary.\nEach point represents a differenet trade-off between FPR and TPR.\nProperties of ROC:\n\nSlope is always upward.\nTwo non-intersecting curves means one model dominate the other.\nPerfect prediction vs. random prediction \nROC shows the trade-off between sensitivity and specificity.\nbut still not a very good summary metric: it is not a single number.\n\n\nAread under the ROC Curve (AUROC, ROC-AUC):\n\nCalculated using the trapezoid rule: sklearn.metrics.auc(x, y).\nIntuitive meaning: Given two randomly chosen examples, one positive and one negative, the probability of ranking positive example higher than the negative example.\n\\(AUC=1\\) for perfect prediction, \\(0.5\\) for random prediction.\n\\(AUC&gt;0.9\\): excellent prediction, but consider information leakage.\n\\(AUC\\approx0.8\\): good prediction.\n\\(AUC&lt;0.5\\): something is rong.\n\nPrecision-Recall Curve and AUPRC:\n\nA high AUPRC represents both higher recall and precision.\nROC curves should be used when there are rounghly equal numbers of observations for each class.\nPrecision-Recall curves may be used when there is a moderate to large class imbalance.\n\n\nClassifier Probability Calibration:\n\nWhen a model produce a probability of positive class, is that number actually a meaningful probability?\nFor example, if my model predicts 90% for a set of examples, does that mean 90% of those examples ahve label \\(+1\\)?\n\nMultiple classes metrics:\n\nAccuracy: \\[ACC=\\dfrac{TP1+TP2+TP3+\\cdots}{Total}\\]\nMacro-average precision: \\[PRE_\\text{macro}=\\dfrac{PRE_1+PRE_2+\\cdots+PRE_n}{n}\\]\nMicro-average precision (should not use): \\[PRE_\\text{micro}=\\dfrac{TP1+TP2+TP3+\\cdots}{TP1+TP2+TP3+\\cdots+FP1+FP2+FP3+\\cdots}\\]"
  },
  {
    "objectID": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#regression-metrics",
    "href": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#regression-metrics",
    "title": "6 Model Selection and Model Assessment",
    "section": "Regression Metrics",
    "text": "Regression Metrics\nGiven \\(\\hat y=f(\\va x;\\va\\theta)\\) and \\(D=\\qty{\\va x^{(i)}, y^{(i)}}_{i=1}^N\\), \\(x^{(i)}\\in\\R^d\\) and \\(y^{(i)}\\in\\R\\).\n\nMean Squared Error (MSE): \\[MSE=\\dfrac{1}{N}\\sum_{i=1}^N\\qty(\\hat y^{(i)}-y^{(i)})^2\\]\nRoot Mean Squared Error (RMSE): \\[RMSE=\\sqrt{MSE}=\\sqrt{\\dfrac{1}{N}\\sum_{i=1}^N\\qty(\\hat y^{(i)}-y^{(i)})^2}\\]\nMean Absolute Error (MAE): \\[MAE=\\dfrac{1}{N}\\sum_{i=1}^N\\abs{\\hat y^{(i)}-y^{(i)}}\\]\nMean Bias Error (MBE): \\[MBE=\\dfrac{1}{N}\\sum_{i=1}^N\\qty(y^{(i)}-y^(i))\\]"
  },
  {
    "objectID": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#model-assessment-process",
    "href": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#model-assessment-process",
    "title": "6 Model Selection and Model Assessment",
    "section": "Model Assessment Process",
    "text": "Model Assessment Process\n\nHouldout: forming a test set:\n\nHold out some data (i.e., test data) that are not used for training the modedl.\nProxy for “everything you might see.”\nProcedure:\n\nOn training data, we train our model.\nOn test data, we use the model to make predictions.\nWe compare the predictions with the true labels to get the performance.\n\nProblem of holdout:\n\nToo few data for traiing: unable to properly learn from the data\nToo few for testing: bad approximation of the true error\nRule of thumb: enough test samples to form a reasonable estimate.\nCommon split size is \\(70\\%-30\\%\\) or \\(80\\%-20\\%\\).\n\n\nQuestion: what to do if we don’t have enough data? \\(K\\)-Fold Cross Validation (CV):\n\nUse all the data to train / test (but don’t use all data to train at the same time).\nProcesudre:\n\nSplit the data into \\(K\\) parts or “folds.”\nTrain on all but the \\(k\\)-th part and test / validate on the \\(k\\)-th part.\nRepeat for each \\(k=1,2,\\ldots,K\\).\nReport average performance over \\(K\\) experiments.\n\nCommon values of \\(K\\):\n\n\\(K=2\\): two-fold cross validation.\n\\(K=5\\) or \\(K=10\\): 5-fold or 10-fold cross validation – common choices.\n\\(K=N\\): leave-one-out cross validation (LOOCV).\n\nThe choice of \\(K\\) is based on how much data we have.\n\nMonte-Carlo Cross Validation:\n\nAKA repeated random sub-sampling validation.\nProcedure:\n\nRandomly select (without replacement) some fraction of the data to form training set.\nAssign rest to test set.\nRepeat multiple times with different partitions.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nHow many possible partitions do we see?\nHow many models do we need to train?\nWhat is the final model?\nHow to get error estimates?\n\n\n\n\nHoldout\n\\(1\\)\n\\(1\\)\nThe model\nBootstrapping\n\n\n\\(K\\)-Fold CV\n\\(K\\)\n\\(K\\)\nAverage of \\(K\\) models\nAverage of \\(K\\) error estimates\n\n\nMonte-Carlo CV\nas many as possible\nas many as possible\nAverage of all models\nAverage of all error estimates\n\n\n\n\nBootstrapping to find Confidence Intervals:\n\nSample with replacement \\(N\\) times.\nCalculate performance metric on each boostrap iterate.\nThe 95% confidence interval is the \\(2.5\\)-th and \\(97.5\\)-th percentile of the boostrap distribution."
  },
  {
    "objectID": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#model-selection",
    "href": "notes/cs334/06-Model-Assessment-and-Model-Selection/06-Model-Assessment-and-Model-Selection.html#model-selection",
    "title": "6 Model Selection and Model Assessment",
    "section": "Model Selection",
    "text": "Model Selection\nGoal: selecting the proper level of flexibility for a model (e.g., regularization strength in logistic regression)\n\nSelect hyperparameters of the model: “meta-optimization”\n\nRegularization strength\nRegularization type\nLoss function\nPolynomial degree\nKernal type\n\nDifferent from model parameters:\n\nFeature coefficients\n\nSimple, popular solution: \\(K\\)-fold CV for Hyperparameter Selection\nAssessment + Selection Guidelines:\n\nDo not use same samples to choose optimal hyperparameters and to estimate test / generalization error.\nChoice of methodology will depend on your problem and dataset.\n\nThree-way split:\n\nTraining set: to train the model\nValidation set: to select hyperparameters\nTest set: to estimate generalization error\n\nHoldout + \\(K\\)-Fold CV:\n\nHoldout: test dataset to assess the performance.\nTraining set: use \\(K\\)-fold CV to find optimal hyperparameters.\nUse optimal hyperparameters to train on the training data and assess on test.\n\nNested CV:\n\nOuter \\(K\\)-fold loop: assess the performance.\nInner \\(K\\)-fold loop: choose the optimal hyperparameters.\n\n\n\n\n\n\n\n\nTip 1: An Example in sklearn\n\n\n\n\n\nMost commonly used function/classes: train_test_split, KFold, and StratifiedKFold.\n# generate an 80-10-10 train-validation-test three-way split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\nX_test, X_val, y_test, y_val = train_test_split(X_train, y_train, test_size=1/9)\n\n# generate a 4-fold CV in a for-loop\n# stratified k-foldL maintains label proportions\nfrom sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5)\nfor train_idx, test_idx in skf.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n\n\n\n\nHyperparameter Search Space:\n\nGrid Search CV: exhaustive search for the best hyperparameter values using cross validation. sklearn.model_selection.GridSearchCV.\nRandomized Search CV: random search over hyperparameters. sklearn.model_selection.RandomizedSearchCV."
  },
  {
    "objectID": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html",
    "href": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html",
    "title": "7 Feature Selection and Kernels",
    "section": "",
    "text": "Types of Variables:\n\nNumerical: Discrete / Continuous.\nCategorical\nOrdinal: categocial with order. E.g., Temperature: Low, Medium, High.\n\nDiscretization of Numerical Features (Quantization / Bining)\n\nNumerical \\(\\to\\) Categorical\n\nE.g., age: \\([18,25], (25, 45], (45, 65], (65, 85], &gt;85\\) or binary: \\(\\leq 65, &gt;65\\)\n\nWhy? Allow a linear model to learn nonlinear relationships\n\nMissing data:\n\nDepend on how missing they are:\n\nDrop examples with missing values\nDrop features with missing values\n\nImputation approaches:\n\nUnivariate imputation\nMultivariate imputation\nNearest neighbor imputation\nMissing indicators\n\n\nTime Series Data:\n\nSummary statistics:\n\nmean, std\nmin, median, max, Q1, Q3\ncumulative sum\ncount\ncount above/below threshold\n\nTrend:\n\nlinear slopes\npiece-wise slopes\n\nPeriodic trends: fast fourier transform"
  },
  {
    "objectID": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html#feature-engineering",
    "href": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html#feature-engineering",
    "title": "7 Feature Selection and Kernels",
    "section": "",
    "text": "Types of Variables:\n\nNumerical: Discrete / Continuous.\nCategorical\nOrdinal: categocial with order. E.g., Temperature: Low, Medium, High.\n\nDiscretization of Numerical Features (Quantization / Bining)\n\nNumerical \\(\\to\\) Categorical\n\nE.g., age: \\([18,25], (25, 45], (45, 65], (65, 85], &gt;85\\) or binary: \\(\\leq 65, &gt;65\\)\n\nWhy? Allow a linear model to learn nonlinear relationships\n\nMissing data:\n\nDepend on how missing they are:\n\nDrop examples with missing values\nDrop features with missing values\n\nImputation approaches:\n\nUnivariate imputation\nMultivariate imputation\nNearest neighbor imputation\nMissing indicators\n\n\nTime Series Data:\n\nSummary statistics:\n\nmean, std\nmin, median, max, Q1, Q3\ncumulative sum\ncount\ncount above/below threshold\n\nTrend:\n\nlinear slopes\npiece-wise slopes\n\nPeriodic trends: fast fourier transform"
  },
  {
    "objectID": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html#feature-selection",
    "href": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html#feature-selection",
    "title": "7 Feature Selection and Kernels",
    "section": "Feature Selection",
    "text": "Feature Selection\n\nMotivation:\n\nWhen having few examples, but a learge number of features (\\(d\\gg N\\)), it becomes very easy to overfit the model.\nWe need to remove uninformative features.\n\nMethods:\n\nFilter method: before model fitting\nWrapper method: after model fitting\nEmbedded method: during model fitting\n\nFilter Method: preprocessing*\n\nRank individual features according to some statistical measure\nFilter out features that fall below a certain threshold\n\nE.g., sample variance, Person’s correlation coerfficient between feature and label, Mutal information, \\(\\chi^2\\)-statistic for categorical/ordinal features.\n\n\nWrapper Method: Search\n\nView feature selection as a model selection problem\nWhich feature to use: hyperparameter\n\nE.g,b Brute-force, exhausitve search: If we have \\(d\\) features, there are \\(2^d-1\\) possible combinations. Computatianlly infeasible.\nGreedy search: Forward selection, backward elimination.\n\nForward selection:\n\n\n\\begin{algorithm} \\caption{Forward Selection} \\begin{algorithmic} \\State initialize $F$ to the set of all features \\State initialize $S$ to the empty set $\\qquad$\\Comment{Start with $0$ features} \\For{$i=1:d-1$} \\For{ each feature $f\\in F$} \\State frain model using $(S, f)$ \\State evaluate model \\EndFor \\State Select best set $\\qty{S, f^*}$. $S=S+F^*$, and $F=F-f^*$ \\EndFor \\end{algorithmic} \\end{algorithm}\n\n\n\nThis algorithm has complexity \\(\\sim\\bigO(d^2)\\).\n\nBackward elimination:\n\n\n\\begin{algorithm} \\caption{Forward elimination} \\begin{algorithmic} \\State initialize $F$ to the set of all features \\For{$i=1:d-1$} \\State $S=$ set of all subsets of $F$ of size $d-i$. $\\qquad$\\Comment{Start with $d$ features} \\For{ each subset $s\\in S$} \\State train model using $s$ \\State evaluate model \\EndFor \\State Select best subset $s^*$, and $F=s^*$ \\EndFor \\end{algorithmic} \\end{algorithm}\n\n\n\nThis algorithm has complexity \\(\\sim\\bigO(d^2)\\). However, forward selection is less computationally expensive because we train more smaller modedls.\n\n\nEmbedded Method: Regularization\n\nIncorporate feature selection as part of the model fitting process\nUse \\(L_1\\) (LASSO) regularization\n\n\n\n\n\n\n\n\n\n\n\n\nFilter\nWrapper\nEmbedded\n\n\n\n\nComputational Cost\nFast. Only run once scalable to high dimension\nSlow\nBetween filter and wrapper\n\n\nModel/Algorithm Specific\nGeneric, agnostic to models and algorithms\nSpecific, considers model performance\nOnly applies to specific model / algorithms\n\n\nOverfitting\nUnlikely\nHigher risk of overfitting\nRegualrization controls overfitting\n\n\n\n\nIn practice, we use combinations of these methods."
  },
  {
    "objectID": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html#fitting-nonlinear-functions-kernel-methods",
    "href": "notes/cs334/07-Feature-Selection-and-Kernels/07-Feature-Selection-and-Kernels.html#fitting-nonlinear-functions-kernel-methods",
    "title": "7 Feature Selection and Kernels",
    "section": "Fitting Nonlinear Functions – Kernel Methods",
    "text": "Fitting Nonlinear Functions – Kernel Methods\n\nQuestion: How can we use linear models to learn nonlinear trends?\n\nMap to higher order dimensions: e.g., \\(\\mqty[1&x&x^2&\\cdots&x^m]\\)\n\nFor example, classification:\n\n\n\n\n\n\nFigure 1: Higher Dimensional Classification\n\n\n\n\nLet \\(\\va x=\\mqty[x_1&x_2]^\\top\\) and \\(\\phi(\\va x)=\\mqty[1&x_1&x_2&x_1x_2&x_1^2&x_2^2]^\\top\\).\nFind a linear classifier such that \\(\\va\\theta\\cdot\\phi(\\va x)=0\\) that perfectlly separates the two classes.\nEquation of a circle: \\((x-h)^2+(y-k)^2=r^2\\).\nIn this example, \\((x_1-2)+(x_2-2)^2=1\\). So, \\(7-4x_1-4x_2+x_1^2+x_2^2=0\\).\nTherfore, \\(\\phi(\\va x)=\\mqty[1&x_1&x_2&x_1x_2&x_1^2&x_2^2]^\\top\\) and \\(\\va\\theta=\\mqty[7&-4&-4&0&1&1]^\\top\\).\nBut, we don’t want to use this method. Why?\n\nBecause dimension will blow-up. Suppose \\(\\va x\\in\\R^d\\) and \\(\\phi(\\va x)\\in\\R^p\\). Then, \\[p=\\text{number of first and second order terms}=(d+1)+\\dfrac{d(d+1)}{2}\\sim\\bigO(d^2).\\]\nWe have \\(p\\gg d\\). It’s also likely that \\(p\\gg N\\).\nIn perceptron algorithm, our update complexity will then be \\(\\sim\\bigO(p)=\\bigO(d^2)\\), which is inefficient.\n\n\nKey Observation:\n\nIf we initialize \\(\\va\\theta^{(k)}=\\va 0\\), then \\(\\va\\theta^{(k)}\\) is always in the span of feature vectors and can be expressed to linear combination of feature vectors: \\[\\va\\theta^{(k)}=\\sum_{i=1}^N\\alpha_i\\va x^{(i)}\\quad\\text{for some }\\alpha_1,\\alpha_2,\\dots,\\alpha_N.\\]\nThen, we can rewrite the classifier to get \\[\\begin{aligned}h(\\va x;\\va\\theta)&=\\operatorname{sign}(\\va\\theta\\cdot\\va x)\\\\&=\\operatorname{sign}\\qty(\\qty(\\sum_{i=1}^N\\alpha_i\\va x^{(i)})\\cdot\\va x)\\\\&=\\operatorname{sign}\\qty(\\sum_{i=1}^N\\alpha_i\\va x^{(i)}\\cdot\\va x).\\end{aligned}\\]\nEven if we are in higher dimensional feature space: \\[h(\\phi(\\va x);\\va\\theta)=\\operatorname{sign}\\qty(\\sum_{i=1}^N\\alpha_i\\qty(\\phi(\\va x^{(i)})\\cdot\\phi(\\va x))).\\]\nClassifiers now is written in \\(\\alpha_i\\) (\\(N\\)-dimensional) space, not in \\(\\va x\\) (\\(d\\)-dimensional) space.\nThen, the update rule is \\[\\alpha_i^{(k+1)}=\\alpha_i^{(k)}+y^{(i)}.\\]\n\n\n\n\n\\begin{algorithm} \\caption{New Perceptron} \\begin{algorithmic} \\State $\\va\\alpha^{(0)}=\\va 0\\in\\R^N$, $k=0$ \\While{not converged} \\For{$i=1,\\dots,N$} \\If{$y^{(i)}\\qty(\\sum_{j=1}^N\\alpha_j\\phi(\\va x^{(i)})\\cdot\\phi(\\va x^{(j)}))\\leq 0$} \\State $\\alpha_{i}^{(k+1)}=\\alpha_i^{(k)}+y^{(i)}$ \\State $\\alpha_j^{(k+1)}=\\alpha_j^{(k)}$ when $j\\neq i$ \\State $k++$ \\EndIf \\EndFor \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\n\n\\(\\phi(\\va x^{(i)})\\cdot\\phi(\\va x^{(j)})\\) can be pre-computed. Complexity is \\(\\bigO(N^2p)\\)\nThe update complexity \\(\\bigO(1)\\).\nHow can we speed up dot product \\(\\phi(\\va x)\\cdot\\phi(\\va x')\\)? We can calculate the dot producrt \\(\\phi(\\va x)\\cdot\\phi(\\va x')\\) withtout calculating \\(\\phi(\\va x)\\) and \\(\\phi(\\va x')\\).\n\n\n\n\n\n\n\n\nExample 1 Suppose \\(\\phi(\\va x)=\\mqty[x_1^2&x_2^2&\\sqrt{2}x_1x_2]^\\top\\). Then, \\[\n\\begin{aligned}\n\\phi(\\va u)\\cdot\\phi(\\va v)&=\\mqty[u_1^2&u_2^2&\\sqrt{2}u_1u_2]^\\top\\cdot\\mqty[v_1^2&v_2^2&\\sqrt{2}v_1v_2]^\\top\\\\\n&=u_1^2v_1^2+u_2v_2^2+2u_1u_2v_1v_2\\\\\n&=(u_1v_1+u_2v_2)^2\\\\\n&=\\qty(\\va u\\cdot\\va v)^2.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1 (Kernel Function) Kernel function is an implicit feature mapping that allows us to compute the dot product in the feature space without explicitly computing the feature vectors. \\[K:\\underbrace{\\R^d\\times\\R^d}_\\text{feature vectors}\\to\\R\\]\n\n\n\n\n\n\n\n\n\n\n\nTheorem 1 (Common Kernels:)  \n\nLinear Kernel: \\[K\\qty(\\va x^{(i)},\\va x^{(j)})=\\va x^{(i)}\\cdot\\va x^{(j)}.\\]\nPolynomial Kernel: \\[K\\qty(\\va x^{(i)},\\va x^{(j)})=\\qty(\\va x^{(i)}\\cdot\\va x^{(j)}+1)^d.\\]\nRadial Basis Function (RBF) Kernel: infinite-dimensional feature space \\[\\begin{aligned}K_\\text{RBF}(\\va u,\\va v)&=\\exp\\qty(-\\gamma\\norm{\\va u-\\va v}^2)\\\\&=C\\sum_{n=0}^\\infty\\dfrac{K_{\\operatorname{poly}(n)}(\\va u,\\va v)}{n!}\\end{aligned}\\]\n\n\n\n\n\n\n\n\\begin{algorithm} \\caption{Kernelized Perceptron} \\begin{algorithmic} \\State $\\alpha_j^{(0)}=0$, $k=0$ \\While{not converged} \\For{$i=1,\\dots,N$} \\If{$y^{(i)}\\qty(\\sum_{j=1}^N\\alpha_j^{(k)}K(\\va x^{(j)}, \\va x^{(i)}))\\leq 0$} \\State $\\alpha_{i}^{(k+1)}=\\alpha_i^{(k)}+y^{(i)}$ \\State $\\alpha_j^{(k+1)}=\\alpha_j^{(k)}$ when $j\\neq i$ \\State $k++$ \\EndIf \\EndFor \\EndWhile \\end{algorithmic} \\end{algorithm}"
  },
  {
    "objectID": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html",
    "href": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html",
    "title": "8 Decision Trees and Random Forest",
    "section": "",
    "text": "Interpretability: Given a linear classifier dinfed by \\(\\va\\theta=[\\theta_1,\\theta_2,\\dots,\\theta_d]\\). How can we interpret the meaning of each parameter/coefficient? \\[\\norm{\\theta_i}\\text{: how this feature contributes to the decision.}\\] To fit nonlinear model, we can use kernels. However, with kernels, the fitted parameter \\(\\va\\theta\\) becomes a blackbox, and we lose interpretability (especially when we use RBF kernels, \\(\\va\\theta\\in\\R^\\infty\\)).\nA different approach: Decision Tree \\[f:\\mathcal{X}\\to\\mathcal{Y}\\]\n\nBoth features (\\(\\mathcal{X}\\)) and labels (\\(\\mathcal{Y}\\)) can be a continuous, descrete, or binary value.\n\n\n\n\n\n\n\n\n\nExample 1 (Forming a Decision Tree) Suppose \\(\\va x\\in\\qty{0,1}^2\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(y\\)\n\n\n\n\n1\n1\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n0\n0\n0\n\n\n\n\n\n\n\n\n\nFigure 1: Decision Tree\n\n\n\n\n\n\n\n\nWe can use a boolean function of input feature to represent a decision tree.\n\n\n\n\n\n\n\n\nRemark 1. \n\nAs the number of nodes increases, the hypothesis space grows.\nTrivial solution: each examples has its own leaf node. If \\(\\va x\\in\\qty{0,1}^d\\), then we have \\(2^d\\) leaf nodes.\nProblem: overffing, unlikely to generalize to unseen examples.\n\n\n\n\n\n\nGoal: Find the smallest tree that performs well on training data.\n\nHowever, finding the optimal partition of the data is NP-complete (hard).\nInstead, we can use a greedy appraoch:\n\nStart with empty tree.\nFind best feature to split on.\nRecursively build branches into subtree.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2 (How to Find the Best Split) We want to predict whether ot not a flight will get delayed: \\[\\text{training data: }\\begin{cases}29\\text{ positive}\\\\35\\text{ negative}\\end{cases}\\implies[29^+, 35^-].\\] Suppose \\(\\va x=[x_1,x_2]\\) are two binary features:\n\n\n\n\n\n\nFigure 2: First Slipt\n\n\n\nSplitting by snow is better because it produces more certain labels. But, how do we measure uncertainty?\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1 (Shannon’s Entropy) Let \\(D_N\\) be the training data, \\(y\\in\\qty{-1,+1}\\) be the binary outcome/label.\n\n\\(\\P_\\oplus\\): fraction of positive examples\n\\(\\P_\\ominus\\): fraction of negative examples \\[\\text{Entropy of }D_N=-\\qty\\Big(\\P_\\oplus\\log_2\\P_\\oplus+\\P_\\ominus\\log_2\\P_\\ominus)\\]\nThe definition uses \\(\\log_2\\) because entropy is measured in bits.\nIt measures the expected number of bits needed to encode a randomly drawn value of \\(y\\).\n\n\n\n\n\n\n\nFigure 3: Plot of Entropy\n\n\n\n\nMore generally, for categorical outcome \\(y\\in\\qty{y_1,y_2,\\dots,y_k}\\), \\[\n\\begin{aligned}\nH(y)&=-\\qty\\Big(\\P(Y=y_1)\\log_2\\P(Y=y_1)+\\P(Y=y_2)\\log_2\\P(Y=y_2)+\\cdots+\\P(Y=y_k)\\log_2\\P(Y=y_k))\\\\\n&=-\\sum_{i=1}^k\\P(Y=y_i)\\log_2\\P(Y=y_i)\n\\end{aligned}\n\\]\nNote: entropy is usually positive as \\(\\log_2\\P(Y=y_i)\\) is negative.\n\n\n\n\n\n\nEntropy and Peakyness:\n\nImagine rolling a die and plotting the empirical distribution: \n\nOn the left: high entropy, more uncertain about the label, less peaky distribution\nOn the right: low entropy, less uncertain about the label, more peaky distribution\n\n\n\n\n\n\n\n\n\n\nDefinition 2 (Conditional Entropy) \\[H(Y\\mid X=x)=-\\qty(\\sum_{i=1}^k\\P(Y=y_i\\mid X=x)\\log_2\\P(Y=y_i\\mid X=x))\\] \\[H(Y\\mid X)=\\sum_{x\\in X}\\P(X=x)\\cdot H(Y\\mid X=x)\\]\n\n\\(H(Y\\mid X)\\) shows the average surprise of \\(Y\\) when \\(X\\) is known.\n\n\n\n\n\n\n\n\n\n\n\n\nRemark 2. \n\nWhen does \\(H(Y\\mid X)=0\\)? When \\(Y\\) is completely determined by \\(X\\).\nWhen does \\(H(Y\\mid X)=H(Y)\\)? When \\(Y\\independ X\\).\nWe can use conditional entropy to measure the quality of a split:\n\nIdea: if knowing \\(x_1\\) reduces uncertainty more than knowing \\(x_2\\), we should split by \\(x_1\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 3 (Information Gain (IG) / Mutual Information) \\[\nIG(X;Y)=H(Y)-H(Y\\mid X),\n\\]\n\nwhere \\(H(Y)\\) is the entropy of parent node, and \\(H(Y\\mid X)\\) is the average entropy of the children note.\n\\(IG\\) measures the amount of information we learn about \\(Y\\) by knowing the value of \\(C\\) (and vice versa \\(\\implies\\) symmetric).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3 (Back to the Example) We want to predict whether ot not a flight will get delayed: \\[\\text{training data: }\\begin{cases}29\\text{ positive}\\\\35\\text{ negative}\\end{cases}\\implies[29^+, 35^-].\\] Suppose \\(\\va x=[x_1,x_2]\\) are two binary features:\n\n\n\n\n\n\nFigure 4: First Slipt\n\n\n\n\nCalculate entropy of \\(y\\): \\[H(y)=-\\qty(\\dfrac{29}{64}\\log_2\\dfrac{29}{64}+\\dfrac{35}{64}\\log_2\\dfrac{35}{64})\\approx0.9937\\]\nCalcualte the conditional entropy for each feature: \\[\n\\begin{aligned}\nH(y\\mid x_1)&=\\dfrac{26}{64}\\qty(-\\dfrac{21}{26}\\log_2\\dfrac{21}{26}-\\dfrac{5}{26}\\log_2\\dfrac{5}{26})+\\dfrac{38}{64}\\qty(-\\dfrac{8}{38}\\log_2\\dfrac{8}{38}-\\dfrac{30}{38}\\log_2\\dfrac{30}{38})\\\\\n&=0.7278\\\\\\\\\nH(y\\mid x_2)&=\\dfrac{45}{64}\\qty(-\\dfrac{18}{45}\\log_2\\dfrac{18}{45}-\\dfrac{27}{45}\\log_2\\dfrac{27}{45})+\\dfrac{19}{64}\\qty(-\\dfrac{11}{19}\\log_2\\dfrac{11}{19}-\\dfrac{8}{19}\\log_2\\dfrac{8}{19})\\\\\n&=0.9742.\n\\end{aligned}\n\\]\nCalcualte the information gain: \\[\n\\begin{aligned}\nIG(x_1;y)&=0.9937-0.7278=0.2659\\\\\nIG(x_2;y)&=0.9937-0.9742=0.0195.\n\\end{aligned}\n\\] So, \\(IG(x_1;y)&gt;IG(x_2;y)\\), \\(x_1\\) is a better split.\n\n\n\n\n\n\nAnother Measure of Uncertainty: Gini Index and Gini Gain: \\[\n\\begin{aligned}\n\\text{Gini}(Y)&=\\sum_{k=1}^k\\P(Y=y_k)\\qty(1-\\P(Y=y_k))=1-\\sum_{k=1}^k\\P(Y=y_k)^2\\\\\n\\text{GiniGain}(X;Y)&=\\text{Gini}(Y)-\\sum_{x\\in X}\\P(X=x)\\text{Gini}(Y\\mid X=x).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nRemark 3. In practice, using \\(IG\\) or \\(\\text{GiniGain}\\) may lead to different results, but it is unclear how different it can be.\n\n\n\n\n\n\nFigure 5: Gini Index and Entropy Plot\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\arg\\max_{j=1,\\dots,d}IG(x_j;y)&=\\arg\\max_j H(y)-H(y\\mid x_j)\\\\\n&=\\arg\\min_j H(y\\mid x_j).\n\\end{aligned}\n\\]\n\nWhen to stop growing a tree? (Stopping Criteria)\n\nWhen all record have the same label (assume no noise).\nIf all record have identical features (no further splits possible).\n\n\n\n\n\n\n\n\n\nRemark 4. We should not stop when all stributtes have \\(0\\ IG\\). See Example 1.\n\n\n\n\n\n\n\\begin{algorithm} \\caption{Building Decision Tree} \\begin{algorithmic} \\Procedure{BuildTree}{$DS$} \\IF{$y^{(i)}==y$ for all examples in $DS$} \\Return{$y$} \\ElseIf{$x^{(i)}==x$ for all examples in $DS$} \\Return{majority label} \\Else \\State $x_s=\\argmin_x H(y\\mid x)$ \\For{each value $v$ of $x_s$} \\State $DS_y=\\qty{\\text{examples in }DS\\text{ where }x_s=v}$ \\State BuildTree($DS_y$)$\\qquad$\\Comment{recursive function} \\EndFor \\EndIf \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\n\nHow do we avoid overfitting? We want simpler trees.\n\nSet a maximum depth\nMeasure performance on validation data. If growing tree results in worse performance, stop.\nPost-prune: grow entire/full tree and then greedily remove nodes that affect validation error the least."
  },
  {
    "objectID": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html#decision-tree",
    "href": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html#decision-tree",
    "title": "8 Decision Trees and Random Forest",
    "section": "",
    "text": "Interpretability: Given a linear classifier dinfed by \\(\\va\\theta=[\\theta_1,\\theta_2,\\dots,\\theta_d]\\). How can we interpret the meaning of each parameter/coefficient? \\[\\norm{\\theta_i}\\text{: how this feature contributes to the decision.}\\] To fit nonlinear model, we can use kernels. However, with kernels, the fitted parameter \\(\\va\\theta\\) becomes a blackbox, and we lose interpretability (especially when we use RBF kernels, \\(\\va\\theta\\in\\R^\\infty\\)).\nA different approach: Decision Tree \\[f:\\mathcal{X}\\to\\mathcal{Y}\\]\n\nBoth features (\\(\\mathcal{X}\\)) and labels (\\(\\mathcal{Y}\\)) can be a continuous, descrete, or binary value.\n\n\n\n\n\n\n\n\n\nExample 1 (Forming a Decision Tree) Suppose \\(\\va x\\in\\qty{0,1}^2\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(y\\)\n\n\n\n\n1\n1\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n0\n0\n0\n\n\n\n\n\n\n\n\n\nFigure 1: Decision Tree\n\n\n\n\n\n\n\n\nWe can use a boolean function of input feature to represent a decision tree.\n\n\n\n\n\n\n\n\nRemark 1. \n\nAs the number of nodes increases, the hypothesis space grows.\nTrivial solution: each examples has its own leaf node. If \\(\\va x\\in\\qty{0,1}^d\\), then we have \\(2^d\\) leaf nodes.\nProblem: overffing, unlikely to generalize to unseen examples.\n\n\n\n\n\n\nGoal: Find the smallest tree that performs well on training data.\n\nHowever, finding the optimal partition of the data is NP-complete (hard).\nInstead, we can use a greedy appraoch:\n\nStart with empty tree.\nFind best feature to split on.\nRecursively build branches into subtree.\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2 (How to Find the Best Split) We want to predict whether ot not a flight will get delayed: \\[\\text{training data: }\\begin{cases}29\\text{ positive}\\\\35\\text{ negative}\\end{cases}\\implies[29^+, 35^-].\\] Suppose \\(\\va x=[x_1,x_2]\\) are two binary features:\n\n\n\n\n\n\nFigure 2: First Slipt\n\n\n\nSplitting by snow is better because it produces more certain labels. But, how do we measure uncertainty?\n\n\n\n\n\n\n\n\n\n\n\nDefinition 1 (Shannon’s Entropy) Let \\(D_N\\) be the training data, \\(y\\in\\qty{-1,+1}\\) be the binary outcome/label.\n\n\\(\\P_\\oplus\\): fraction of positive examples\n\\(\\P_\\ominus\\): fraction of negative examples \\[\\text{Entropy of }D_N=-\\qty\\Big(\\P_\\oplus\\log_2\\P_\\oplus+\\P_\\ominus\\log_2\\P_\\ominus)\\]\nThe definition uses \\(\\log_2\\) because entropy is measured in bits.\nIt measures the expected number of bits needed to encode a randomly drawn value of \\(y\\).\n\n\n\n\n\n\n\nFigure 3: Plot of Entropy\n\n\n\n\nMore generally, for categorical outcome \\(y\\in\\qty{y_1,y_2,\\dots,y_k}\\), \\[\n\\begin{aligned}\nH(y)&=-\\qty\\Big(\\P(Y=y_1)\\log_2\\P(Y=y_1)+\\P(Y=y_2)\\log_2\\P(Y=y_2)+\\cdots+\\P(Y=y_k)\\log_2\\P(Y=y_k))\\\\\n&=-\\sum_{i=1}^k\\P(Y=y_i)\\log_2\\P(Y=y_i)\n\\end{aligned}\n\\]\nNote: entropy is usually positive as \\(\\log_2\\P(Y=y_i)\\) is negative.\n\n\n\n\n\n\nEntropy and Peakyness:\n\nImagine rolling a die and plotting the empirical distribution: \n\nOn the left: high entropy, more uncertain about the label, less peaky distribution\nOn the right: low entropy, less uncertain about the label, more peaky distribution\n\n\n\n\n\n\n\n\n\n\nDefinition 2 (Conditional Entropy) \\[H(Y\\mid X=x)=-\\qty(\\sum_{i=1}^k\\P(Y=y_i\\mid X=x)\\log_2\\P(Y=y_i\\mid X=x))\\] \\[H(Y\\mid X)=\\sum_{x\\in X}\\P(X=x)\\cdot H(Y\\mid X=x)\\]\n\n\\(H(Y\\mid X)\\) shows the average surprise of \\(Y\\) when \\(X\\) is known.\n\n\n\n\n\n\n\n\n\n\n\n\nRemark 2. \n\nWhen does \\(H(Y\\mid X)=0\\)? When \\(Y\\) is completely determined by \\(X\\).\nWhen does \\(H(Y\\mid X)=H(Y)\\)? When \\(Y\\independ X\\).\nWe can use conditional entropy to measure the quality of a split:\n\nIdea: if knowing \\(x_1\\) reduces uncertainty more than knowing \\(x_2\\), we should split by \\(x_1\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 3 (Information Gain (IG) / Mutual Information) \\[\nIG(X;Y)=H(Y)-H(Y\\mid X),\n\\]\n\nwhere \\(H(Y)\\) is the entropy of parent node, and \\(H(Y\\mid X)\\) is the average entropy of the children note.\n\\(IG\\) measures the amount of information we learn about \\(Y\\) by knowing the value of \\(C\\) (and vice versa \\(\\implies\\) symmetric).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3 (Back to the Example) We want to predict whether ot not a flight will get delayed: \\[\\text{training data: }\\begin{cases}29\\text{ positive}\\\\35\\text{ negative}\\end{cases}\\implies[29^+, 35^-].\\] Suppose \\(\\va x=[x_1,x_2]\\) are two binary features:\n\n\n\n\n\n\nFigure 4: First Slipt\n\n\n\n\nCalculate entropy of \\(y\\): \\[H(y)=-\\qty(\\dfrac{29}{64}\\log_2\\dfrac{29}{64}+\\dfrac{35}{64}\\log_2\\dfrac{35}{64})\\approx0.9937\\]\nCalcualte the conditional entropy for each feature: \\[\n\\begin{aligned}\nH(y\\mid x_1)&=\\dfrac{26}{64}\\qty(-\\dfrac{21}{26}\\log_2\\dfrac{21}{26}-\\dfrac{5}{26}\\log_2\\dfrac{5}{26})+\\dfrac{38}{64}\\qty(-\\dfrac{8}{38}\\log_2\\dfrac{8}{38}-\\dfrac{30}{38}\\log_2\\dfrac{30}{38})\\\\\n&=0.7278\\\\\\\\\nH(y\\mid x_2)&=\\dfrac{45}{64}\\qty(-\\dfrac{18}{45}\\log_2\\dfrac{18}{45}-\\dfrac{27}{45}\\log_2\\dfrac{27}{45})+\\dfrac{19}{64}\\qty(-\\dfrac{11}{19}\\log_2\\dfrac{11}{19}-\\dfrac{8}{19}\\log_2\\dfrac{8}{19})\\\\\n&=0.9742.\n\\end{aligned}\n\\]\nCalcualte the information gain: \\[\n\\begin{aligned}\nIG(x_1;y)&=0.9937-0.7278=0.2659\\\\\nIG(x_2;y)&=0.9937-0.9742=0.0195.\n\\end{aligned}\n\\] So, \\(IG(x_1;y)&gt;IG(x_2;y)\\), \\(x_1\\) is a better split.\n\n\n\n\n\n\nAnother Measure of Uncertainty: Gini Index and Gini Gain: \\[\n\\begin{aligned}\n\\text{Gini}(Y)&=\\sum_{k=1}^k\\P(Y=y_k)\\qty(1-\\P(Y=y_k))=1-\\sum_{k=1}^k\\P(Y=y_k)^2\\\\\n\\text{GiniGain}(X;Y)&=\\text{Gini}(Y)-\\sum_{x\\in X}\\P(X=x)\\text{Gini}(Y\\mid X=x).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nRemark 3. In practice, using \\(IG\\) or \\(\\text{GiniGain}\\) may lead to different results, but it is unclear how different it can be.\n\n\n\n\n\n\nFigure 5: Gini Index and Entropy Plot\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\arg\\max_{j=1,\\dots,d}IG(x_j;y)&=\\arg\\max_j H(y)-H(y\\mid x_j)\\\\\n&=\\arg\\min_j H(y\\mid x_j).\n\\end{aligned}\n\\]\n\nWhen to stop growing a tree? (Stopping Criteria)\n\nWhen all record have the same label (assume no noise).\nIf all record have identical features (no further splits possible).\n\n\n\n\n\n\n\n\n\nRemark 4. We should not stop when all stributtes have \\(0\\ IG\\). See Example 1.\n\n\n\n\n\n\n\\begin{algorithm} \\caption{Building Decision Tree} \\begin{algorithmic} \\Procedure{BuildTree}{$DS$} \\IF{$y^{(i)}==y$ for all examples in $DS$} \\Return{$y$} \\ElseIf{$x^{(i)}==x$ for all examples in $DS$} \\Return{majority label} \\Else \\State $x_s=\\argmin_x H(y\\mid x)$ \\For{each value $v$ of $x_s$} \\State $DS_y=\\qty{\\text{examples in }DS\\text{ where }x_s=v}$ \\State BuildTree($DS_y$)$\\qquad$\\Comment{recursive function} \\EndFor \\EndIf \\EndProcedure \\end{algorithmic} \\end{algorithm}\n\n\n\nHow do we avoid overfitting? We want simpler trees.\n\nSet a maximum depth\nMeasure performance on validation data. If growing tree results in worse performance, stop.\nPost-prune: grow entire/full tree and then greedily remove nodes that affect validation error the least."
  },
  {
    "objectID": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html#forming-a-decision-tree",
    "href": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html#forming-a-decision-tree",
    "title": "8 Decision Trees and Random Forest",
    "section": "",
    "text": "Suppose \\(\\va x\\in\\qty{0,1}^2\\)\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(y\\)\n\n\n\n\n1\n1\n0\n\n\n1\n0\n1\n\n\n0\n1\n1\n\n\n0\n0\n0\n\n\n\n\n\n\n\n\n\nFigure 1: Decision Tree"
  },
  {
    "objectID": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html#ensemble-methods-and-random-forest",
    "href": "notes/cs334/08-Decision-Trees-and-Random-Forest/08-Decision-Trees-and-Random-Forest.html#ensemble-methods-and-random-forest",
    "title": "8 Decision Trees and Random Forest",
    "section": "Ensemble Methods and Random Forest",
    "text": "Ensemble Methods and Random Forest\n\nGoal: Descreae variance without increasing bias (recall bias-variance trade-off)\nIdea: Average across multiple models to reduce estimation error. But we only have one single training set, how can we learn multiple models? BAGGING\n\n\nBootstrap Aggregatting (BAGGING)\n\nGeneral procedure:\n\nCreate \\(B\\) bootstrap samples: \\(D_N^{(1)},\\dots,D_N^{(B)}\\)\nTrain decision tree on each \\(D_N^{(b)}\\)\nClassify new examples by majority vote (i.e., mode)\n\n\n\n\n\n\n\n\nFigure 6: BAGGING\n\n\n\n\nWhy does bagging work? (Assume \\(y\\in\\qty{-1,+1}\\))\n\nSuppose we have \\(B\\) independent classifers: \\[\\hat f^{(b)}:\\R^d\\to\\qty{-1,+1},\\] and each \\(\\hat f^{(b)}\\) has a misclassification rate of \\(0.4\\).\n\nThat is, if \\(y^{(i)}=+1\\), then \\(\\P\\qty(\\hat f^{(b)}(\\va x^{(i)})=-1)=0.4\\quad\\forall b=1,\\dots,B\\) and \\(\\forall\\ i,\\dots,d\\)\n\nNow, applay baaged classifier: \\[\\hat f^{(\\text{bag})}(\\va x)=\\arg\\max_{y\\in\\qty{-1,+1}}\\sum_{b=1}^B\\1\\qty(\\hat f^{(b)}(\\va x)=\\hat y)=\\arg\\max\\qty{B_{-1},B_{+1}},\\] where \\(B_{-1}\\) is the number of votes for \\(-1\\), and \\(B_{+1}\\) is the number of votes for \\(+1\\). Then, \\[B_{-1}\\sim\\text{Binomial}(B,0.4).\\] Recall: if \\(X\\sim\\text{Binomial}(n,p)\\), then the probability of getting exactkly \\(k\\) successes in \\(n\\) trails is given by \\[P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}.\\] Thus, misclassification rate of bagged classifer is \\[\\begin{aligned}\\P\\qty(\\hat f^{(\\text{bag})}(\\va x^{(i)})=-1)&=\\P\\qty(B_{-1}\\geq\\dfrac{B}{2})\\\\&=1-\\P\\qty(B_{-1}&lt;\\dfrac{B}{2})\\\\&=1-\\sum_{k=1}^{\\lfloor B/2\\rfloor}\\binom{B}{k}(0.4)^k(1-0.4)^{B-k}.\\end{aligned}\\] Note: \\[\\lim_{B\\to+\\infty}\\sum_{k=1}^{\\lfloor B/2\\rfloor}\\binom{B}{k}p^k(1-p)^{B-k}=1\\] as long as misclassification rate \\(p&lt;0.5\\). So, as \\(B\\to\\infty\\), misclassification \\(\\to0\\).\n\nReality: Predcition error rarely goes to \\(0\\).\n\nBagging only reduces estimation error (varaince).\nWe don’t ahve independence assumption: classifiers trained on bootstrapped dataset are NOT independent.\n\n\n\n\n\n\n\n\n\nRemark 5. \n\nOn average, each bootstrap contain \\(63.2\\%\\) of original data.\nHow similar are boostrap samples?\n\nProbability of example \\((i)\\) is not selected once: \\(1-\\dfrac{1}{n}\\).\nProbability of example \\((i)\\) is not selected at all: \\(\\qty(1-\\dfrac{1}{n})^n\\).\n\nThen, \\[\\lim_{n\\to\\infty}\\qty(1-\\dfrac{1}{n})^n=\\dfrac{1}{e}\\approx36.8\\%.\\] So, when \\(n\\to\\infty\\), the probability of example \\((i)\\) is not selected at all is \\(36.8\\%\\).\n\n\n\n\n\n\n\nFurther Decorrelate Trees: Random Forest\n\nRandom forest is an ensemble method designed specifically for trees (bagging applies more boardly).\nTwo sources of randomness:\n\nBagging\nRandom feature subsets:at erach node, best split chosen from subset of \\(m\\) features instead of all \\(d\\) features.\n\n\n\n\n\\begin{algorithm} \\caption{Random Forest} \\begin{algorithmic} \\State{\\# Bagging} \\For{$b=1,\\dots, B$} \\State draw bootstrap sample $D_N^{(b)}$ of size $N$ from $D_N$ \\State grow decision tree $DT^{(b)}$$\\qquad$\\Comment{See below code for growing $DT^{(b)}$} \\EndFor \\Return{ensemble $\\qty{DT^{(1)}, \\dots, DT^{(B)}}$} \\State{\\# Subprocedure for growing $DT^{(b)}$; random feature subset} \\While{stopping criteria not met} \\State Recursively repeat following steps for each node of tree: \\State 1. select $m$ features at random from $d$ features \\State 2. pick best feature to split on (using $IG$ or $\\text{Gini}$) \\State 3. split node into childre. \\EndWhile \\State{\\# Another option to do Steps 1 and 2: } \\State{1. compute $IG$ for all $d$ features} \\State{2. randomly pick from top $m$} \\end{algorithmic} \\end{algorithm}"
  },
  {
    "objectID": "notes/RealAnalysis.html",
    "href": "notes/RealAnalysis.html",
    "title": "Real Analysis",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jiuru Lyu",
    "section": "Education",
    "text": "Education\nEmory University (2022 - 2026) | Atlanta, GA  BS in Applied Mathematics and Statistics; Minor in Computer Science\nUnited World College Changshu China (2019 - 2022) | Suzhou, China  International Baccalaureate Diploma Programme"
  },
  {
    "objectID": "index.html#research-experience",
    "href": "index.html#research-experience",
    "title": "Jiuru Lyu",
    "section": "Research Experience",
    "text": "Research Experience\nResearch Assistant @ Emory University (2025 - Present) | Atlanta, GA Topic: Numerical Methods for Mean-Field Games\nResearch Assistant @ Emory University (2025 - Present) | Atlanta, GA Topic: Spectral Graph Theory and Differential Equations\nResearch Assistant @ Emory University (2023 - Present) | Atlanta, GA Topic: Global Optimization for Morse Potential"
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "Jiuru Lyu",
    "section": "Work Experience",
    "text": "Work Experience\nSummer Digital Intern @ Baker Hughes (2024) | Shanghai, China"
  },
  {
    "objectID": "notes/NumericalODEsPDEs.html",
    "href": "notes/NumericalODEsPDEs.html",
    "title": "Numerical ODEs and PDEs",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes/cs334/09-Boosting/09-Boosting.html",
    "href": "notes/cs334/09-Boosting/09-Boosting.html",
    "title": "9 Boosting",
    "section": "",
    "text": "Goal: Reduce both approximation and estimation error at the same time (bias-variance tradeoff)."
  },
  {
    "objectID": "notes/cs334/09-Boosting/09-Boosting.html#bosting-introduction",
    "href": "notes/cs334/09-Boosting/09-Boosting.html#bosting-introduction",
    "title": "9 Boosting",
    "section": "Bosting Introduction",
    "text": "Bosting Introduction\n\n\n\n\n\n\n\nDefinition 1 (Boosting) Combine simple “weak” classifiers into a more complex “stronger” model.\n\nType of boosting methos: AdaBoost and Gradient Boosting\nWeak classifier: Decision stump (a one-level decision tree)\n\n\n\n\n\n\n\nFigure 1: Decision Stump\n\n\n\n\n\n\n\n\nNotation: \\[\nh\\qty(\\va x;\\va\\theta)=\\operatorname{sign}(\\theta_1(x_k-\\theta_0))=\\pm1,\n\\] where \\(\\va\\theta=(k,\\theta_0,\\theta_1)\\) such that \\(k\\) denotes the coordinate, \\(\\theta_0\\) is the location, and \\(\\theta_1\\) is the direction.\nEnsemble as a weighted combination of decision stumps: \\[\n\\begin{aligned}\nh_M(\\va x)&=\\sum_{m=1}^M\\alpha_m h\\qty(\\va x;\\va\\theta^{(m)})&\\text{for}\\quad \\alpha_m\\geq0.\\\\\n&=\\alpha_1 h\\qty(\\va x;\\va\\theta^{(1)})+\\alpha_2 h\\qty(\\va x;\\va\\theta^{(2)})+\\cdots+\\alpha_M h\\qty(\\va x;\\va\\theta^{(M)})\n\\end{aligned}\n\\]\nThis can be viewed as a linear classifier: \\(h_M(\\va x)=\\va\\alpha\\cdot\\phi(\\va x)\\), where\n\n\\(\\phi(\\va x)=\\mqty[h(\\va x;\\va\\theta^{(1)},\\dots,h(\\va x;\\va\\theta^{(M)})]\\), the feature mapping\n\\(\\va\\alpha=\\mqty[\\alpha_1,\\dots,\\alpha_m]\\), the parameter vector \\(\\va\\alpha\\in\\R^M\\).\n\n\\(\\phi(\\va x)\\in\\R^M\\):\n\nintead of specifying \\(\\phi(\\va x)\\), we learn \\(\\phi(\\cdot)\\) in addition to \\(\\va\\alpha\\).\n\\(M\\), the number of weak learners, is a hyperparameter."
  },
  {
    "objectID": "notes/cs334/09-Boosting/09-Boosting.html#adaboost-adaptive-boosting",
    "href": "notes/cs334/09-Boosting/09-Boosting.html#adaboost-adaptive-boosting",
    "title": "9 Boosting",
    "section": "AdaBoost: Adaptive Boosting",
    "text": "AdaBoost: Adaptive Boosting\n\nOne of the simplies and most popular boosting algorithms.\nAlgorithm Overview:\n\nSet example weights uniformly.\nFor each weak learner \\(m=1,\\dots, M\\):\n\nTrain decision stump on weighted examples\nApply decision stump to all examples\nSet decision stump weight based on weighted error\nSet example weights based on ensemble predictions.\n\n\nA greedy approach: Given the current ensemble, find the next weak learner that, if added, makes a better new ensemble.\n\nSuppose we have the frist \\((m-1)\\) decision stumps, which make up an ensemble classifier \\[h(\\va x;\\va\\theta^{(1)}),\\ h(\\va x;\\va\\theta^{(2)}),\\dots, h(\\va x;\\va\\theta^{(m-1)})\\implies h_{m-1}(\\va x).\\]\nGoal: Find the next decision stump \\(h(\\va x;\\va\\theta^{(m)})\\) and its weight \\(\\alpha_m\\) in order to minimize the same training loss (empirical risk) of the new ensemble \\(h_m(\\va x)\\): \\[\n\\begin{aligned}\n\\argmin_{\\va\\theta^{(m)},\\alpha_m} J(\\alpha_m,\\va\\theta^{(m)})&=\\argmin_{\\va\\theta^{(m)},\\alpha_m}\\sum_{i=1}^N \\operatorname{loss}\\qty(y^{(i)}\\cdot h_m(\\va x^{(i)})) &\\text{exponential }\\operatorname{loss}(\\cdot)=e^{-z}=\\exp(-z).\\\\\nJ(\\alpha_m,\\va\\theta^{(m)})&=\\sum_{i=1}^N \\exp\\qty(-y^{(i)}\\cdot h_m(\\va x^{(i)}))\\\\\n&=\\sum_{i=1}^N \\exp\\bigg(-y^{(i)}\\bigg[\\underbrace{h_{m-1}(\\va x^{(i)})}_{\\substack{\\text{previous}\\\\\\text{ensemble}}}+\\underbrace{\\alpha_mh(\\va x;\\va\\theta^{(m)})}_{\\text{update}}\\bigg]\\bigg)\\\\\n&=\\sum_{i=1}^N\\underbrace{\\exp\\qty(-y^{(i)}h_{m-1}(\\va x^{(i)}))}_{\\substack{\\text{independent of }\\alpha_m,\\va\\theta^{(m)}\\\\\\text{denote it as }w_{m-1}(i)}}\\exp\\qty(-y^{(i)}\\alpha_mh(\\va x;\\va\\theta^{(m)}))\\\\\n&=\\sum_{i=1}^N w_{m-1}(i)\\exp\\qty(-y^{(i)}\\alpha_mh(\\va x;\\va\\theta^{(m)}))\\\\\n\\end{aligned}\n\\]\nLet \\(w_{m-1}(i)=\\exp\\qty(-y^{(i)}h_{m-1}(\\va x^{(i)}))\\):\n\nLoss associated with the previous ensemble with respect to the \\((i)\\)-th point.\nUsed as weight for each training example: \\(i=1,\\dots, N\\).\nNew decision stump \\(\\va\\theta^{(m)}\\) will be more heavily influenced by examples that were misclassified by the previous ensemble.\n\nNote: weighted loss associated with point \\(\\va x^{(i)}\\) in the objective: \\[\nJ(\\alpha_m,\\va\\theta{(m)})=\\begin{cases}w_{m-1}(i)\\exp(-\\alpha_m)\\quad&\\text{if }\\va x^{(i)}\\text{ is correctly classified}\\\\w_{m-1}(i)\\exp(\\alpha_m)\\quad&\\text{o/w}.\\end{cases}\n\\] If \\(\\va x^{(i)}\\) is correctly classified: \\(y^{(i)}=h(\\va x;\\va\\theta^{(m)})\\). Let’s normalize example weigths so that they sum to \\(1\\): \\[\n\\tilde w_{m-1}(i)=\\dfrac{w_{m-1}(i)}{\\dsst\\sum_{j} w_{m-1}(j)}.\n\\] Then, \\[\n\\begin{aligned}\n\\tilde J(\\alpha_m,\\va\\theta^{(m)})&=\\underbrace{\\exp(-\\alpha_m)\\sum_{i:y^{(i)}=h(\\va x^{(i)};\\va\\theta^{(m)})}\\tilde w_{m-1}(i)}_\\text{correctly classified}+\\underbrace{\\exp(\\alpha_m)\\sum_{i:y^{(i)}\\neq h(\\va x^{(i)};\\va\\theta^{(m)})}\\tilde w_{m-1}(i)}_\\text{incorrect points}\\\\\n&=\\exp(-\\alpha_m)\\underbrace{\\sum_{i=1}^N\\tilde w_{m-1}(i)}_{=1}-\\exp(-\\alpha_m)\\sum_{i=1}^N\\tilde{w}_{m-1}(i)\\1\\qty{y^{(i)}\\neq h(\\va x^{(i)}\\neq h(\\va x^{(i);\\va\\theta^{(m)}}))}\\\\\n&\\qquad\\qquad+\\exp(\\alpha_m)\\sum_{i=1}^N\\tilde{w}_{m-1}(i)\\1\\qty{y^{(i)}\\neq h(\\va x^{(i)};\\va\\theta^{(m)})}\\\\\n&=\\exp(-\\alpha_m)+\\underbrace{\\qty\\bigg(\\exp(\\alpha_m)-\\exp(-\\alpha_m))}_{\\geq0}\\sum_{i=1}^N\\tilde{w}_{m-1}(i)\\1\\qty{y^{(i)}\\neq h(\\va x^{(i)};\\va\\theta^{(m)})}\\\\\n\\end{aligned}\n\\] So, our objective is \\[\n\\argmin_{\\va\\theta^{(m)},\\alpha_m}\\exp(-\\alpha_m)+\\qty\\bigg(\\exp(\\alpha_m)-\\exp(-\\alpha_m))\\sum_{i=1}^N\\tilde{w}_{m-1}(i)\\1\\qty{y^{(i)}\\neq h(\\va x^{(i)};\\va\\theta^{(m)})}\n\\]\nTo solve:\n\nFirst solve for best \\(\\va\\theta^{(m)*}\\), then \\[\n\\va\\theta^{(m)*}=\\argmin_{\\va\\theta^{(m)}}\\underbrace{\\sum_{i=1}^N\\tilde{w}_{m-1}(i)\\1\\qty{y^{(i)}\\neq h(\\va x^{(i)};\\va\\theta^{(m)})}}_{\\substack{\\epsilon_m\\text{: weighted classification error}\\\\\\text{of decision stumps}}}=\\argmin_{\\va\\theta^{(m)}}\\,\\epsilon_m\n\\] It is easy to optimize \\(\\va\\theta^{(m)}\\) via an exhaustive search over all possible decision stumps. Denote \\[\n\\tilde\\epsilon_m=\\sum_{i=1}^N\\tilde{w}_{m-1}(i)\\1\\qty{y^{(i)}\\neq h(\\va x^{(i)};\\va\\theta^{(m)*})}\n\\]\nFigure out how much weight to give it. \\[\n\\alpha_m^*=\\argmin_{\\alpha_m}\\underbrace{\\exp(-\\alpha_m)+\\qty[\\exp(\\alpha_m)-\\exp(-\\alpha_m)]\\tilde\\epsilon_m}_{L(\\alpha_m).}\n\\] By FOC: \\[\n\\begin{aligned}\n\\dfrac{\\partial L(\\alpha_m)}{\\partial\\alpha_m}=-\\exp(-\\alpha_m)+\\qty[\\exp(\\alpha_m)-\\exp(-\\alpha_m)]\\tilde\\epsilon_m&\\overset{\\text{set}}{=}0\\\\\n(\\epsilon_m-1)\\exp(-\\alpha_m)+\\epsilon_m\\exp(\\alpha_m)&=0\\\\\n\\implies\\alpha_m^*&=\\dfrac{1}{2}\\ln\\dfrac{1-\\tilde\\epsilon_m}{\\tilde\\epsilon_m}\\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n\\begin{algorithm} \\caption{AdaBoost} \\begin{algorithmic} \\State{Set $\\tilde w_0(i)=\\dfrac{1}{N}$ for $i=1,\\dots, N$} \\# Set example weights uniformly \\For{$m=1,\\dots,M$} \\State{\\# for each weak leaner} \\State{Find $\\va\\theta^{(m)}$ that minimizes $\\epsilon_m$} \\# Train decision stump on weighted examples \\State{Set $\\alpha_m=\\dfrac{1}{2}\\ln\\qty(\\dfrac{1-\\tilde\\epsilon_m}{\\tilde\\epsilon_m})$} \\# Set decision stump weight based on weighted error \\State{\\# Update weights based on the new ensemble} \\# Set example weights based on ensemble predictions \\For{$i=1,\\dots,N$} \\State{$\\tilde w_m(i)=\\dfrac{\\tilde w_{m-1}(i)\\exp\\qty(-y^{(i)}\\alpha_m^*h_m(\\va x^{(i)};\\theta^{(m)*}))}{Z_m}$} \\# Update weights \\State{where $Z_m$ is the normalization factor to ensure weigths sum to $1$} \\EndFor \\EndFor \\State{Find ensemble classifier $\\dsst h_M(\\va x)=\\sum_{m=1}^M\\alpha_mh(\\va x;\\va\\theta^{(m)})$} \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\n\n\nExample 1 (How AdaBoost Works in Action)  \n\n\n\n\n\n\nFigure 2: Boosting Example\n\n\n\n\n\n\n\n\n\nFigure 3: Graphical Representation of Boosting Results\n\n\n\n\n\n\n\n\nProperties of Boosting:\n\nWeighted training error \\(\\hat\\epsilon_m\\) (for each iteration’s new weak error): tends to increase with each boosting iteration.\nEnsemble training error does not necessarily decrease monotonically. Ensemble exponential loss decreases monotonically (as this is what we are minimizing).\nEnsemble test error (generalization error) does not increase even after a large number of boosting iterations (more robust to overfitting)."
  },
  {
    "objectID": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html",
    "href": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html",
    "title": "10 Introduction to Neural Networks",
    "section": "",
    "text": "Successful machine learning application relies on successful representation of data. \\[\n\\text{Input}\\longrightarrow\\text{Feature Representation}\\longrightarrow\\text{Learning Algorithm}\n\\]\nMachine learning practitioners put a lot of effort into feature engineering:\n\nHow can we get good representations automatically?\nHow can we learn good features?\n\nMethods for non-linear classification:\n\nExplicit feature mapping \\(\\phi(\\va x)\\): \\[\\hat y=\\operatorname{sign}(\\va\\theta\\cdot\\phi(\\va x)).\\]\n\nHand-crafted, labor-intensive, could become very high dimensional.\n\\(\\phi(\\va x)\\) depends on \\(\\va x\\) alone and is not learned.\n\nImplicit feature mapping via a kernel: \\[\\hat y=\\operatorname{sign}\\qty(\\sum_{j=1}^N\\alpha_j y^{(j)}K(\\va x^{(j)},\\va x))=\\operatorname{sign}(\\va\\alpha\\cdot\\phi(\\va x)),\\] where \\(\\phi(\\va x)=\\mqty[y^{(1)}K(\\va x^{(1)},\\va x),\\dots,y^{(N)}K(\\va x^{(N)},\\va x)]\\).\n\n\\(\\phi(\\va x)\\) depends on \\(\\va x\\) and the training set \\(\\qty{\\va x^{(i)},y^{(i)}}_{i=1}^N\\), but is not learned.\n\nBoosting ensemble: \\[\\hat y=\\operatorname{sign}\\qty(\\sum_{m=1}^M\\alpha_mh(\\va x;\\va\\theta^{(m)}))=\\operatorname{sign}(\\va\\alpha\\cdot\\phi(\\va x)),\\] where \\(\\phi(\\va x)=\\mqty[h(\\va x;\\va\\theta^{(1)}),\\dots,h(\\va x;\\va\\theta^{(M)})]\\).\n\n\\(\\phi(\\va x)\\) is learned via a greedy approach in boosting.\nOptimization is performed sequentially choosing one weak classifier at a time.\n\nNeural networks:\n\nJointly Learning\nModel parameters and feature representations are learned at the same time."
  },
  {
    "objectID": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#representing-data",
    "href": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#representing-data",
    "title": "10 Introduction to Neural Networks",
    "section": "",
    "text": "Successful machine learning application relies on successful representation of data. \\[\n\\text{Input}\\longrightarrow\\text{Feature Representation}\\longrightarrow\\text{Learning Algorithm}\n\\]\nMachine learning practitioners put a lot of effort into feature engineering:\n\nHow can we get good representations automatically?\nHow can we learn good features?\n\nMethods for non-linear classification:\n\nExplicit feature mapping \\(\\phi(\\va x)\\): \\[\\hat y=\\operatorname{sign}(\\va\\theta\\cdot\\phi(\\va x)).\\]\n\nHand-crafted, labor-intensive, could become very high dimensional.\n\\(\\phi(\\va x)\\) depends on \\(\\va x\\) alone and is not learned.\n\nImplicit feature mapping via a kernel: \\[\\hat y=\\operatorname{sign}\\qty(\\sum_{j=1}^N\\alpha_j y^{(j)}K(\\va x^{(j)},\\va x))=\\operatorname{sign}(\\va\\alpha\\cdot\\phi(\\va x)),\\] where \\(\\phi(\\va x)=\\mqty[y^{(1)}K(\\va x^{(1)},\\va x),\\dots,y^{(N)}K(\\va x^{(N)},\\va x)]\\).\n\n\\(\\phi(\\va x)\\) depends on \\(\\va x\\) and the training set \\(\\qty{\\va x^{(i)},y^{(i)}}_{i=1}^N\\), but is not learned.\n\nBoosting ensemble: \\[\\hat y=\\operatorname{sign}\\qty(\\sum_{m=1}^M\\alpha_mh(\\va x;\\va\\theta^{(m)}))=\\operatorname{sign}(\\va\\alpha\\cdot\\phi(\\va x)),\\] where \\(\\phi(\\va x)=\\mqty[h(\\va x;\\va\\theta^{(1)}),\\dots,h(\\va x;\\va\\theta^{(M)})]\\).\n\n\\(\\phi(\\va x)\\) is learned via a greedy approach in boosting.\nOptimization is performed sequentially choosing one weak classifier at a time.\n\nNeural networks:\n\nJointly Learning\nModel parameters and feature representations are learned at the same time."
  },
  {
    "objectID": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#introduction-to-neural-networks",
    "href": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#introduction-to-neural-networks",
    "title": "10 Introduction to Neural Networks",
    "section": "Introduction to Neural Networks",
    "text": "Introduction to Neural Networks\n\nOther names:\n\nFeedforward neural networks (FNN)\nMultilayer perceptrons (MLP)\nFully-connected/Dense networks\n\n\n\n\n\n\n\n\n\nDefinition 1 (Neural Networks) Neural networks are composed of simple computational units called neurons/units.\n\n\n\n\n\n\nFigure 1: Example of a Neural Network\n\n\n\n\n\\(z=z(\\va x;\\va w)=w_1x_1+w_2x_2+w_3x_3\\), and \\(h=g(z)\\) is the activation function.\nExample of activation function: sigmoid function: \\[h=g(z)=\\dfrac{1}{1+e^{-z}}.\\]\n\nNeurons are arranged in a network composed of layers. The specific arrangement corresponds to the architecture. - Input layer: The first layer of the network, which receives the input data. - Hidden layers: Intermediate layers between the input and output layers. Each hidden layer consists of multiple neurons that process the input data. - Output layer: The final layer of the network, which produces the output predictions.\n\n\n\n\n\n\nFigure 2: Example of Layers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemark 1 (Single-Layer Neural Network). A single-layer neural network is simply logistic regression. \\[\n\\va x=\\mqty[x_1\\\\x_2\\\\x_3],\\quad \\va w=\\mqty[w_1\\\\w_2\\\\w_3],\\quad \\implies\\quad\\hat y=h(\\va x;\\va w)=\\dfrac{1}{1+\\exp(-\\va w\\cdot\\va x)}.\n\\]\n\n\n\n\n\n\n\n\n\n\n\nRemark 2 (Offset/Bias Term). We can always include an offset/intercept/bias term by adding a constant input.\n\n\n\n\n\n\nFigure 3: Adding Bias\n\n\n\n\\[\nz=z(\\va x;\\va w)=w_0+w_1x_1+w_2x_2+w_3x_3+w_4.\n\\]\n\n\n\n\n\nAdding one hidden layer:\n\nNotation: the weight \\(W_{ik}^{(j)}\\), where \\(j\\)-th layer, \\(i\\)-th input, and \\(k\\)-th unit. \nTwo-layer network since ther eare two sets of weights.\nForward propagation: \nCommon activation functions:\n\nReLU: \\(g(z)=\\max\\qty{0,z}\\).\nThreshold: \\(g(z)=\\operatorname{sign}(z)\\).\nSoftmax: \\(g(z)=\\dfrac{e^z}{\\dsst\\sum_ke^{z_k}}\\) for multiclass classification.\nSigmoid: \\(g(z)=\\dfrac{1}{(1+e^{-z})}\\).\nHyperbolic tangent: \\(g(z)=\\tanh(z)\\).\n\n\n\n\n\n\n\n\n\n\nExample 1 (What is neural network doing?)  \n\n\n\nNeural Network Effects"
  },
  {
    "objectID": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#what-is-neural-network-doing",
    "href": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#what-is-neural-network-doing",
    "title": "10 Introduction to Neural Networks",
    "section": "What is neural network doing?",
    "text": "What is neural network doing?\n\n\n\nNeural Network Effects"
  },
  {
    "objectID": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#training-neural-networks",
    "href": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#training-neural-networks",
    "title": "10 Introduction to Neural Networks",
    "section": "Training Neural Networks",
    "text": "Training Neural Networks\nGaol: Formulate an optimization problem to find the weifghts. Apply SGD.\n\nSet-up: \\(D=\\qty{\\va x^{(i)},y^{(i)}}_{i=1}^N\\), \\(\\va x\\in\\R^d\\), \\(y\\in\\qty{-1,+1}\\).\nWe want to learn \\(\\va\\theta=\\mqty[w_{10}^{(1)},w_{11}^{(1)},\\dots,w_{km}^{(L)}]\\) parameter of the neural network in order to minimize loss over training examples: \\[\nJ(\\va\\theta)=\\dfrac{1}{N}\\sum_{i=1}^N\\operatorname{loss}(y^{(i)}\\cdot h(\\va x^{(i)};\\va\\theta)),\n\\] where \\(y^{(i)}\\) is the true label and \\(h(\\va x^{(i)};\\va\\theta)\\) is the neural network output.\n\n\n\n\n\n\n\n\nRemark 3 (Choice of Loss Function). \\(\\operatorname{loss}(\\cdot)\\) can be any (sub)differentiable loss function. For example, hinge loss.\n\n\n\n\n\nOverview of Optimization Procedure: SGD\n\nInitialize \\(\\va\\theta\\) to small random values (to prevent learning the same features).\nSelect \\(i=\\qty{1,\\dots,N}\\) at random (or mini-batch).\nUpdate \\[\\va\\theta^{(k+1)}=\\va\\theta^{(k)}-\\eval{\\eta_k\\grad_{\\va\\theta}\\operatorname{loss}\\qty(y^{(i)}\\cdot h(\\va x^{(i)};\\va\\theta))}_{\\va\\theta=\\va\\theta^{(k)}}.\\]\n\n\n\n\n\n\n\n\n\nRemark 4 (Number of Parameters/Dimensions). Gradient vector has the same dimensionality as the number of parameters. \\[\nd'=\\sum_{\\l=1}^{\\text{number of layers}}\\qty(\\text{number of inputs for layer }\\l)\\times\\qty(\\text{number of ouputs for layer }\\l).\n\\]"
  },
  {
    "objectID": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#backpropagation",
    "href": "notes/cs334/10-Introduction-to-Neural-Networks/10-Introduction-to-Neural-Networks.html#backpropagation",
    "title": "10 Introduction to Neural Networks",
    "section": "Backpropagation",
    "text": "Backpropagation\n\nSimple Single-Layer NN\n\n\n\n\n\n\nFigure 4: single-layer-nn\n\n\n\n\nWe consider no activation function: \\[h(\\va x;\\theta)=w_0+\\sum_{j=1}^dw_jx_j=z.\\]\nConsider Hinge loss: \\[L=\\max\\qty{0, 1-yz}.\\]\nFor \\(j=1,\\dots, d\\): \\[\\pdv{L}{w_j}=\\pdv{L}{z}\\cdot\\pdv{z}{w_j}=-y\\cdot\\1\\qty{L&gt;0}\\cdot x_j,\\quad\\text{Chain Rule: }L(z(w)).\\]\nThe update rule is: if \\(\\operatorname{loss}(yz)&gt;0\\) (equivalent to \\(y\\cdot h(\\va x;\\va\\theta^{(k)})&lt;1\\).), then \\(w_j^{(k+1)}=w_j^{(k)}+\\eta_kyx_j\\).\n\\(j=0\\): \\[\\pdv{L}{w_0}=\\pdv{L}{z}\\cdot\\pdv{z}{w_0}=-y\\cdot\\1\\qty{L&gt;0}\\cdot 1=-y\\cdot\\1{K&gt;0}.\\]\nThe update rule is if \\(\\operatorname{loss}(yz)&gt;0\\), then \\(w_0^{(k+1)}=w_0^{(k)}+\\eta_ky\\).\n\n\n\nTwo-Layer NN (One Hidden Layer)\n\n\n\n\n\n\nFigure 5: Two-Layer NN\n\n\n\n\\[\n\\begin{aligned}\nz_j^{(2)}&=w_{0j}^{(1)}+\\sum_{i=1}^d x_iw_{ij}^{(1)}\\\\\nh_j^{(2)}&=\\max\\qty{0,z_j^{(2)}}\\\\\nz^{(3)}&=w_{0}^{(2)}+\\sum_{j=1}^m h_j^{(2)}w_j^{(2)}\\\\\nh(\\va x;\\va\\theta)&=z^{(3)}&\\text{(no activation function)}\n\\end{aligned}\n\\]\n\nNotation change: \\(i=0,\\dots, d\\) and \\(j=1,\\dots, m\\)\n\n\\(w_{ij}=w_{ij}^{(1)}\\)\n\\(v_j=w_j^{(2)}\\)\n\\(z_j=z_j^{(2)}\\)\n\\(h_j=h_j^{(2)}\\)\n\\(z=z^{(3)}\\)\nThen, \\[\n\\begin{aligned}\nz_j&=w_{0j}+\\sum_{i=1}^d x_iw_{ij}\\\\\nh_j&=\\max\\qty{0,z_j}\\\\\nz&=v_0+\\sum_{j=1}^m h_jv_j\\\\\nh(\\va x;\\va\\theta)&=z\\\\\nL&=\\max\\qty{0,1-yz} &\\text{(loss function)}.\n\\end{aligned}\n\\]\n\nTo work out the update rule, let’s go backwards\n\nOutput layer is simple linear classifier based on \\(h_j\\)’s: \\[\n\\begin{aligned}\nh(\\va x;\\va\\theta)&=z=\\va v\\cdot\\phi(\\va x)\\\\\n\\phi(\\va x)&=\\mqty[1, h_1,\\dots,h_m]\\\\\n\\va v&=\\mqty[v_0,v_1,\\dots,v_m]\\\\\n\\pdv{L}{v_j}&=\\pdv{L}{z}\\cdot\\pdv{z}{v_j}=-y\\1\\qty{L&gt;0}h_j\n\\end{aligned}\n\\] So, the update rule is \\(v_j^{(k+1)}=v_j^{(k)}+\\eta_ky\\1\\qty{L&gt;0}h_j\\).\nHidden layer: each unit is a linear combination of input feature \\(x_i\\)’s followed by activation function \\(g\\), but its update \\(h_j\\) is used as input to the ouput layer, so changing \\(w_{ij}\\) will affect the loss through \\(z_j,h_j\\), and \\(z\\). \\[\n\\begin{aligned}\n\\pdv{L}{w_{ij}}&=\\pdv{L}{z}\\cdot\\pdv{z}{h_j}\\cdot\\pdv{h_j}{z_j}\\cdot\\pdv{z_j}{w_{ij}}\\\\\n&=-y\\1\\qty{L&gt;0}v_j\\cdot\\1\\qty{z_j&gt;0}\\cdot x_i\\\\\n\\end{aligned}\n\\] Then, the update rule is \\(w_{ij}^{(k+1)}=w_{ij}^{(k)}+\\eta_ky\\1\\qty{L&gt;0}v_j\\1\\qty{z_j&gt;0}x_i\\) for \\(i=0,\\dots,d\\) and \\(j=0,\\dots,m\\).\n\nThis is the backpropagation: \\[\n\\begin{aligned}\n\\pdv{L}{v_1}&=\\pdv{L}{z}\\cdot\\pdv{z}{v_1}\\\\\n\\pdv{L}{w_{11}}&=\\pdv{L}{z}\\cdot\\pdv{z}{h_1}\\cdot\\pdv{h_1}{z_1}\\cdot\\pdv{z_1}{w_{11}}\\\\\n\\pdv{L}{w_{01}}&=\\pdv{L}{z}\\cdot\\pdv{z}{h_1}\\cdot\\pdv{h_1}{z_1}\\cdot\\pdv{z_1}{w_{01}}\\\\\n\\end{aligned}\n\\]\n\nObservation: intermediate partial derivatives are shared. Overlapping subproblems, implemented via dynamic programming.\nBackpropagation: Chain Rule + Dynamic Programming.\nSubroutine for effeciently computing the gradient (i.e., all partial derivatives) of a neural network:\n\nfor each training example:\n\nmake a forward pass, go through the layers and make a prediction\ncalculate loss\nmake a backward pass, go through the layers in reverse and calculate the partial derivatives.\n\nUse the gradient information in an optimiztioon procedure (e.g. SGD).\n\n\n\n\n\nThree-Layer NN (Two Hidden Layers)\n\n\n\n\n\n\nFigure 6: Three-Layer NN"
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html",
    "title": "11 Convolutional Neural Networks",
    "section": "",
    "text": "Each image is a \\(32\\times32\\) grayscale image (\\(0-255\\)).\nA flat representation of the image: \\[\\va x=\\mqty[x_1,x_2,\\dots,x_{1024}]\\]\nProblem with flat representation:\n\nIgnore spatial structure\nSubsceptible to translational error\n\nGoal: preserve the spatial structure of the task by capturing relationships among neighboring pixels.\nIdeas:\n\nLaern feature representations based on small patches.\nApply patch-based feature representations across the entire image.\n\nBuilding blocks of CNN:\n\nConvolutional layers\nActivation layers\nPooling layers\nFully connected layers"
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#introduction-to-the-mnist-dataset-and-cnns",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#introduction-to-the-mnist-dataset-and-cnns",
    "title": "11 Convolutional Neural Networks",
    "section": "",
    "text": "Each image is a \\(32\\times32\\) grayscale image (\\(0-255\\)).\nA flat representation of the image: \\[\\va x=\\mqty[x_1,x_2,\\dots,x_{1024}]\\]\nProblem with flat representation:\n\nIgnore spatial structure\nSubsceptible to translational error\n\nGoal: preserve the spatial structure of the task by capturing relationships among neighboring pixels.\nIdeas:\n\nLaern feature representations based on small patches.\nApply patch-based feature representations across the entire image.\n\nBuilding blocks of CNN:\n\nConvolutional layers\nActivation layers\nPooling layers\nFully connected layers"
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#convolutional-layer",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#convolutional-layer",
    "title": "11 Convolutional Neural Networks",
    "section": "Convolutional Layer",
    "text": "Convolutional Layer\n\n\n\n\n\n\nFigure 1: Covolutional Layer\n\n\n\n\nNeurons that maps a \\(3\\times 3\\) patch to a scalar value. \\[\\va x\\cdot\\va w+b,\\] where \\(\\va x\\) is the image patch, \\(\\va w\\) and \\(b\\) are filter parameters.\nConvolution operation:\n\nSlide the filter over the image spatially\nCompute the dot product with different patches of the image.\n\n\n\n\n\n\n\n\n\nExample 1 (Padding)  \n\n\n\n\n\n\nFigure 2: filter\n\n\n\nOften times, it is beneficial to preserve the original image size. This can be done with padding: allow filter to overlap with boundary (zero padding/copy-paste).\n\n\n\n\n\n\nFigure 3: padding"
  },
  {
    "objectID": "notes/cs334/12-Recurrent-Neural-Networks/12-Recurrent-Neural-Networks.html",
    "href": "notes/cs334/12-Recurrent-Neural-Networks/12-Recurrent-Neural-Networks.html",
    "title": "12 Recurrent Neural Networks",
    "section": "",
    "text": "Application:\n\nLanguage modeling\nSequence tagging\nText classification\n\nRNN is a family of neural networks for processing sequential data of arbitrary length.\n\nOutput of the layer can connect back to the neuron itself or a layer before it.\nShare same weights across several time steps.\n\nA recurrence function is applied at each step: \\[h_t=f_W(h_{t-1},x_t),\\] where\n\n\\(h_t\\) is the new state\n\\(f_W\\) is a neural network with parameter \\(W\\)\n\\(h_{t-1}\\) is the old state\n\\(x-t\\) is the input feature vector at time step \\(t\\)\n\nVanilla RNN: connect the output of the last layer to the input of the next layer.\n\nThe problem of long-term dependencies:\n\nAppeal of RNN is to connect previous information to current task.\nGap between relevant information and where we need it can be large.\nLong-range dependencies are difficult to learn because of vanishing gradients or exploding gradients.\n\n\nTo solve the problem, we introduce LSTM networks and GRU networks.\nThere are other more advanced architectures, such as Attention and Transformer networks."
  },
  {
    "objectID": "notes/cs334/14-Recommender-Systems/14-Recommender-Systems.html",
    "href": "notes/cs334/14-Recommender-Systems/14-Recommender-Systems.html",
    "title": "14 Recommender Systems",
    "section": "",
    "text": "Collaborative filtering:\n\nRecommender problems that can be reduced to a matrix completion problem.\nWe have a \\(n\\times m\\) matrix, where \\(n\\) is the number of users and \\(m\\) is the number of movies. Each entry \\(Y_{a,i}\\in\\qty{1,\\dots,5}\\) is the rating of user \\(a\\) for movie \\(i\\).\nThe key idea is to borrow experience from other similar users."
  },
  {
    "objectID": "notes/cs334/15-Clustering/15-Clustering.html",
    "href": "notes/cs334/15-Clustering/15-Clustering.html",
    "title": "15 Clustering",
    "section": "",
    "text": "Input: dataset of feature vectors \\(D=\\qty{\\va x^{(i)}}_{i=1}^N\\), where \\(\\va x^{(i)}\\in\\R^d\\). We don’t have labels!\nOutput: a set of clusters \\(C_1,\\dots,C_k\\)\nTypes of clusters: partitional vs. hierarchical"
  },
  {
    "objectID": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html",
    "href": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html",
    "title": "13 Reinforcement Learning",
    "section": "",
    "text": "Reinforcement learning is agent-oriented learning."
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#activation-layers",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#activation-layers",
    "title": "11 Convolutional Neural Networks",
    "section": "Activation Layers",
    "text": "Activation Layers\n\n\n\n\n\n\nFigure 4: Activation Layer\n\n\n\n\nEach filter produces a feature map and a activation map.\nMultiple filters \\(\\longrightarrow\\) multiple feature maps and activation maps (or channels)."
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#pooling-layers",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#pooling-layers",
    "title": "11 Convolutional Neural Networks",
    "section": "Pooling Layers",
    "text": "Pooling Layers\n\n\n\n\n\n\nFigure 5: Pooling Layer\n\n\n\n\nDownsamples previous layers activation map\nCosolidate feature learned at previous stage.\nWhy?\n\nCompress/Smooth\nSpatial invariance\nPrevent overfitting\n\nPooling often uses simple functions: max or average.\nPooling operates over each activation map independently."
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#fully-connected-layers",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#fully-connected-layers",
    "title": "11 Convolutional Neural Networks",
    "section": "Fully Connected Layers",
    "text": "Fully Connected Layers\n\n\n\n\n\n\nFigure 6: Fully Connected Layer\n\n\n\n\nFlatten the output from previous layer\nNormal dense fully connected layer"
  },
  {
    "objectID": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#architecture-details",
    "href": "notes/cs334/11-Convolutional-Neural-Networks/11-Convolutional-Neural-Networks.html#architecture-details",
    "title": "11 Convolutional Neural Networks",
    "section": "Architecture Details:",
    "text": "Architecture Details:\n\nInput to a covolutional layer: \\(C_\\text{in}\\times H\\times W\\)\n\n\\(C_\\text{in}\\): number of input channels\n\\(H\\): height of the input\n\\(W\\): width of the input\n\n\\(C_\\text{out}\\) (number of output channels) filters of \\(h\\times w\\), where \\(h&lt;H\\) and \\(w&lt;W\\) (\\(h=w\\)).\nOutput: \\(C_\\text{out}\\times H'\\times W'\\), where \\(H'\\) and \\(W'\\) depends on filter size, padding, and stride.\nParameter sharing: efficient:\n\nSuppose input image \\(100\\times100\\longrightarrow10,000\\) input pixels.\nFully-connected layer with \\(100\\) neurons (no bias): \\(10,000\\times100=1,000,000\\) parameters.\nConvolutional layer with \\(100\\) filters of size \\(3\\times 3\\) (no bias): \\(3\\times3\\times100=900\\) parameters."
  },
  {
    "objectID": "notes/cs334/12-Recurrent-Neural-Networks/12-Recurrent-Neural-Networks.html#recurrent-neural-networks-rnns",
    "href": "notes/cs334/12-Recurrent-Neural-Networks/12-Recurrent-Neural-Networks.html#recurrent-neural-networks-rnns",
    "title": "12 Recurrent Neural Networks",
    "section": "",
    "text": "Application:\n\nLanguage modeling\nSequence tagging\nText classification\n\nRNN is a family of neural networks for processing sequential data of arbitrary length.\n\nOutput of the layer can connect back to the neuron itself or a layer before it.\nShare same weights across several time steps.\n\nA recurrence function is applied at each step: \\[h_t=f_W(h_{t-1},x_t),\\] where\n\n\\(h_t\\) is the new state\n\\(f_W\\) is a neural network with parameter \\(W\\)\n\\(h_{t-1}\\) is the old state\n\\(x-t\\) is the input feature vector at time step \\(t\\)\n\nVanilla RNN: connect the output of the last layer to the input of the next layer.\n\nThe problem of long-term dependencies:\n\nAppeal of RNN is to connect previous information to current task.\nGap between relevant information and where we need it can be large.\nLong-range dependencies are difficult to learn because of vanishing gradients or exploding gradients.\n\n\nTo solve the problem, we introduce LSTM networks and GRU networks.\nThere are other more advanced architectures, such as Attention and Transformer networks."
  },
  {
    "objectID": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html#the-rl-interface-sequential-decision-making",
    "href": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html#the-rl-interface-sequential-decision-making",
    "title": "13 Reinforcement Learning",
    "section": "The RL Interface: Sequential Decision Making",
    "text": "The RL Interface: Sequential Decision Making\n\nOverfiew: At each time \\(t\\), the agent\n\nObserve state \\(S_t\\) (Environment)\nExecutes an action \\(a_t\\)\nReceives a scalar reward \\(r_t\\)\nTransitions to the next state \\(S_{t+1}\\).\n\nThe process is repeated and forms a trajectory of states, actions, and rewards: \\(s_1,a_1,r_1,s_2,a_2,r_2,\\dots\\).\n\n\n\n\n\n\n\n\nDefinition 1 (Markov Decision Process (MDP))  \n\n\\(\\mathcal{S}\\): set of states\n\\(\\mathcal{A}\\): set of actions\n\\(R\\): reward function \\[p(r_t\\mid s_t,a_t)\\]\n\\(P\\): transition function \\[p(s_{t+1}\\mid s_t,a_t)\\]\n\nPolicy: mapping from states to actions \\[\\pi:\\mathcal{S}\\to\\mathcal{A}\\] Goal: learn polyci that maximizes the cummulative reward: \\[G=\\sum_{t=1}^Tr_t.\\]"
  },
  {
    "objectID": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html#multi-armed-bandit-problem",
    "href": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html#multi-armed-bandit-problem",
    "title": "13 Reinforcement Learning",
    "section": "Multi-Armed Bandit Problem",
    "text": "Multi-Armed Bandit Problem\n\n\n\n\n\n\nFigure 1: Multi-Armed Bandit Problem\n\n\n\n\nSet-up:\n\n\\(\\mathcal{S}\\): single state\n\\(\\mathcal{A}\\): arms \\(a=1,a=2,a=3,\\dots,a=k\\).\n\\(R\\): \\(P(r\\mid a)\\) for \\(a\\in\\mathcal{A}\\), pobablistic mapping from action to reward.\nTask: Agent sequentially chooses which arm to pull next.\nfor steps \\(t=1,\\dots, T\\): The arm chosed to pull: \\(a_t\\in\\mathcal{A}\\). Observed reward: \\(r_t\\sim P(r\\mid a_t)\\).\nGoal: Decide a sequence of actions that maximizes cumulative reward \\[\\sum_{t=1}^T r_t\\]\nAssumption: Reward depends only on the action taken. i.e., it is i.i.d. with expectation \\(\\mu(a)\\) for \\(a=1,\\dots, k\\).\n\n\n\n\n\n\n\n\n\nExample 1 (Example: Best Arm to Pull)  \n\naction \\(1\\): \\(\\mu(a)=8\\)\naction \\(2\\): \\(\\mu(a)=12\\)\naction \\(3\\): \\(\\mu(a)=12.5\\)\naction \\(4\\): \\(\\mu(a)=11\\)\n\nAction \\(3\\) is the best since \\(\\mu(a)\\) is the highest. If we know \\(\\mu(a)\\) for \\(a\\in\\mathcal{A}\\), then always taking \\(a=3\\) givesn the highest cummulative reward.\n\n\n\n\n\nChallenge: \\(\\mu(a)\\) is unknown, the distribution is unknown.\n\n\nAction-Value Methods\n\nMain idea: learn \\(Q(a)\\approx\\mu(a)\\quad\\forall\\,a\\in\\mathcal{A}\\).\nSuppose we have \\(a_1,r_1,a_2,r_2,\\dots,a_{t-1},r_{t-1}\\).\nEstimate \\(\\mu(a)\\) for \\(a\\in\\mathcal{A}\\) as sample average: \\[\n\\begin{aligned}\nQ_t(a)&=\\dfrac{\\text{sum of rewards when action }a\\text{ is taken previously}}{\\text{number of times action }a\\text{ is taken previously}}\\\\\n&=\\dfrac{\\dsst\\sum_{i=1}^{t-1}r_1\\1\\qty{a_i=a}}{\\dsst\\underbrace{\\sum_{i=1}^{t-1}\\1\\qty{a_i=a}}_{N_t(a)}}\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nRemark 1 (Convergence of Sample Average). Sample average converges to the true value if action is taken infinitely number of times: \\[\n\\lim_{N_t(a)\\to\\infty}Q_t(a)=\\mu(a),\n\\] where \\(N_t(a)\\) is the number of times action \\(a\\) has been taken by time \\(t\\).\n\n\n\n\n\nGiven \\(Q_t(a)\\) for all \\(a\\in\\mathcal{A}\\), the greedy action \\(a_t^*=\\argmax_{a}Q_t(a)\\).\nFor the next action \\(a_t\\):\n\nif \\(a_t=a_t^*\\), we are exploiting, we kind of know which actions are good.\nif \\(a_t\\neq a_t^*\\), we are exploring, we want to collect more data to improve estimates.\n\nWe can only pick one \\(a_t\\), so we can’t do both.\nBUT, we have to do both.\nThis is the key dilemma in reinforcement learning: Exploration vs. Exploitation.\n\nExploration: gain more information about value of each action.\nExploitation: Revisit actions that are already known to given high rewards.\n\nFirst attempt: Naïve approach:\n\nExploration phase: Try each arm \\(100\\) times.\nEstimate their value as \\(Q(a)\\) for \\(a\\in\\mathcal{A}\\).\nExploitation phase: Always pick \\(a^*=\\argmax_a Q(a)\\).\nProblem:\n\nIs \\(100\\) times too much? e.g., negtive rewards \\(10\\) consecutive times\nIs \\(100\\) times enough? \\(Q(a)\\to\\mu(a)\\) in the limit of infinite samples. We should never stop exploring.\n\n\nSecond attempt: \\(\\epsilon\\)-Greedy Action Selection:\n\nThis ia simple, effective way to balance exploration and exploitation.\n\n\n\n\n\\begin{algorithm} \\caption{$\\epsilon$-Greedy Action Selection} \\begin{algorithmic} \\State{Initialize $\\begin{cases}Q(a)=0\\\\N(a)=0\\end{cases}$ for $a=1,\\dots,k$} \\For{$t=1,2,3,\\dots$} \\State{$a_t=\\begin{cases}\\dsst\\argmax_a Q(a)&\\text{with probability }1-\\epsilon\\longrightarrow\\text{exploitation}\\\\\\text{random action}&\\text{with probability }\\epsilon\\longrightarrow\\text{exploration}\\end{cases}\\qquad$} \\# breaks ties randomly \\State{Take action $a_t$, receive reward $r_t$} \\State{update: $\\begin{cases}N(a_t)\\gets N(a_t)+1\\\\Q(a_t)\\gets Q(a_t)+\\dfrac{1}{N(a_t)}\\qty\\Big[r_t-Q(a_t)]\\end{cases}\\qquad$} \\# incremental implementation of sample average \\EndFor \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\n\n\nRemark 2 (\\(\\epsilon\\) Controls the Exploration Rate). \n\nLarger \\(\\epsilon\\), explore more, learn faster, converge to suboptimal.\nSmaller \\(\\epsilon\\), explore less, learn slower, converge to near-optimal.\n\n\n\n\n\n\n\\(\\epsilon\\)-greedy explores forever, and we have constant exploration rate.\n\nShould we explore forever?\nYes! But perhaps explore less as time goes by.\nKey idea: “Optimism in the face of uncertainty”\n\nThe more uncertain we are about an action, the more important it is to explore that action.\n\n\nOptimistic initialization:\n\nInitialize \\(Q(a)\\) to some positive value\nEncourage exploration initially, naturally gets “washed out” as we collect data.\nThis method is somewhat hacky, but it works.\n\n\n\n\n\\begin{algorithm} \\caption{Optimistic Initialization (Somewhat Hacky)} \\begin{algorithmic} \\State{Initialize $\\begin{cases}Q(a)=\\textcolor{red}{Q_0},&\\text{where }Q_0&gt;0\\\\N(a)=0\\end{cases}$ for $a=1,\\dots,k\\qquad$} \\# Larger $Q_0$, more exploration \\For{$t=1,2,3,\\dots$} \\State{$a_t=\\dsst\\argmax_{a}Q(a)\\qquad$} \\# breaks ties randomly \\State{Take action $a_t$, receive reward $r_t$} \\State{update: $\\begin{cases}N(a_t)\\gets N(a_t)+1\\\\Q(a_t)\\gets Q(a_t)+\\dfrac{1}{N(a_t)}\\qty\\Big[r_t-Q(a_t)]\\end{cases}\\qquad$} \\# incremental implementation of sample average \\EndFor \\end{algorithmic} \\end{algorithm}\n\n\n\nUpper Confidence Bound (UCB) Action Selection:\n\nSelect actions greedily based on potential of being the best\nEstimate \\(Q(a)+\\text{Uncertainty }N(a)\\).\n\nUCB Score: \\[Q_t(a)+c\\sqrt{\\dfrac{\\ln(t)}{N_t(a)}},\\quad c&gt;0,\\] where\n\n\\(Q_t(a)\\) is the sample average estimate\n\\(\\dsst c\\sqrt{\\dfrac{\\ln(t)}{N_t(a)}}\\) is the exploration bonus\n\\(c\\) is the degree of exploration. Larger \\(c\\), more exploration.\n\nAs \\(N_t(a)\\) increases, more certain, explore less that action.\nAs \\(t\\) increases, but \\(N_t(a)\\) doesn’t increase, explore more of that action.\n\n\n\n\n\\begin{algorithm} \\caption{Upper Confidence Bound (UCB) Action Selection} \\begin{algorithmic} \\State{Initialize $\\begin{cases}Q(a)=0\\\\N(a)=0\\end{cases}$ for $a=1,\\dots,k\\qquad$} \\For{$t=1,2,3,\\dots$} \\State{$a_t=\\dsst\\argmax_{a}\\mqty[\\textcolor{red}{Q_t(a)+c\\sqrt{\\dfrac{\\ln(t)}{N_t(a)}}}]\\qquad$} \\# breaks ties randomly \\State{Take action $a_t$, receive reward $r_t$} \\State{update: $\\begin{cases}N(a_t)\\gets N(a_t)+1\\\\Q(a_t)\\gets Q(a_t)+\\dfrac{1}{N(a_t)}\\qty\\Big[r_t-Q(a_t)]\\end{cases}\\qquad$} \\# incremental implementation of sample average \\EndFor \\end{algorithmic} \\end{algorithm}"
  },
  {
    "objectID": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html#example-best-arm-to-pull",
    "href": "notes/cs334/13-Reinforcement-Learning/13-Reinforcement-Learning.html#example-best-arm-to-pull",
    "title": "13 Reinforcement Learning",
    "section": "Example: Best Arm to Pull",
    "text": "Example: Best Arm to Pull\n\naction \\(1\\): \\(\\mu(a)=8\\)\naction \\(2\\): \\(\\mu(a)=12\\)\naction \\(3\\): \\(\\mu(a)=12.5\\)\naction \\(4\\): \\(\\mu(a)=11\\)\n\nAction \\(3\\) is the best since \\(\\mu(a)\\) is the highest. If we know \\(\\mu(a)\\) for \\(a\\in\\mathcal{A}\\), then always taking \\(a=3\\) givesn the highest cummulative reward."
  },
  {
    "objectID": "notes/cs334/14-Recommender-Systems/14-Recommender-Systems.html#nearest-neighbors-prediction",
    "href": "notes/cs334/14-Recommender-Systems/14-Recommender-Systems.html#nearest-neighbors-prediction",
    "title": "14 Recommender Systems",
    "section": "Nearest Neighbors Prediction",
    "text": "Nearest Neighbors Prediction\n\n\\(KNN(a,i)\\): \\(k\\) nearest neighbors\n\nThe \\(k\\) most similar users to \\(a\\), who has rated movie \\(i\\). \\[\\hat Y_{a,i}=\\dfrac{1}{\\abs{KNN(a,i)}}\\sum_{b\\in KNN(a,i)}Y_{b,i}\\]\nHow to find \\(KNN\\)? Correlation. Also, we can consider an average correction.\nPro: Interpretable, easy to implement.\nCon: Slow."
  },
  {
    "objectID": "notes/cs334/14-Recommender-Systems/14-Recommender-Systems.html#matrix-factorization",
    "href": "notes/cs334/14-Recommender-Systems/14-Recommender-Systems.html#matrix-factorization",
    "title": "14 Recommender Systems",
    "section": "Matrix Factorization",
    "text": "Matrix Factorization\n\nNotation: \\[Y:n\\times m,\\] where \\(Y\\) is the ratings, \\(n\\) is the number of users, and \\(m\\) is the number of items.\nProblem: missing entries: not all \\(Y_{a,i}\\)’s are observed. \\(\\implies\\) Matrix completion problem:\n\nFill out the missing entries\nPredict the unkonwn ratings.\n\n\n\nFirst Attempt\n\nLet \\(\\hat Y\\) represent the approximation of the true, unerlying rating matrix. Formulate a regression problem with regularization: \\[J(\\hat Y)=\\dfrac{1}{2}=\\sum_{a,i\\in D}\\qty(Y_{ai}-\\hat Y_{ai}^2+\\dfrac{\\lambda}{2}\\sum_{a,i}\\hat Y_{ai}^2),\\] where \\(D\\) is the set of observed data and the regularization term is added to all data.\nObjective: find \\(\\hat Y\\) that minimizes \\(J(\\hat Y)\\). FOC gives us \\[\\pdv{J}{\\hat Y_{ai}}=-\\1\\qty{(a,i)\\in D}\\qty(Y_{ai}-\\hat Y_{ai})+\\lambda\\hat Y_{ai}\\overset{\\text{set}}{=}0.\\]\n\nIf \\((a,i)\\notin D\\): unobserved entries: \\[\\hat Y_{ai}=0\\quad\\text{constantly predicting }0\\]\nIf \\((a,i)\\in D\\): observed data: \\[\n\\begin{aligned}\n-\\qty(Y_{ai}-\\hat Y_{ai})+\\lambda\\hat Y_{ai}&=0\\\\\n\\hat Y_{ai}&=\\dfrac{Y_{ai}}{1+\\lambda}\\quad\\longrightarrow\\text{shrinking real values}\n\\end{aligned}\n\\] So, we have a trivial solution that is not useful.\n\nProblem: without constraints, we can set each entry independently.\nIdea: impose a constraint such that row/column are linearly dependent.\n\nUse a low-rank approximation via matrix factorization (constraint on rank).\n\n\n\n\nLow-Rank Approximation\n\\[\nY\\text{ is }n\\times m\\qquad\\xrightarrow{\\quad\\text{approximation}\\quad} \\hat Y=UV^\\top,\\quad\\text{where }U\\in\\R^{n\\times k}, V\\in\\R^{m\\times d}.\n\\]\n\n\\(\\rank(\\hat Y)=\\min\\qty{\\rank(U),\\rank(V)}\\).  If we choose \\(d\\in\\min\\qty{m,n}\\), then \\(\\rank(\\hat Y)=d\\).  So, \\(\\hat Y\\) is not full rank, and entries of \\(\\hat Y\\) are not linearly independent.\n**Goal: Learn \\(U\\) and \\(V\\) such that \\(\\hat Y\\) is a good approximation of \\(Y\\).\nNotation:  Let \\(\\va u^{(a)}\\in\\R^d\\) be the \\(a\\)-th row of \\(U\\): \\[U=\\mqty[-&\\va u^{(1)\\top}&-\\\\&\\vdots\\\\-&\\va u^{(n)^\\top}&-].\\] Let \\(\\va v^{(i)}\\in\\R^d\\) be the \\(i\\)-th row of \\(V\\): \\[V=\\mqty[|&&|\\\\\\va v^{(1)}&\\cdots&\\va v^{(m)}\\\\|&&|].\\] Then, \\[\\mqty[UV^\\top]_{a,i}=\\va u^{(a)}\\cdot\\va v^{(i)}=\\hat Y_{a,i}.\\]\nThen, the new objective function is \\[\n\\begin{aligned}\nJ(U,V)&=\\dfrac{1}{2}\\sum_{(a,i)\\in D}\\qty(Y_{ai}-\\mqty[UV^\\top]_{a,i})^2+\\dfrac{\\lambda}{2}\\sum_{a=1}^n\\sum_{k=1}^dU_{ak}^2+\\dfrac{\\lambda}{2}\\sum_{i=1}^m\\sum_{k=1}^dV_{i,k}^2\\\\\n&=\\dfrac{1}{2}\\sum_{(a,i)\\in D}\\qty(Y_{ai}-\\va u^{(a)}\\cdot\\va v^{(i)})^2+\\dfrac{\\lambda}{2}\\sum_{a=1}^n\\norm{\\va u^{(a)}}^2+\\dfrac{\\lambda}{2}\\sum_{i=1}^m\\norm{\\va v^{(i)}}^2.\n\\end{aligned}\n\\] Optimization problem: \\[\\min_{U,V}J(U,V).\\]\n\nIf \\(d=\\min\\qty{m,n}\\), then \\(\\hat Y\\) is full rank.  We are reduced to the trivial solution since each element can be chosen independently.\nThe smaller \\(d\\), the more constrained the problem becomes.  Both \\(d\\) and \\(\\lambda\\) are hyperparameters.\n\nHow do we solve for this? Symmetry\n\nIf we know \\(U\\), we can solve \\(V\\). (\\(U\\) is feature and \\(V\\) is parameter).\nIf we know \\(V\\), we can solve \\(U\\).\nAlternative minimization.\n\n\n\n\n\\begin{algorithm} \\caption{Alternative Minimization} \\begin{algorithmic} \\State{(0) Initialize movie feature vectors randomly $\\va v^{(1)},\\va v^{(2)},\\dots,\\va v^{(m)}$.} \\While{not converged} \\State{\\# Stop when $U$ and $V$ does not change} \\State{(1) Fix $\\va v^{(1)},\\dots,\\va v^{(m)}$, solve for $\\va u^{(1)},\\dots,\\va u^{(n)}$:} \\State{$\\qquad\\dsst\\min_{\\va u^{(a)}}\\dfrac{1}{2}\\sum_{i\\in D_a}\\qty(Y_{ai}-\\va u^{(a)}\\cdot\\va v^{(i)})^2+\\dfrac{\\lambda}{2}\\norm{\\va u^{(a)}}^2$.} \\# $D_a$: all movies rated by user $a$; ridge regression \\State{Do this for each $a=1,\\dots,n$, we have} \\State{$\\qquad\\va u^{(a)},\\dots,\\va u^{(n)}$.} \\State{(2) Fix $\\va u^{(1)},\\dots,\\va u^{(n)}$, solve for $\\va v^{(1)},\\dots,\\va v^{(m)}$.} \\State{$\\qquad\\dsst\\min_{\\va v^{(i)}}\\dfrac{1}{2}\\sum_{a\\in D_i}\\qty(Y_{ai}-\\va u^{(a)}\\cdot\\va v^{(i)})^2+\\dfrac{\\lambda}{2}\\norm{\\va v^{(i)}}^2$.} \\# $D_i$: all users rated movie $i$; ridge regression \\State{Do this for each $i=1,\\dots,m$, we get} \\State{$\\qquad\\va v^{(1)},\\dots,\\va v^{(m)}$.} \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\n\nTheoretical guarantees:\n\n\\(J(U,V)\\) monotonically decreases as we iterate.\nPotentially many local minima. So, initialization is important.\n\n\n\n\n\n\n\n\n\nExample 1 (Alternating Minimization Example) \\[\nY=\\mqty[5&?&7\\\\?&2&?\\\\7&1&4\\\\4&?&?\\\\?&3&6]\n\\]\n\nHyperparameters: \\(d=1\\), \\(\\lambda=1\\).\nAfter some iterations, we have \\[U=\\mqty[6,2,3,3,5]^\\top\\quad\\text{and}\\quad V=\\mqty[4,1,5]^\\top.\\]\nThen, we will update \\(u^{(1)}\\) as follows\n\n\\(\\text{error}=\\qty(Y_{1,1}-\\hat Y_{1,1})^2=\\qty(5-6\\times4)^2=19^2\\).\nFix \\(V\\), update \\(U\\). Find \\(u^{(1)}\\). \\[\\tag{Objective}\\min_{u^{(1)}}\\dfrac{1}{2}\\sum_{i\\in D_1}\\qty(Y_{1i}-u^{(1)}v^{(i)})^2+\\dfrac{1}{2}\\qty(u^{(1)})^2\\equiv J\\qty(u^{(1)})\\] \\[\n\\begin{aligned}\nJ\\qty(u^{(1)})&=\\dfrac{1}{2}\\qty[\\qty(Y_{11}-u^{(1)}v^{(1)})^2+\\qty(Y_{13}-u^{(1)}v^{(3)})^2]+\\dfrac{1}{2}\\qty(u^{(1)})^2\\\\\n&=\\dfrac{1}{2}\\qty[\\qty(5-4u^{(1)})^2+\\qty(7-5u^{(1)})^2]+\\dfrac{1}{2}\\qty(u^{(1)})^2\n\\end{aligned}\n\\] So, the FOC gives us \\[\n\\begin{aligned}\n\\dv{u^{(1)}}J\\qty(u^{(1)})=-4\\qty(5-4u^{(1)})-5\\qty(7-5u^{(1)})+u^{(1)}&=0\\\\\n-20+16u^{(1)}-35+25u^{(1)}+u^{(1)}&=0\\\\\n42u^{(1)}&=55\\\\\nu^{(1)}&=\\dfrac{55}{42}\\approx 1.31\n\\end{aligned}\n\\]\nHence, the new \\(\\hat Y\\) is \\[\\hat Y_{11}=u^{(1)}\\cdot v^{(1)}=\\dfrac{55}{42}\\times4=\\dfrac{110}{21}\\approx5.24.\\] Then, the new error is \\[\\text{error}=\\qty(Y_{11}-\\hat Y_{11})=\\qty(5-5.24)^2\\approx0.057\\quad\\rightarrow\\text{better!}\\]"
  },
  {
    "objectID": "notes/cs334/15-Clustering/15-Clustering.html#partitional-clustering",
    "href": "notes/cs334/15-Clustering/15-Clustering.html#partitional-clustering",
    "title": "15 Clustering",
    "section": "Partitional Clustering",
    "text": "Partitional Clustering\n\nBasic idea: group similar points.\nGoal: Given a set of examples \\(D=\\qty{\\va x^{(i)}}_{i=0}^N\\), \\(\\va x^{(i)}\\in\\R^d\\).\n\nAssign similar points to the same clusters, and\nAssign dissimilar points to different clusters.\n\nMeasure dissmilarity: Euclidean distance: \\[\\norm{\\va x^{(i)}-\\va x^{(j)}}^2.\\]\nNotation:\n\n\\(C\\): cluster, a set of point indices\n\\(\\va z^{(j)}\\): representative example, cluster centroid.\n\nPartition \\(\\R^d\\) into \\(k\\) convex cells.\n\\(z_j=\\dfrac{1}{\\abs{C_j}}\\sum_{i\\in C_j}\\va x^{(i)}\\).\n\\(C_j=\\qty{i=1,\\dots,N,\\quad\\text{where the closest representative example to }\\va x^{(i)}\\text{ is }\\va z^{(j)}}\\)\n\nGiven \\(C_j\\), we can find \\(z_j\\), and vice versa.\n\n\n\n\n\n\n\n\nFigure 1: Cluster\n\n\n\n\nObjective: Intertia/Within-Cluster Sum of Square/Intra-Cluster Distance \\[\n\\min_{\\textcolor{blue}{\\substack{C_1,\\dots,C_k\\\\\\va z^{(1)},\\dots,\\va z^{(k)}}}}\\textcolor{red}{\\sum_{j=1}^k}\\textcolor{teal}{\\sum_{i\\in C_j}}\\norm{\\va x^{(i)}-\\va z^{(j)}}^2\n\\]\n\n\\(\\dsst\\min_{\\textcolor{blue}{\\substack{C_1,\\dots,C_k\\\\\\va z^{(1)},\\dots,\\va z^{(k)}}}}\\): Find clusters and their centroids.\n\\(\\dsst\\textcolor{red}{\\sum_{j=1}^k}\\): Sum over all clusters.\n\\(\\dsst\\textcolor{teal}{\\sum_{i\\in C_j}}\\): Sum over points in each cluster.\nThis problem is NP-hard.\nWe have efficient heuristics to find local optimum.\n\n\n\n\n\\begin{algorithm} \\caption{K-Means Clustering (Alternating Minimization)} \\begin{algorithmic} \\State{Initialize $\\va z^{(1)},\\dots,\\va z^{(k)}$ randomly.} \\While{not converged} \\For{$j=1,\\dots,k$} \\State{$C_j=\\qty{i=1,\\dots,N,\\text{ where the closest representative example for }\\va x^{(i)}\\text{ is }\\va z^{(j)}}$} \\EndFor \\For{$j=1,\\dots,k$} \\State{$\\dsst\\va z^{(j)}=\\dfrac{1}{\\abs{C_j}}\\sum_{i\\in C_j}\\va x^{(i)}$} \\EndFor \\EndWhile \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\n\n\nExample 1 (K-Means Example)  \n\n\n\n\n\n\nFigure 2: K Means\n\n\n\n\n\\(k=2\\)\nInitialization: \\(\\textcolor{blue}{\\va z^{(1)}=(3,5)}\\) and \\(\\textcolor{red}{\\va z^{(2)}=(1,1)}\\)\nFix \\(\\va z^{(j)}\\). Make assignment:\n\n\n\n\n\n\n\n\n\n\n\n\nPoint\n\\(L^2\\) Distance to \\(\\textcolor{blue}{\\va z^{(1)}}\\)\nto \\(\\textcolor{red}{\\va z^{(2)}}\\)\nAssignment\n\n\n\n\n1\n\\((0,5)\\)\n\\(3\\)\n\\(\\sqrt{17}\\)\n\\(\\textcolor{blue}{C_1}\\)\n\n\n2\n\\((2,5)\\)\n\\(1\\)\n\\(\\sqrt{17}\\)\n\\(\\textcolor{blue}{C_1}\\)\n\n\n3\n\\((1,4)\\)\n\\(\\sqrt{5}\\)\n\\(3\\)\n\\(\\textcolor{blue}{C_1}\\)\n\n\n4\n\\((2,2)\\)\n\\(\\sqrt{10}\\)\n\\(\\sqrt{2}\\)\n\\(\\textcolor{red}{C_2}\\)\n\n\n5\n\\((3,0)\\)\n\\(5\\)\n\\(\\sqrt{5}\\)\n\\(\\textcolor{red}{C_2}\\)\n\n\n6\n\\((3,2)\\)\n\\(3\\)\n\\(\\sqrt{5}\\)\n\\(\\textcolor{red}{C_2}\\)\n\n\n7\n\\((5,0)\\)\n\\(\\sqrt{29}\\)\n\\(\\sqrt{17}\\)\n\\(\\textcolor{red}{C_2}\\)\n\n\n\n\nUpdate centroid:\n\n\\(\\textcolor{blue}{\\va z^{(1)}=(1, 4.67)}\\)\n\\(\\textcolor{red}{\\va z^{(2)}=(3.25, 1)}\\)\n\nWe are converged already because redo the iteration will not change the assignment and clusters anymore.\n\n\n\n\n\n\nConvergence:\n\nClusters/centroids stop changing. If ties are not broken consistently, we may cycle. If it cycles, we know we converged.\n\\(k\\)-means is guaranteed to converge (to local optimum), but we may not necessarily converge to the global optimum.\n\nInitialization:\n\nRandomly\n\\(k\\)-means\\(++\\): accounts for distribution of \\(\\va x\\) in \\(\\R^d\\). This approach tries to “spread it out” more.\nIn general, we repeat \\(k\\)-means multiple times. We choose clustering solution with lowest inertia.\n\nChoosing \\(k\\):\n\nIn some applications, \\(k\\) will be given.\nUse validation data.\nThe “elbow” method: plot inertia vs. \\(k\\). Choose \\(k\\) where the curve starts to flatten out.\n\n\n\n\n\n\n\n\nFigure 3: Elbow Method\n\n\n\n\n\n\n\n\n\n\nRemark 1 (The Elbow Plot). If \\(k=N\\), every point forms its own cluster. \\[\\sum_{j=1}^N\\sum_{i\\in C_j}\\norm{\\va x^{(i)}-\\va z^{(j)}}^2=0\\implies \\va z^{(j)}=\\va x^{(i)}.\\]"
  },
  {
    "objectID": "blogs/2024-12-10-arnoldi/index.html",
    "href": "blogs/2024-12-10-arnoldi/index.html",
    "title": "Polynomial Representation of Arnoldi",
    "section": "",
    "text": "Find \\(q_1,\\dots,q_n\\), orthonormal basis, of the Krylov subspace \\(\\mathcal{K}_n(A,b)=\\sp\\qty{b,Ab,A^2b,\\dots,A^{n-1}b}\\).\n\nArnoldi relation: \\[\nAQ_n=Q_{n+1}H_n,\n\\] where \\(Q_n=\\mqty[q_1&\\dots&q_n]\\) and \\(H_n\\) is an upper Hessenberg matrix.\n\nBy construction of \\(Q_n\\), we know that \\(Q_ny\\in\\mathcal{K}_n(A,b)\\). If we jump to the next iteration, we add \\(A^nb\\) to the Krylov subspace, and so we want to find \\(q_{n+1}\\) such that \\[\nq_{n+1}\\perp \\mathcal{K}_n(A,b)\\cup\\{A^nb\\}.\n\\]\nThat is, we want to minimize the distance between \\(A^nb\\) and the Krylov subspace. Visually, we have the following:"
  },
  {
    "objectID": "blogs/2024-12-10-arnoldi/index.html#arnoldis-method-overview",
    "href": "blogs/2024-12-10-arnoldi/index.html#arnoldis-method-overview",
    "title": "Polynomial Representation of Arnoldi",
    "section": "",
    "text": "Find \\(q_1,\\dots,q_n\\), orthonormal basis, of the Krylov subspace \\(\\mathcal{K}_n(A,b)=\\sp\\qty{b,Ab,A^2b,\\dots,A^{n-1}b}\\).\n\nArnoldi relation: \\[\nAQ_n=Q_{n+1}H_n,\n\\] where \\(Q_n=\\mqty[q_1&\\dots&q_n]\\) and \\(H_n\\) is an upper Hessenberg matrix.\n\nBy construction of \\(Q_n\\), we know that \\(Q_ny\\in\\mathcal{K}_n(A,b)\\). If we jump to the next iteration, we add \\(A^nb\\) to the Krylov subspace, and so we want to find \\(q_{n+1}\\) such that \\[\nq_{n+1}\\perp \\mathcal{K}_n(A,b)\\cup\\{A^nb\\}.\n\\]\nThat is, we want to minimize the distance between \\(A^nb\\) and the Krylov subspace. Visually, we have the following:"
  },
  {
    "objectID": "blogs/2024-12-10-arnoldi/index.html#set-up-an-optimization-problem",
    "href": "blogs/2024-12-10-arnoldi/index.html#set-up-an-optimization-problem",
    "title": "Polynomial Representation of Arnoldi",
    "section": "Set Up an Optimization Problem",
    "text": "Set Up an Optimization Problem\nAs \\(Q_ny\\in\\mathcal{K}_n(A,b)\\), we can rewrite the problem as minimizing the residual \\(r_n=A^nb-Q_ny\\): \\[\n\\min_{y\\in\\C^n}\\|r_n\\|=\\min_{y\\in\\mathbb{C}^n}\\norm{A^nb-Q_ny}_2.\n\\tag{Arnoldi Approx.}\n\\]"
  },
  {
    "objectID": "blogs/2024-12-10-arnoldi/index.html#polynomial-representation",
    "href": "blogs/2024-12-10-arnoldi/index.html#polynomial-representation",
    "title": "Polynomial Representation of Arnoldi",
    "section": "Polynomial Representation",
    "text": "Polynomial Representation\nAs \\(Q_ny\\in\\mathcal{K}_n(A,b)=\\sp\\qty{b,Ab,A^2b,\\dots,A^{n-1}b}\\), we can rewrite \\(Q_ny\\) as linear combinations of \\(b,Ab,A^2b,\\dots,A^{n-1}b\\): \\[\nQ_ny=y_1b+y_2Ab+\\dots+y_nA^{n-1}b\n\\]\nPlug-in this into (Arnoldi Approx.), we get \\[\n\\begin{aligned}\n\\min_{y\\in\\C^n}\\|r_n\\|&=\\min_{y\\in\\C^n}\\norm{A^nb-Q_ny}_2\\\\\n&=\\min_{y\\in\\C^n}\\norm{A^nb-\\qty(y_1b+y_2Ab+\\dots+y_nA^{n-1}b)}_2\\\\\n&=\\min_{y\\in\\C^n}\\norm{A^nb-y_1b-y_2Ab-\\dots-y_nA^{n-1}b}_2\\\\\n&=\\min_{y\\in\\C^n}\\norm{-y_1b-y_2Ab-\\dots-y_nA^{n-1}b+A^nb}_2\\\\\n&=\\min_{y\\in\\C^n}\\|(\\underbrace{-y_1I-y_2A-\\dots-y_nA^{n-1}+A^n}_{p_n(A)})b\\|_2\\\\\n&=\\min_{\\substack{p_n\\in P_n\\\\p_n\\text{ monic}}}\\norm{p_n(A)b}_2.\n\\end{aligned}\n\\]\n\n\n\n[1] Lloyd N. Trefethen and David Bau, “Numerical Linear Algebra, Twenty-fifth Anniversary Edition  SIAM Publications Library,” Other Titles in Applied Mathematics. https://epubs.siam.org/doi/book/10.1137/1.9781611977165."
  },
  {
    "objectID": "notes/NumericalAnalysis3.html",
    "href": "notes/NumericalAnalysis3.html",
    "title": "PhD-Level Numerical Analysis II",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "notes/IBMath.html",
    "href": "notes/IBMath.html",
    "title": "IB Math AA HL Notes",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/LA.html",
    "href": "notes/LA.html",
    "title": "Linear Algebra",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/LADR.html",
    "href": "notes/LADR.html",
    "title": "Linear Algebra Done Right",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/MathStats.html#statistical-inference",
    "href": "notes/MathStats.html#statistical-inference",
    "title": "Mathematical Statistics – Probability Theory",
    "section": "Statistical Inference",
    "text": "Statistical Inference"
  },
  {
    "objectID": "notes/Prob.html#statistical-inference",
    "href": "notes/Prob.html#statistical-inference",
    "title": "Mathematical Statistics – Probability Theory",
    "section": "Statistical Inference",
    "text": "Statistical Inference"
  },
  {
    "objectID": "notes/Prob copy.html#statistical-inference",
    "href": "notes/Prob copy.html#statistical-inference",
    "title": "Mathematical Statistics – Probability Theory",
    "section": "Statistical Inference",
    "text": "Statistical Inference"
  },
  {
    "objectID": "notes/Prob.html",
    "href": "notes/Prob.html",
    "title": "Mathematical Statistics – Probability Theory",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/Inference.html#statistical-inference",
    "href": "notes/Inference.html#statistical-inference",
    "title": "Mathematical Statistics – Statistical Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference"
  },
  {
    "objectID": "notes/Inference.html",
    "href": "notes/Inference.html",
    "title": "Mathematical Statistics – Statistical Inference",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/NonlinearOpt.html",
    "href": "notes/NonlinearOpt.html",
    "title": "Nonlinear Optimization",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/NumericalDEs.html",
    "href": "notes/NumericalDEs.html",
    "title": "Numerical ODEs and PDEs",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/NA2.html",
    "href": "notes/NA2.html",
    "title": "PhD-Level Numerical Analysis I (Numerical Linear Algebra)",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/NA3.html",
    "href": "notes/NA3.html",
    "title": "PhD-Level Numerical Analysis II",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/NA1.html",
    "href": "notes/NA1.html",
    "title": "Undergraduate-Level Numerical Analysis",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/ProofPractice.html#proof-practice",
    "href": "notes/ProofPractice.html#proof-practice",
    "title": "Proof Practice",
    "section": "Proof Practice",
    "text": "Proof Practice"
  },
  {
    "objectID": "notes/ProofPractice.html",
    "href": "notes/ProofPractice.html",
    "title": "Proof Practice",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/Probability.html",
    "href": "notes/Probability.html",
    "title": "Mathematical Statistics – Probability Theory",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/Proofs.html",
    "href": "notes/Proofs.html",
    "title": "Mathematical Proofs",
    "section": "",
    "text": "📖 Open in new tab  |  📄 Download PDF \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs171.html",
    "href": "notes/cs171.html",
    "title": "CS 171 Introduction to Computer Science II",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLecture 1 Introduction & Review\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nOOP\n\n\nData Structure\n\n\n\nThis lecture introduces the purpose of studying algorithms and data structures. It also does some review on Java and its code basics.\n\n\n\n\n\nAug 29, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 2 Objects and Classes\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nOOP\n\n\nObjects\n\n\nClass\n\n\n\nThis lecture introduces the concepts of OOP in Java.\n\n\n\n\n\nSep 7, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 3 Packages\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nOOP\n\n\nPakcage\n\n\n\nBased on Objects and Classes, this lecture extends the idea and introduces Packages and how it works in Java.\n\n\n\n\n\nSep 16, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 4 Inheritance and Polymorphism\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nOOP\n\n\nInhertiance\n\n\nPolymorphism\n\n\n\nThis lecture is a more detailed lecture on inheritance and polymorphism, two very essential concepts in OOP.\n\n\n\n\n\nSep 19, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 5 Abstract Classes and Interfaces\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nOOP\n\n\nInterface\n\n\nAbstract Class\n\n\n\nThis lecture touches on abstract classes and extends it to interfaces. It also introduces Iterator and Iterable interfaces in Java and how to use them in practice. \n\n\n\n\n\nOct 4, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 6 Generic Classes and Generic Methods\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nGenerics\n\n\n\nThis lecture discusses the use of generic class and generic methods in Java. It also touches on the use of generic classes in practice.\n\n\n\n\n\nOct 10, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 7 Array Data Structure\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nArray\n\n\n\nStarting from this lecture, we discuss some data structures. The very basic data structure of discussion is the array data structure.\n\n\n\n\n\nOct 14, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 8 Stack\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nStack\n\n\n\nThis lecture discusses the stack data structure and its implementation in Java.\n\n\n\n\n\nOct 18, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 9 Queue Data Structure\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nQueue\n\n\n\nThis lecture discusses the queue data structure and its implementation in Java.\n\n\n\n\n\nOct 18, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 10 Linked List\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nLinked List\n\n\n\nThis lecture discusses the linked list data structure and its implementation in Java.\n\n\n\n\n\nNov 2, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 11 Complexity Analysis\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithms\n\n\nComplexity Analysis\n\n\n\nStarting from this lecture, we will discuss some sorting algorithms and their complexity analysis. This lecture offers an overview of running time analysis.\n\n\n\n\n\nNov 11, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 12 Sorting Algorithms\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithms\n\n\nSorting\n\n\n\nThis lecture discusses various sorting algorithms and their implementation in Java. It also touches on the runtime analysis of them.\n\n\n\n\n\nDec 4, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 13 Hashing (Hash Table): Implementation and Runtime Analysis\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nAlgorithms\n\n\nHash Table\n\n\nHashing\n\n\n\nThis lecture discusses the hashing algorithm and the hash table data structure. It also covers the implementation of the hash table and the runtime analysis of the hash table operations.\n\n\n\n\n\nDec 6, 2023\n\n\nJiuru Lyu\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "notes/cs253.html",
    "href": "notes/cs253.html",
    "title": "CS 253 Introduction to Data Structure and Algorithms",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n0 Summary of Data Structures\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nData Structure\n\n\n\nThis lecture introduces the basic data structures and their relationships.\n\n\n\n\n\nMay 8, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n1 Array List\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nArray List\n\n\n\nThis lecture introduces the basic concepts of array and ArrayList in Java.\n\n\n\n\n\nMay 9, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n2 Linked List, Stack, and Queue\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nLinked List\n\n\nStack\n\n\nQueue\n\n\n\nThis lecture introduces the basic concepts of linked list, stack, and queue in Java.\n\n\n\n\n\nMay 10, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n3 Priority Queues and Heaps\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nPriority Queue\n\n\nHeaps\n\n\n\nThis lecture introduces the basic concepts of priority queues, heaps, and how to implement them in Java.\n\n\n\n\n\nMay 11, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n4 Trees and Binary Search Trees\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nTrees\n\n\n\nThis lecture introduces the basic concepts of trees and binary search trees in Java.\n\n\n\n\n\nMay 12, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n5 Balanced Search Trees and other Types of Trees\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nBalanced Search Trees\n\n\nAVL Trees\n\n\nSplay Trees\n\n\n2-4 Trees\n\n\n\nThis lecture introduces balanced search trees, AVL trees, splay trees, and 2-4 trees in Java.\n\n\n\n\n\nMay 13, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n6 Graph Basics\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nGraph\n\n\n\nThis lecture introduces the basics of graph theory.\n\n\n\n\n\nMay 14, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n7 Directed Acyclic DAG (DAG)\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nData Structure\n\n\nDAG\n\n\n\nThis lecture introduces Directed Acyclic Graphs (DAG) and their properties, including cycle detection and topological sorting.\n\n\n\n\n\nMay 15, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n8 Shortest Path\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nShortest Path\n\n\n\nThis lecture introduces the concept of shortest path in graphs, including BFS for unweighted graphs and Dijkstra’s algorithm for weighted graphs.\n\n\n\n\n\nMay 16, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n9 Union-Find\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nUnion-Find\n\n\n\nThis lecture introduces the Union-Find data structure, which efficiently supports dynamic connectivity operations in graphs.\n\n\n\n\n\nMay 17, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n10 Minimum Spanning Tree (MST)\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nMinimum Spanning Tree\n\n\n\nThis lecture introduces the minimum spanning tree algorithm\n\n\n\n\n\nMay 18, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n11 Maximum Flow\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nMaximum Flow\n\n\n\nThis lecture introduces the Maximum Flow algorithm\n\n\n\n\n\nMay 19, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\n\n\n\n\n\n\n12 Tries\n\n\n\n\n\n\nCoding\n\n\nJava\n\n\nAlgorithm\n\n\nTries\n\n\n\nThis lecture introduces the Trie data structure and its applications\n\n\n\n\n\nMay 20, 2024\n\n\nJiuru Lyu\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/5 Balanced Search Tree and AVL Tree.html",
    "href": "notes/cs253/5 Balanced Search Tree and AVL Tree.html",
    "title": "5 Balanced Search Trees and other Types of Trees",
    "section": "",
    "text": "Balanced Search Trees\n\nMotivation: As seen before, in the worst case, time complexity of a search tree can be up to \\(\\mathcal{O}(n)\\). To optimize the time complexity, we need to balance the tree.\nBalanced Search Trees Examples: \nNote: until now, we have not defined what a balanced search tree is. We will define it in the next section.\n\n\n\nAVL Trees\n\n\n\n\n\n\n\nAVL Trees are a type of balanced search trees such that every internal node v is height balanced, namely the heights of the children of v can differ by at most 1.\n\n\n\n\n- Therefore, AVL trees are balanced. \n- Note: heights of the children means the heights of subtrees rooted at the children.\n\nFact: The height \\(h\\) of an AVL tree storing \\(n\\) nodes is \\(\\mathcal{O}(\\log n)\\).\nProof (by induction): Let define \\(n(h)\\), the minimum number of internal nodes of an AVL tree of height \\(h\\). Base Case: We easily see that \\(n(1)=1\\) and \\(n(2)=2\\).  Inductive Steps: For \\(n&gt;2\\), an AVL tree of height \\(h\\) contains the root node, one AVL subtree of height \\(h-1\\) and another height \\(h-2\\). That is, \\(n(h)=1+n(h-1)+n(h-2)\\). Knowing \\(n(h-1)&gt;n(h-2)\\), we get \\(n(h)&gt;2n(h-2)\\) So, we have \\(n(h)&gt;2n(h-2), n(h)&gt;4n(h-4),\\dots,n(h)&gt;2^in(h-2i)\\) Solving the base case, (i.e., \\(h-2i=1\\)), we get \\(n(h)&gt;2^{h/2-1}\\).  Taking logarithms: \\(h&lt;2\\log n(h)+2\\) Thus, the height of an AVL tree is \\(\\mathcal{O}(\\log n)\\). \\(\\qquad\\blacksquare\\)\nInsert in AVL Tree:\n\nAfter inserting, we need to check if the tree is still height balanced. If not, we need to perform rotations to balance the tree.\nTo perform rebalancing, we need to:\n\nStep 1: Identify the tri-nodes. Unbalanced subtree root, its taller child, and its taller grandchild.\nStep 2: Execute tri-nodes restructure.\n\n\nDelete in AVL Tree:\n\nAfter deleting, we need to check ALL the ancestors of the deleted node to see if the tree is still height balanced. If not, we need to perform rotations to balance the tree.\nSometimes, we need to perform multiple rotations to balance the tree.\nWhen selecting the trinodes, we will use a higher subtree. Pulling up a higher subtree gives us a higher chance to rebalance the tree.\n\n\npublic AVLTree&lt;K,V&gt; extends BinarySearchTree&lt;K,V&gt; {\n  // ... We will redefine the Node class to include the height of the node.\n  // This way, we fasten the speed of computing the height. \n  protected static class Node&lt;E&gt; {\n    public E element;\n    public int height = 0;\n    public Node&lt;E&gt; parent;\n    public Node&lt;E&gt; left;\n    public Node&lt;E&gt; right;\n    public Node(E e, Node&lt;E&gt; above, Node&lt;E&gt; leftChild, Node&lt;E&gt; rightChild) {\n      element = e;\n      parent = above;\n      left = leftChild;\n      right = rightChild;\n    }\n  }\n\n  // method to update the height of a node\n  protected void recomputeHeight(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n    p.height = 1+ Math.max(p.left.height, p.right.height);\n  }\n\n  // The rebalancing method\n  protected void rebalance(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n    int oldHeight, newHeight;\n    do { // Scan potential unblanced nodes from the deleted one up to the root\n      oldHeight = p.height;\n      if (Math.abs(p.left.height - p.right.height) &gt;= 2) { \n        // if the current nodes' subtree is unbalanced\n        p = resructure(tallerChild(tallerChild(p))); // identify the tri-nodes and restructure\n        // Update the height of the nodes\n        // These two are the only two nodes with height changed. \n        recomputeHeight(p.left);\n        recomputeHeight(p.right);\n      }\n      recomputeHeight(p); // update height\n      newHeight = p.height;\n      p = p.parent;\n    } while (oldHeight != newHeight && p != null);\n    // Stopping condition: \n    // 1. The height of the current node does not change \n    //    (if the height changed, it could cause further unbalance and we need to further scan toward the root)\n    // 2. Reach the root so stop\n  }\n\n  // Helper method: finding the taller child of a node\n  protected Node&lt;Entry&lt;K,V&gt;&gt; tallerChild(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n    if (p.left.height &gt; p.right.height) return p.left; // clear winner\n    else if (p.left.height &lt; p.right.height) return p.right; // clear winner\n    else { // tie\n      if (isRoot(p)) return p.left; // choice is irrelevant\n      if (p == p.parent.left) return p.left; // return aligned child\n      else return p.right;\n    }\n  }\n\n  // With the restructure method, we can perform the balanced insertion and deletion.\n  public void insert(K key, V value) {\n    // same as before\n    Node&lt;Entry&lt;K,V&gt;&gt; p  = treeSearch(root, key);\n    if (isExternal(p)) {\n      Entry&lt;K,V&gt; entry = new Entry&lt;&gt;(key, value);\n      expandExternal(p, entry);\n    } else {\n      p.element.value = value;\n    }\n    rebalance(p); // new!!\n  }\n\n  public void delete(K key) {\n    // same as before\n    Node&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key);\n    if (isInternal(p)) {\n      if (isExternal(p.left) || isExternal(p.right)) {\n        deleteHelper(p);\n      } else {\n        Node&lt;Entry&lt;K,V&gt;&gt; replacement = treeMax(p.left);\n        p.element = replacement.element;\n        deleteHelper(replacement);\n      }\n    }\n    rebalance(p.parent); // new!!\n  }\n}\n\nTime Complexity of AVL Tree Operations:\n\nInsertion: \\(\\mathcal{O}(\\log n)\\)\nDeletion: \\(\\mathcal{O}(\\log n)\\)\nSearch: \\(\\mathcal{O}(\\log n)\\)\nNote: The time complexity of AVL tree operations is \\(\\mathcal{O}(\\log n)\\) because the height of an AVL tree is \\(\\mathcal{O}(\\log n)\\).\n\n\n\n\nSplay Trees\n\nMotivation: We want to optimize the time complexity of search operations. That is, we want to make the most frequently accessed nodes to be closer to the root.\n\n\n\n\n\n\n\n\nDefinition 1 A Splay tree is a binary search tree with the following intention: more frequently accessed elements to remain nearer to the root. Thereby, we reduce the typical search times.\n\n\n\n\n\nHow to splay?\n\nTo splay a node, we need to perform a sequence of rotations to bring the node to the root.\nWe will identify the tri-nodes and perform rotation operations accordingly.\n\n\nprivate void splay(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n  while (!isRoot(p)) {\n    // Situation 3: two-node rotation\n    if (p.parent.parent == null) {\n      rotate(p);\n      break;\n    }\n    // Situation 2: tri-node straight line\n    if ((p.parent.left == p) == \n        (p.parent.parent.left == p.parent)) {\n      rotate(p.parent);\n      rotate(p);\n    }\n    // Situation 1: tri-node zig-zag\n    else {\n      rotate(p);\n      rotate(p);\n    }\n  }\n}\n\nWhen to splay?\n\nRecall that we want to splay the most frequently accessed nodes to be closer to the root.\nWhen search(), which node to splay?\n\nSituation 1: If the key is found, we splay the node we found.\nSituation 2: If the target key is not found, we splay the last node we visited.\n\nWhen insert(), which node to splay?\n\nWe splay the node we inserted.\n\nWhen remove(), which node to splay?\n\nWe splay the parent of the removed node.\n\n\n\npublic void accessSplay(K key) {\n  Node&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key);\n  \n  // Situation 1: If the key is found, we splay the node we found.\n  if (!isExternal(p)) {\n    splay(p);\n  } \n  // Situation 2: If the target key is not found, we splay the last node we visited. \n  else {\n    if (p.parent != null) splay(p.parent);\n  }\n}\n\npublic void insertSplay(K key, V value) {\n  // same as before\n  split(p);\n}\n\npublic void deleteSplay(K key) {\n  // same as before\n  splay(p.parent);\n}\n\n\n2-4 Trees\n\nGeneralize Binary Search Tree to Multiway Search Tree\n\nA d-node is a node with d children.\nA multiway search tree is a tree\n\nEach internal node has at least two children: a d-node where \\(d\\geq2\\).\nEach internal d-node \\(w\\) stores an ordered set of \\(d-1\\) key-value pairs: \\((k_1,v_1),\\dots,(k_{d-1},v_{d-1})\\), where \\(k_1\\leq\\cdots\\leq k_{d-1}\\). They separate all the \\(d\\) children \\(c_1,\\dots,c_d\\).\nFor each entry \\((k,v)\\) stored at a node in the subtree of \\(w\\) rooted at \\(c_i\\), \\(i=1,\\dots,d\\), we have that \\(k_{i-1}\\leq k\\leq k_i\\).\nExternal nodes are dummy nodes.\n\n\nA (2,4)-Tree is a special type of multiway search tree with the following additional properties:\n\nSize property: every internal node has at most four children.\nDepth property: all the external nodes have the same depth.\n\n\n\n\n\n\n\n\nFigure 1: 2-4 Tree\n\n\n\n\nProperty of a (2,4)-Tree: The height of a (2,4) tree storing \\(n\\) entries is \\(\\mathcal{O}(\\log n)\\).\n\nProof \\(\\quad\\) As we aim at the worse case situation, we are interested in the “slimmest” situation of the tree, meaning when each node has only two children, where we have:  \\[\\text{number of entries:}\\quad2^0+2^1+\\cdots+2^{h-1}=2^h-1.\\] So, \\[2^h-1\\leq n\\implies h\\leq\\log(n+1).\\qquad\\blacksquare\\]\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#balanced-search-trees",
    "href": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#balanced-search-trees",
    "title": "Balanced Search Trees and other Types of Trees",
    "section": "",
    "text": "Motivation: As seen before, in the worst case, time complexity of a search tree can be up to \\(\\mathcal{O}(n)\\). To optimize the time complexity, we need to balance the tree.\nBalanced Search Trees Examples: \nNote: until now, we have not defined what a balanced search tree is. We will define it in the next section."
  },
  {
    "objectID": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#avl-trees",
    "href": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#avl-trees",
    "title": "5 Balanced Search Trees and other Types of Trees",
    "section": "",
    "text": "AVL Trees are a type of balanced search trees such that every internal node v is height balanced, namely the heights of the children of v can differ by at most 1.\n\n\n\n\n- Therefore, AVL trees are balanced. \n- Note: heights of the children means the heights of subtrees rooted at the children.\n\nFact: The height \\(h\\) of an AVL tree storing \\(n\\) nodes is \\(\\mathcal{O}(\\log n)\\).\nProof (by induction): Let define \\(n(h)\\), the minimum number of internal nodes of an AVL tree of height \\(h\\). Base Case: We easily see that \\(n(1)=1\\) and \\(n(2)=2\\).  Inductive Steps: For \\(n&gt;2\\), an AVL tree of height \\(h\\) contains the root node, one AVL subtree of height \\(h-1\\) and another height \\(h-2\\). That is, \\(n(h)=1+n(h-1)+n(h-2)\\). Knowing \\(n(h-1)&gt;n(h-2)\\), we get \\(n(h)&gt;2n(h-2)\\) So, we have \\(n(h)&gt;2n(h-2), n(h)&gt;4n(h-4),\\dots,n(h)&gt;2^in(h-2i)\\) Solving the base case, (i.e., \\(h-2i=1\\)), we get \\(n(h)&gt;2^{h/2-1}\\).  Taking logarithms: \\(h&lt;2\\log n(h)+2\\) Thus, the height of an AVL tree is \\(\\mathcal{O}(\\log n)\\). \\(\\qquad\\blacksquare\\)\nInsert in AVL Tree:\n\nAfter inserting, we need to check if the tree is still height balanced. If not, we need to perform rotations to balance the tree.\nTo perform rebalancing, we need to:\n\nStep 1: Identify the tri-nodes. Unbalanced subtree root, its taller child, and its taller grandchild.\nStep 2: Execute tri-nodes restructure.\n\n\nDelete in AVL Tree:\n\nAfter deleting, we need to check ALL the ancestors of the deleted node to see if the tree is still height balanced. If not, we need to perform rotations to balance the tree.\nSometimes, we need to perform multiple rotations to balance the tree.\nWhen selecting the trinodes, we will use a higher subtree. Pulling up a higher subtree gives us a higher chance to rebalance the tree.\n\n\npublic AVLTree&lt;K,V&gt; extends BinarySearchTree&lt;K,V&gt; {\n  // ... We will redefine the Node class to include the height of the node.\n  // This way, we fasten the speed of computing the height. \n  protected static class Node&lt;E&gt; {\n    public E element;\n    public int height = 0;\n    public Node&lt;E&gt; parent;\n    public Node&lt;E&gt; left;\n    public Node&lt;E&gt; right;\n    public Node(E e, Node&lt;E&gt; above, Node&lt;E&gt; leftChild, Node&lt;E&gt; rightChild) {\n      element = e;\n      parent = above;\n      left = leftChild;\n      right = rightChild;\n    }\n  }\n\n  // method to update the height of a node\n  protected void recomputeHeight(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n    p.height = 1+ Math.max(p.left.height, p.right.height);\n  }\n\n  // The rebalancing method\n  protected void rebalance(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n    int oldHeight, newHeight;\n    do { // Scan potential unblanced nodes from the deleted one up to the root\n      oldHeight = p.height;\n      if (Math.abs(p.left.height - p.right.height) &gt;= 2) { \n        // if the current nodes' subtree is unbalanced\n        p = resructure(tallerChild(tallerChild(p))); // identify the tri-nodes and restructure\n        // Update the height of the nodes\n        // These two are the only two nodes with height changed. \n        recomputeHeight(p.left);\n        recomputeHeight(p.right);\n      }\n      recomputeHeight(p); // update height\n      newHeight = p.height;\n      p = p.parent;\n    } while (oldHeight != newHeight && p != null);\n    // Stopping condition: \n    // 1. The height of the current node does not change \n    //    (if the height changed, it could cause further unbalance and we need to further scan toward the root)\n    // 2. Reach the root so stop\n  }\n\n  // Helper method: finding the taller child of a node\n  protected Node&lt;Entry&lt;K,V&gt;&gt; tallerChild(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n    if (p.left.height &gt; p.right.height) return p.left; // clear winner\n    else if (p.left.height &lt; p.right.height) return p.right; // clear winner\n    else { // tie\n      if (isRoot(p)) return p.left; // choice is irrelevant\n      if (p == p.parent.left) return p.left; // return aligned child\n      else return p.right;\n    }\n  }\n\n  // With the restructure method, we can perform the balanced insertion and deletion.\n  public void insert(K key, V value) {\n    // same as before\n    Node&lt;Entry&lt;K,V&gt;&gt; p  = treeSearch(root, key);\n    if (isExternal(p)) {\n      Entry&lt;K,V&gt; entry = new Entry&lt;&gt;(key, value);\n      expandExternal(p, entry);\n    } else {\n      p.element.value = value;\n    }\n    rebalance(p); // new!!\n  }\n\n  public void delete(K key) {\n    // same as before\n    Node&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key);\n    if (isInternal(p)) {\n      if (isExternal(p.left) || isExternal(p.right)) {\n        deleteHelper(p);\n      } else {\n        Node&lt;Entry&lt;K,V&gt;&gt; replacement = treeMax(p.left);\n        p.element = replacement.element;\n        deleteHelper(replacement);\n      }\n    }\n    rebalance(p.parent); // new!!\n  }\n}\n\nTime Complexity of AVL Tree Operations:\n\nInsertion: \\(\\mathcal{O}(\\log n)\\)\nDeletion: \\(\\mathcal{O}(\\log n)\\)\nSearch: \\(\\mathcal{O}(\\log n)\\)\nNote: The time complexity of AVL tree operations is \\(\\mathcal{O}(\\log n)\\) because the height of an AVL tree is \\(\\mathcal{O}(\\log n)\\)."
  },
  {
    "objectID": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#splay-trees",
    "href": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#splay-trees",
    "title": "5 Balanced Search Trees and other Types of Trees",
    "section": "Splay Trees",
    "text": "Splay Trees\n\nMotivation: We want to optimize the time complexity of search operations. That is, we want to make the most frequently accessed nodes to be closer to the root.\n\n\n\n\n\n\n\n\nDefinition 1 A Splay tree is a binary search tree with the following intention: more frequently accessed elements to remain nearer to the root. Thereby, we reduce the typical search times.\n\n\n\n\n\nHow to splay?\n\nTo splay a node, we need to perform a sequence of rotations to bring the node to the root.\nWe will identify the tri-nodes and perform rotation operations accordingly.\n\n\nprivate void splay(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n  while (!isRoot(p)) {\n    // Situation 3: two-node rotation\n    if (p.parent.parent == null) {\n      rotate(p);\n      break;\n    }\n    // Situation 2: tri-node straight line\n    if ((p.parent.left == p) == \n        (p.parent.parent.left == p.parent)) {\n      rotate(p.parent);\n      rotate(p);\n    }\n    // Situation 1: tri-node zig-zag\n    else {\n      rotate(p);\n      rotate(p);\n    }\n  }\n}\n\nWhen to splay?\n\nRecall that we want to splay the most frequently accessed nodes to be closer to the root.\nWhen search(), which node to splay?\n\nSituation 1: If the key is found, we splay the node we found.\nSituation 2: If the target key is not found, we splay the last node we visited.\n\nWhen insert(), which node to splay?\n\nWe splay the node we inserted.\n\nWhen remove(), which node to splay?\n\nWe splay the parent of the removed node.\n\n\n\npublic void accessSplay(K key) {\n  Node&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key);\n  \n  // Situation 1: If the key is found, we splay the node we found.\n  if (!isExternal(p)) {\n    splay(p);\n  } \n  // Situation 2: If the target key is not found, we splay the last node we visited. \n  else {\n    if (p.parent != null) splay(p.parent);\n  }\n}\n\npublic void insertSplay(K key, V value) {\n  // same as before\n  split(p);\n}\n\npublic void deleteSplay(K key) {\n  // same as before\n  splay(p.parent);\n}"
  },
  {
    "objectID": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#trees",
    "href": "notes/cs253/5 Balanced Search Tree and AVL Tree.html#trees",
    "title": "5 Balanced Search Trees and other Types of Trees",
    "section": "2-4 Trees",
    "text": "2-4 Trees\n\nGeneralize Binary Search Tree to Multiway Search Tree\n\nA d-node is a node with d children.\nA multiway search tree is a tree\n\nEach internal node has at least two children: a d-node where \\(d\\geq2\\).\nEach internal d-node \\(w\\) stores an ordered set of \\(d-1\\) key-value pairs: \\((k_1,v_1),\\dots,(k_{d-1},v_{d-1})\\), where \\(k_1\\leq\\cdots\\leq k_{d-1}\\). They separate all the \\(d\\) children \\(c_1,\\dots,c_d\\).\nFor each entry \\((k,v)\\) stored at a node in the subtree of \\(w\\) rooted at \\(c_i\\), \\(i=1,\\dots,d\\), we have that \\(k_{i-1}\\leq k\\leq k_i\\).\nExternal nodes are dummy nodes.\n\n\nA (2,4)-Tree is a special type of multiway search tree with the following additional properties:\n\nSize property: every internal node has at most four children.\nDepth property: all the external nodes have the same depth.\n\n\n\n\n\n\n\n\nFigure 1: 2-4 Tree\n\n\n\n\nProperty of a (2,4)-Tree: The height of a (2,4) tree storing \\(n\\) entries is \\(\\mathcal{O}(\\log n)\\).\n\nProof \\(\\quad\\) As we aim at the worse case situation, we are interested in the “slimmest” situation of the tree, meaning when each node has only two children, where we have:  \\[\\text{number of entries:}\\quad2^0+2^1+\\cdots+2^{h-1}=2^h-1.\\] So, \\[2^h-1\\leq n\\implies h\\leq\\log(n+1).\\qquad\\blacksquare\\]"
  },
  {
    "objectID": "notes/cs253/10 Minimum Spanning Tree (MST).html",
    "href": "notes/cs253/10 Minimum Spanning Tree (MST).html",
    "title": "10 Minimum Spanning Tree (MST)",
    "section": "",
    "text": "Claim: Every connected graph has at least one spanning tree.\n\n\n\n\n\n\n\n\nDefinition 1 Minimum Spanning Tree: the spanning tree with the smallest sum of edge weights.\n\n\n\n\n\nApplication of MST:\n\nMinimal total cost of edges to ensure the connectivity of the network.\nFor example, telecommunication networks, computer networks, transportation networks, etc.\n\nKey Property of MST:\n\nFact: In a connected graph, partition the set of vertices into any two groups, there must be \\(\\geq1\\) edges connecting these groups.\nProperty: Among these edges (connecting these groups), the MST of this graph must include the edge with the smallest weight.\n\nProof (by contradiction).\n\n\n\nSuppose among \\((0,1)\\), \\((0,3)\\), \\((3,4)\\), the edge \\((0,3)\\) has the smallest weight but is not included in the MST. Then, one of \\((0,1)\\) and \\((3,4)\\) must be in the MST to ensure the two parts are connected.\n\nHowever, if we add \\((0,3)\\) into the MST, we will therefore get a graph with a cycle involving either \\((0,1)\\) or \\((3,4)\\). Deleting such an edge, we form again a spanning tree. This spanning tree has a smaller weight than our previously defined MST. Therefore, our assumption is wrong. The smallest weight must be involved in the MST. \\(\\qquad\\blacksquare\\)\n\nGeneralization: So, among the edges spanning two groups, the one with the smallest weight must be in the MST:\n\nSmallest weight\nSpanning two groups\n\n\n\n\n\n\nIdea:\n\nFind edges spanning two groups.\nFind the edges with the smallest weight (aka, visit the unvisited vertex closed to the current group).\nUpdate the groups\nRepeat the process until all vertices are visited.\n\n\nAlgorithm (Prim's Algorithm):\n    INPUT: an undirected, weighted, connected graph\n    OUTPUT: a tree\n    INITIALIZATION: \n        1. Randomly pick up a starting vertex\n        2. Initialize all vertices' distances to the starting vertex\n    \n    while (thre is still unvisted vertex) {\n        1. visit the unvisted vertex closest to the tree\n        2. update this vertex's unvisited neighbors' distances to the tree. \n    }\n\nThis algorithm is very similar to Dijkstra’s algorithm. The only difference is that Prim’s algorithm will update the tree’s distance to the unvisited vertex, while Dijkstra’s algorithm will update the distance to the starting vertex.\n\n\n\n\n\nIdea:\n\nFirst, find the edge with the smallest weight.\nThen, find if this edge indeed connects two groups.\nIf so, add this edge to the MST.\nRepeat the process until all vertices are visited.\n\n\nAlgorithm (Kruskal's Algorithm):\n    INPUT: an undirected, weighted, connected graph\n    OUTPUT: All the selected edges that form an MST\n    INTIALIZATION:\n        1. initialize an empty edge list;\n        2. initialize each vertex as a component;\n    \n    while (edge list has less than n-1 edges) {\n        1. get the smallest-weighted unvisted edge;\n        if (this edge spans two different components) {\n            2.1 add this edge to the edge list;\n            2.2 union these two components;\n        }\n    }\n\n\n\n\n\n\n\n\n\n\n\n\nKruskal Algorithm\nPrim’s Algorithm\n\n\n\n\nStep 1\nfind the edge with the smallest weight\nfind the edges spanning two groups\n\n\nStep 2\ntell if it spans two groups\nfind the edges with the smallest weight\n\n\nStep 3\nupdate the groups\nupdate the groups\n\n\nTime Complexity ($N = $ number of vertices and $M = $ number of edges)\n\n\\(\\mathcal{O}((M+N)\\log{N{}})\\)"
  },
  {
    "objectID": "notes/cs253/10 Minimum Spanning Tree (MST).html#introduction",
    "href": "notes/cs253/10 Minimum Spanning Tree (MST).html#introduction",
    "title": "Minimum Spanning Tree (MST)",
    "section": "",
    "text": "Claim: Every connected graph has at least one spanning tree.\n\n!!! note Definition Minimum Spanning Tree: the spanning tree with the smallest sum of edge weights.\n\nApplication of MST:\n\nMinimal total cost of edges to ensure the connectivity of the network.\nFor example, telecommunication networks, computer networks, transportation networks, etc.\n\nKey Property of MST:\n\nFact: In a connected graph, partition the set of vertices into any two groups, there must be \\(\\geq1\\) edges connecting these groups.\nProperty: Among these edges (connecting these groups), the MST of this graph must include the edge with the smallest weight. Proof (by contradiction).\n\n\n\nSuppose among \\((0,1)\\), \\((0,3)\\), \\((3,4)\\), the edge \\((0,3)\\) has the smallest weight but is not included in the MST. Then, one of \\((0,1)\\) and \\((3,4)\\) must be in the MST to ensure the two parts are connected.\n\nHowever, if we add \\((0,3)\\) into the MST, we will therefore get a graph with a cycle involving either \\((0,1)\\) or \\((3,4)\\). Deleting such an edge, we form again a spanning tree. This spanning tree has a smaller weight than our previously defined MST. Therefore, our assumption is wrong. The smallest weight must be involved in the MST. \\(\\qquad\\blacksquare\\)\nGeneralization: So, among the edges spanning two groups, the one with the smallest weight must be in the MST:\n\nSmallest weight\nSpanning two groups"
  },
  {
    "objectID": "notes/cs253/10 Minimum Spanning Tree (MST).html#prims-algorithm-prim-jarnik-algorithm",
    "href": "notes/cs253/10 Minimum Spanning Tree (MST).html#prims-algorithm-prim-jarnik-algorithm",
    "title": "10 Minimum Spanning Tree (MST)",
    "section": "",
    "text": "Idea:\n\nFind edges spanning two groups.\nFind the edges with the smallest weight (aka, visit the unvisited vertex closed to the current group).\nUpdate the groups\nRepeat the process until all vertices are visited.\n\n\nAlgorithm (Prim's Algorithm):\n    INPUT: an undirected, weighted, connected graph\n    OUTPUT: a tree\n    INITIALIZATION: \n        1. Randomly pick up a starting vertex\n        2. Initialize all vertices' distances to the starting vertex\n    \n    while (thre is still unvisted vertex) {\n        1. visit the unvisted vertex closest to the tree\n        2. update this vertex's unvisited neighbors' distances to the tree. \n    }\n\nThis algorithm is very similar to Dijkstra’s algorithm. The only difference is that Prim’s algorithm will update the tree’s distance to the unvisited vertex, while Dijkstra’s algorithm will update the distance to the starting vertex."
  },
  {
    "objectID": "notes/cs253/10 Minimum Spanning Tree (MST).html#kruskals-algorithm",
    "href": "notes/cs253/10 Minimum Spanning Tree (MST).html#kruskals-algorithm",
    "title": "10 Minimum Spanning Tree (MST)",
    "section": "",
    "text": "Idea:\n\nFirst, find the edge with the smallest weight.\nThen, find if this edge indeed connects two groups.\nIf so, add this edge to the MST.\nRepeat the process until all vertices are visited.\n\n\nAlgorithm (Kruskal's Algorithm):\n    INPUT: an undirected, weighted, connected graph\n    OUTPUT: All the selected edges that form an MST\n    INTIALIZATION:\n        1. initialize an empty edge list;\n        2. initialize each vertex as a component;\n    \n    while (edge list has less than n-1 edges) {\n        1. get the smallest-weighted unvisted edge;\n        if (this edge spans two different components) {\n            2.1 add this edge to the edge list;\n            2.2 union these two components;\n        }\n    }"
  },
  {
    "objectID": "notes/cs253/10 Minimum Spanning Tree (MST).html#comparison-of-two-algorithms",
    "href": "notes/cs253/10 Minimum Spanning Tree (MST).html#comparison-of-two-algorithms",
    "title": "10 Minimum Spanning Tree (MST)",
    "section": "",
    "text": "Kruskal Algorithm\nPrim’s Algorithm\n\n\n\n\nStep 1\nfind the edge with the smallest weight\nfind the edges spanning two groups\n\n\nStep 2\ntell if it spans two groups\nfind the edges with the smallest weight\n\n\nStep 3\nupdate the groups\nupdate the groups\n\n\nTime Complexity ($N = $ number of vertices and $M = $ number of edges)\n\n\\(\\mathcal{O}((M+N)\\log{N{}})\\)"
  },
  {
    "objectID": "notes/cs253/2 Linked List, Stack, and Queue.html",
    "href": "notes/cs253/2 Linked List, Stack, and Queue.html",
    "title": "2 Linked List, Stack, and Queue",
    "section": "",
    "text": "Singly Linked List\n\n\n\n\n\n\n\nDefinition 1 A singly linked list is a concrete data structure consisting of a sequence of nodes, starting from a head pointer.\n\n\n\n\n\nEach node stores:\n\nelement\nlink to the next node\n\n\n\n\n\n\n\n\nFigure 1: Singly Linked List\n\n\n\npublic class SinglyLinkedList&lt;E&gt; implements Interable&lt;E&gt; {\n    /* Nested class */\n    private static class Node&lt;E&gt; {\n        private E element;\n        private Node&lt;E&gt; next;\n        public Node(E e, Node&lt;E&gt; n) {\n            element = e;\n            next = n;\n        }\n        public E getElement() { \n            return element; \n        }\n        public Node&lt;E&gt; getNext() {\n            return next;\n        }\n        public void setNext(Node&lt;E&gt; n) {\n            next = n;\n        }\n    } /* End of nested class */\n\n    private Node&lt;E&gt; head = null;\n    private Node&lt;E&gt; tail = null;\n    private int size = 0;\n    public SinglyLinkedList() { }\n}\n\nInserting at the head:\n\nBuild new node\nHave new node point to the old head\nUpdate head to point to new node\n\nInserting at the tail:\n\nBuild new node\nHave old last node point to new node\nUpdate tail to point to new node\n\nRemoving at the head:\n\nUpdate head to point to the next node in the list\nAllow garbage collector to reclaim the former first node\n\nRemoving at the tail: Time complexity = \\(\\mathcal{O}(n)\\)\n\nUpdate tail to point to the second last node in the list (require list traversal)\nUpdate the previous node’s next variable to null\nAllow garbage collector to reclaim the former last node\n\nRemoving at any non-head node: Time complexity = \\(\\mathcal{O}(n)\\)\n\n\n\nDoubly Linked List\n\nA doubly linked list can be traversed forward and backward.\nNodes store:\n\nelement\nlink to the previous node\nlink to the next node\n\nSpecial tail and head nodes\n\n\n\n\n\n\n\nFigure 2: Doubly Linked List\n\n\n\npublic class DoublyLinkedList&lt;E&gt; implements Interable&lt;E&gt; {\n    /* Nested class */\n    private static class Node&lt;E&gt; {\n        public E element;\n        public Node&lt;E&gt; previous;\n        public Node&lt;E&gt; next;\n        public Node(E e, Node&lt;E&gt; p, Node&lt;E&gt; n) {\n            element = e;\n            previous = p;\n            next = n;\n        }\n    } /* End of nested class */\n\n    private Node&lt;E&gt; head;\n    private Node&lt;E&gt; tail;\n    private int size = 0;\n    public DoublyLinkedList() {\n        head = new Node&lt;E&gt;(null, null, null);\n        tail = new Node&lt;E&gt;(null, head, null);\n        head.next = tail;\n    }\n}\n\nDeletion: remove a node n from a doubly linked list: Time complexity = \\(\\mathcal{O}(1)\\)\n\npublic E delete(Node&lt;E&gt; n) {\n    n.previous.next = n.next;\n    n.next.previous = n.previous;\n    size--;\n    return n.element;\n}\n\nInsertion: insert a new node, q, between p and its successor: Time complexity = \\(\\mathcal{O}(1)\\)\n\npublic void insert(E e, Node&lt;E&gt; previous, Node&lt;E&gt; next) {\n    Node&lt;E&gt; current = new Node&lt;E&gt;(e, previous, next);\n    previous.next = current;\n    next.previous = current;\n    size++;\n}\n\nCompare Array List and Linked List (Time complexity comparison)\n\n\n\n\n\nSingly Linked List\nDoubly Linked List\nArray List\n\n\n\n\nInsert at head\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(n)\\)\n\n\nRemove at head\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(n)\\)\n\n\nInsert at tail\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nRemove at tail\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nIndexing\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\n\n\n\nDoubly Linked List (compared to Singly Linked List)\n\nrequires more space to hold the extra pointer\nneeds more time for operating this extra pointer.\n\n\n\n\nStack\n\n\n\n\n\n\n\nDefinition 2 A stack is a collection of objects that are inserted and removed according to the last-in, first-out (LIFO) principle.\n\n\n\n\n\nApplications of Stacks\n\nDirect applications:\n\nPage-visited history in a Web browser\nUndo sequence in a text editor\nChain of method calls in the Java Virtual Machine\nParentheses matching\nHTML Tag Matching\n\nIndirect applications:\n\nAuxiliary data structure for algorithms (e.g. recursion, DFS)\n\n\n\npublic interface Stack&lt;E&gt; {\n    /**\n     * @return the number of element in the stack.\n     */\n    int size();\n\n    /**\n     * @return true if the stack is empty, false otherwise.\n     */\n    boolean isEmpty();\n\n    /**\n     * @return the top element in the stack, null if the stack is empty.\n     */\n    E top();\n\n    /**\n     * Add an element to the top of the stack.\n     * @param e the element to be added.\n     */\n    void push(E e);\n\n    /**\n     * Remove and return the top element from the stack.\n     * @return the top element in the stack, null if the stack is empty.\n     */\n    E pop();\n}\n\nArray-based Stack Implementation\n\npublic class ArrayStack&lt;E&gt; implements Stack&lt;E&gt; {\n    private static final int CAPACITY = 1000;\n    private int t = -1; // index of the top element\n    private E[] data;\n    public ArrayStack() {\n        this(CAPACITY);\n    }\n    public ArrayStack(int capacity) {\n        data = (E[]) new Object[capacity];\n    }\n    public int size() {\n        return t + 1;\n    }\n    public boolean isEmpty() {\n        return t == -1;\n    }\n    public E top() {\n        if (isEmpty())\n            return null;\n        return data[t];\n    }\n    public E pop() {\n        if (isEmpty())\n            return null;\n        E answer = data[t];\n        data[t] = null;\n        t--;\n        return answer;\n    }\n    public void push(E e) {\n        if (size() == data.length)\n            throw new IllegalStateException(\"Stack is full\");\n        data[t+1] = e;\n        t++;\n    }\n}\n\nSingly Linked List-based Stack Implementation\n\npop() is equal to removeFirst() in Singly Linked List.\npush() is equal to addFirst() in Singly Linked List.\n\n\n\n\nQueue\n\n\n\n\n\n\n\nDefinition 3 A queue is a collection of objects that are inserted and removed according to the first-in, first-out (FIFO) principle.\n\n\n\n\n\nApplications of Queues\n\nDirect applications:\n\nWaiting lists\nAccess to shared resources (e.g., printer)\n\nIndirect applications:\n\nAuxiliary data structure for algorithms (e.g., BFS)\nComponent of other data structures (e.g., priority queues)\n\n\n\npublic interface Queue&lt;E&gt; {\n    /**\n     * @return the number of element in the queue.\n     */\n    int size();\n\n    /**\n     * @return true if the queue is empty, false otherwise.\n     */\n    boolean isEmpty();\n\n    /**\n     * @return the first element in the queue, null if the queue is empty.\n     */\n    E first();\n\n    /**\n     * Add an element to the end of the queue.\n     * @param e the element to be added.\n     */\n    void enqueue(E e);\n\n    /**\n     * Remove and return the first element from the queue.\n     * @return the first element in the queue, null if the queue is empty.\n     */\n    E dequeue();\n}\n\nArray-based Queue Implementation (circular array)\n\npublic class ArrayQueue&lt;E&gt; implements Queue&lt;E&gt; {\n    private int f = 0;\n    private int size = 0;\n    private E[] data;\n    private static final int CAPACITY = 1000;\n    public ArrayQueue() {\n        this(CAPACITY);\n    }\n    public ArrayQueue(int capacity) {\n        data = (E[]) new Object[capacity];\n    }\n    public int size() {\n        return size;\n    }\n    public boolean isEmpty() {\n        return size == 0;\n    }\n    public E first() {\n        return data[f];\n    }\n    public E dequeue() {\n        if (isEmpty())\n            return null;\n        E answer = data[f];\n        data[f] = null;\n        f = (f + 1) % data.length;\n        size--;\n        return answer;\n    }\n    public void enqueue(E e) {\n        if (size == data.length)\n            throw new IllegalStateException(\"Queue is full\");\n        data[(f + size) % data.length] = e;\n        size++;\n    }\n}\n\nExtend to dynamic array\n\npublic void enqueue(E e) {\n    if (size == data.length) {\n        E[] temp = (E[]) new Object[2 * data.length];\n        int cur_front = f;\n        for (int k = 0; k &lt; size(); k++) {\n            temp[k] = data[cur_front%data.length];\n            cur_front++;\n        }\n        f = 0;\n        data = temp;\n    }\n    data[(f + size) % data.length] = e;\n    size++;\n}\n\nQueue implemented by Singly Linked List\n\nenqueue() is equal to addLast() in Singly Linked List.\ndequeue() is equal to removeFirst() in Singly Linked List.\n\npublic class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt; {\n  private SinglyLinkedList&lt;E&gt; ll = new SinglyLinkedList();\n\n  public int size() {\n      return ll.size();\n  }\n  public boolean isEmpty() {\n      return size() == 0;\n  }\n  public E first() {\n      return ll.first();\n  }\n  public E dequeue() {\n      return ll.removeFirst();\n  }\n  public void enqueue(E e) {\n      ll.addLast(e);\n  }\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/2 Linked List, Stack, and Queue.html#singly-linked-list",
    "href": "notes/cs253/2 Linked List, Stack, and Queue.html#singly-linked-list",
    "title": "2 Linked List, Stack, and Queue",
    "section": "",
    "text": "Definition 1 A singly linked list is a concrete data structure consisting of a sequence of nodes, starting from a head pointer.\n\n\n\n\n\nEach node stores:\n\nelement\nlink to the next node\n\n\n\n\n\n\n\n\nFigure 1: Singly Linked List\n\n\n\npublic class SinglyLinkedList&lt;E&gt; implements Interable&lt;E&gt; {\n    /* Nested class */\n    private static class Node&lt;E&gt; {\n        private E element;\n        private Node&lt;E&gt; next;\n        public Node(E e, Node&lt;E&gt; n) {\n            element = e;\n            next = n;\n        }\n        public E getElement() { \n            return element; \n        }\n        public Node&lt;E&gt; getNext() {\n            return next;\n        }\n        public void setNext(Node&lt;E&gt; n) {\n            next = n;\n        }\n    } /* End of nested class */\n\n    private Node&lt;E&gt; head = null;\n    private Node&lt;E&gt; tail = null;\n    private int size = 0;\n    public SinglyLinkedList() { }\n}\n\nInserting at the head:\n\nBuild new node\nHave new node point to the old head\nUpdate head to point to new node\n\nInserting at the tail:\n\nBuild new node\nHave old last node point to new node\nUpdate tail to point to new node\n\nRemoving at the head:\n\nUpdate head to point to the next node in the list\nAllow garbage collector to reclaim the former first node\n\nRemoving at the tail: Time complexity = \\(\\mathcal{O}(n)\\)\n\nUpdate tail to point to the second last node in the list (require list traversal)\nUpdate the previous node’s next variable to null\nAllow garbage collector to reclaim the former last node\n\nRemoving at any non-head node: Time complexity = \\(\\mathcal{O}(n)\\)"
  },
  {
    "objectID": "notes/cs253/2 Linked List, Stack, and Queue.html#doubly-linked-list",
    "href": "notes/cs253/2 Linked List, Stack, and Queue.html#doubly-linked-list",
    "title": "2 Linked List, Stack, and Queue",
    "section": "",
    "text": "A doubly linked list can be traversed forward and backward.\nNodes store:\n\nelement\nlink to the previous node\nlink to the next node\n\nSpecial tail and head nodes\n\n\n\n\n\n\n\nFigure 2: Doubly Linked List\n\n\n\npublic class DoublyLinkedList&lt;E&gt; implements Interable&lt;E&gt; {\n    /* Nested class */\n    private static class Node&lt;E&gt; {\n        public E element;\n        public Node&lt;E&gt; previous;\n        public Node&lt;E&gt; next;\n        public Node(E e, Node&lt;E&gt; p, Node&lt;E&gt; n) {\n            element = e;\n            previous = p;\n            next = n;\n        }\n    } /* End of nested class */\n\n    private Node&lt;E&gt; head;\n    private Node&lt;E&gt; tail;\n    private int size = 0;\n    public DoublyLinkedList() {\n        head = new Node&lt;E&gt;(null, null, null);\n        tail = new Node&lt;E&gt;(null, head, null);\n        head.next = tail;\n    }\n}\n\nDeletion: remove a node n from a doubly linked list: Time complexity = \\(\\mathcal{O}(1)\\)\n\npublic E delete(Node&lt;E&gt; n) {\n    n.previous.next = n.next;\n    n.next.previous = n.previous;\n    size--;\n    return n.element;\n}\n\nInsertion: insert a new node, q, between p and its successor: Time complexity = \\(\\mathcal{O}(1)\\)\n\npublic void insert(E e, Node&lt;E&gt; previous, Node&lt;E&gt; next) {\n    Node&lt;E&gt; current = new Node&lt;E&gt;(e, previous, next);\n    previous.next = current;\n    next.previous = current;\n    size++;\n}\n\nCompare Array List and Linked List (Time complexity comparison)\n\n\n\n\n\nSingly Linked List\nDoubly Linked List\nArray List\n\n\n\n\nInsert at head\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(n)\\)\n\n\nRemove at head\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(n)\\)\n\n\nInsert at tail\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nRemove at tail\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nIndexing\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\n\n\n\nDoubly Linked List (compared to Singly Linked List)\n\nrequires more space to hold the extra pointer\nneeds more time for operating this extra pointer."
  },
  {
    "objectID": "notes/cs253/2 Linked List, Stack, and Queue.html#stack",
    "href": "notes/cs253/2 Linked List, Stack, and Queue.html#stack",
    "title": "2 Linked List, Stack, and Queue",
    "section": "Stack",
    "text": "Stack\n\n\n\n\n\n\n\nDefinition 2 A stack is a collection of objects that are inserted and removed according to the last-in, first-out (LIFO) principle.\n\n\n\n\n\nApplications of Stacks\n\nDirect applications:\n\nPage-visited history in a Web browser\nUndo sequence in a text editor\nChain of method calls in the Java Virtual Machine\nParentheses matching\nHTML Tag Matching\n\nIndirect applications:\n\nAuxiliary data structure for algorithms (e.g. recursion, DFS)\n\n\n\npublic interface Stack&lt;E&gt; {\n    /**\n     * @return the number of element in the stack.\n     */\n    int size();\n\n    /**\n     * @return true if the stack is empty, false otherwise.\n     */\n    boolean isEmpty();\n\n    /**\n     * @return the top element in the stack, null if the stack is empty.\n     */\n    E top();\n\n    /**\n     * Add an element to the top of the stack.\n     * @param e the element to be added.\n     */\n    void push(E e);\n\n    /**\n     * Remove and return the top element from the stack.\n     * @return the top element in the stack, null if the stack is empty.\n     */\n    E pop();\n}\n\nArray-based Stack Implementation\n\npublic class ArrayStack&lt;E&gt; implements Stack&lt;E&gt; {\n    private static final int CAPACITY = 1000;\n    private int t = -1; // index of the top element\n    private E[] data;\n    public ArrayStack() {\n        this(CAPACITY);\n    }\n    public ArrayStack(int capacity) {\n        data = (E[]) new Object[capacity];\n    }\n    public int size() {\n        return t + 1;\n    }\n    public boolean isEmpty() {\n        return t == -1;\n    }\n    public E top() {\n        if (isEmpty())\n            return null;\n        return data[t];\n    }\n    public E pop() {\n        if (isEmpty())\n            return null;\n        E answer = data[t];\n        data[t] = null;\n        t--;\n        return answer;\n    }\n    public void push(E e) {\n        if (size() == data.length)\n            throw new IllegalStateException(\"Stack is full\");\n        data[t+1] = e;\n        t++;\n    }\n}\n\nSingly Linked List-based Stack Implementation\n\npop() is equal to removeFirst() in Singly Linked List.\npush() is equal to addFirst() in Singly Linked List."
  },
  {
    "objectID": "notes/cs253/2 Linked List, Stack, and Queue.html#queue",
    "href": "notes/cs253/2 Linked List, Stack, and Queue.html#queue",
    "title": "2 Linked List, Stack, and Queue",
    "section": "Queue",
    "text": "Queue\n!!! note Definition A queue is a collection of objects that are inserted and removed according to the first-in, first-out (FIFO) principle. - Applications of Queues - Direct applications: - Waiting lists - Access to shared resources (e.g., printer) - Indirect applications: - Auxiliary data structure for algorithms (e.g., BFS) - Component of other data structures (e.g., priority queues)\npublic interface Queue&lt;E&gt; {\n    /**\n     * @return the number of element in the queue.\n     */\n    int size();\n\n    /**\n     * @return true if the queue is empty, false otherwise.\n     */\n    boolean isEmpty();\n\n    /**\n     * @return the first element in the queue, null if the queue is empty.\n     */\n    E first();\n\n    /**\n     * Add an element to the end of the queue.\n     * @param e the element to be added.\n     */\n    void enqueue(E e);\n\n    /**\n     * Remove and return the first element from the queue.\n     * @return the first element in the queue, null if the queue is empty.\n     */\n    E dequeue();\n}\n\nArray-based Queue Implementation (circular array)\n\npublic class ArrayQueue&lt;E&gt; implements Queue&lt;E&gt; {\n    private int f = 0;\n    private int size = 0;\n    private E[] data;\n    private static final int CAPACITY = 1000;\n    public ArrayQueue() {\n        this(CAPACITY);\n    }\n    public ArrayQueue(int capacity) {\n        data = (E[]) new Object[capacity];\n    }\n    public int size() {\n        return size;\n    }\n    public boolean isEmpty() {\n        return size == 0;\n    }\n    public E first() {\n        return data[f];\n    }\n    public E dequeue() {\n        if (isEmpty())\n            return null;\n        E answer = data[f];\n        data[f] = null;\n        f = (f + 1) % data.length;\n        size--;\n        return answer;\n    }\n    public void enqueue(E e) {\n        if (size == data.length)\n            throw new IllegalStateException(\"Queue is full\");\n        data[(f + size) % data.length] = e;\n        size++;\n    }\n}\n\nExtend to dynamic array\n\npublic void enqueue(E e) {\n    if (size == data.length) {\n        E[] temp = (E[]) new Object[2 * data.length];\n        int cur_front = f;\n        for (int k = 0; k &lt; size(); k++) {\n            temp[k] = data[cur_front%data.length];\n            cur_front++;\n        }\n        f = 0;\n        data = temp;\n    }\n    data[(f + size) % data.length] = e;\n    size++;\n}\n\nQueue implemented by Singly Linked List\n\nenqueue() is equal to addLast() in Singly Linked List.\ndequeue() is equal to removeFirst() in Singly Linked List.\n\npublic class LinkedListQueue&lt;E&gt; implements Queue&lt;E&gt; {\n  private SinglyLinkedList&lt;E&gt; ll = new SinglyLinkedList();\n\n  public int size() {\n      return ll.size();\n  }\n  public boolean isEmpty() {\n      return size() == 0;\n  }\n  public E first() {\n      return ll.first();\n  }\n  public E dequeue() {\n      return ll.removeFirst();\n  }\n  public void enqueue(E e) {\n      ll.addLast(e);\n  }\n}"
  },
  {
    "objectID": "notes/cs253/4 Trees and Binary Search Trees.html",
    "href": "notes/cs253/4 Trees and Binary Search Trees.html",
    "title": "4 Trees and Binary Search Trees",
    "section": "",
    "text": "Tree Terminology\n\nRoot: The top node in a tree.\nInternal node: node with at least one child.\nExternal node (a.k.a. leaf): node with no children.\nAncestor of a node: parent, grandparent, great-grandparent, etc.\nDescendant of a node: child, grandchild, great-grandchild, etc.\nDepth of a node: number of ancestors.\nHeight of a node: maximum depth of any node.\nSubtree: tree consisting of a node and ALL its descendants.\nSiblings: children sharing the same parent.\nEdge: parent-child pair\nPath: sequence of nodes such that any two consecutive nodes in the sequence form an edge.\nThe relation between number of nodes \\(n\\) and number of edges \\(e\\) is given by \\(n=e+1\\). This is because every node except the root has exactly one incoming edge.\nBinary Trees: Each internal node has at most two children. We call these children the left and right child.\n\nProper Tree: Internal nodes must have two children.\n\nApplication 1: a binary tree associated with a decision process.\n\nInternal nodes: questions with yes/no answer\nExternal nodes: outcomes/decisions\n\nApplication 2: arithmetic expression tree\n\nInternal nodes: operators\nExternal nodes: operands\n\n\nPerfect Tree: All interior nodes have two children, and all leaves have the same depth.\n\nPerfect tree is a special case of proper tree.\n\nComplete Tree: All levels except the last are completed filled, and all nodes in the last level are as far left as possible.\n\n\n\n\nBinary Tree Implementation\n\nArray-based implementation\n\nIt is not efficient when the tree is not complete.\nIf we use array-based implementation, there must be some empty slots in the array if the tree is not complete.\n\nTherefore, we will be using a linked structure based tree. It will attain the following methods:\n\n    public void attach(p, t1, t2);\n    public E remove(p);\n    public int depth(p);\n    public int height(p);\n\n\n\n\n\n\nFigure 1: Linked Structure Based Tree\n\n\n\n\nThe following is a simple implementation of a binary tree.\n\npublic class LinkedBinaryTree&lt;E&gt; {\n    // Static nested class of Node\n    protected static class Node&lt;E&gt; {\n      public E element;\n      public Node&lt;E&gt; parent;\n      public Node&lt;E&gt; left;\n      public Node&lt;E&gt; right;\n      public Node(E e, Node&lt;E&gt; above, Node&lt;E&gt; leftChild, Node&lt;E&gt; rightChild) {\n        element = e;\n        parent = above;\n        left = leftChild;\n          ight = rightChild;\n      }\n    } // End of Node class\n\n    // Basic methods\n    protected Node&lt;E&gt; root = null;\n    private int size = 0;\n    public int size() { return size; }\n    public boolean isEmpty() { return size == 0; }\n    public Node&lt;E&gt; root() { return root; }\n    public LinkedBinaryTree() { }\n    public int numChildren(Node&lt;E&gt; p) {\n      int count = 0;\n      if (p.left != null) count++;\n      if (p.right != null) count++;\n      return count;\n    }\n    public boolean isInternal(Node&lt;E&gt; p) { return numChildren(p) &gt; 0;}\n    public boolean isExternal(Node&lt;E&gt; p) { return numChildren(p) == 0; }\n    public Node&lt;E&gt; addLeft(Node&lt;E&gt; p, E e) {\n      if (p.left != null) throw new IllegalArgumentException(\"p already has a left child\");\n      Node&lt;E&gt; child = new Node&lt;&gt;(e, p, null, null);\n      p.left = child;\n      size++;\n      return child;\n    }\n    public Node&lt;E&gt; addRight(Node&lt;E&gt; p, E e) {\n      if (p.right != null) throw new IllegalArgumentException(\"p already has a right child\");\n      Node&lt;E&gt; child = new Node&lt;&gt;(e, p, null, null);\n      p.right = child;\n      size++;\n      return child;\n    }\n\n    //  Major methods\n    public void attach(Node&lt;E&gt; p, LinkedBinaryTree&lt;E&gt; t1, LinkedBinaryTree&lt;E&gt; t2) {\n      // only hanld nodes with no children\n      if (numChildren(p) &gt; 0) throw new IllegalArgumentException(\"p is not a leaf\");\n      addLeft(p, t1.root.element);\n      addRight(p, t2.root.element);\n    }\n    public E remove(Node&lt;E&gt; p) { ... }\n    public int depth(Node&lt;E&gt; p) { ... }\n    public int height(Node&lt;E&gt; p) { ... }\n}\n\nThe following is an implementation of the remove method.\n\nThe time complexity of the remove method is \\(\\mathcal{O}(1)\\). \n\npublic E remove(Node&lt;E&gt; p) {\n  // only handle nodes with less than two children\n\n  // if two children\n  if (numChildren(p) == 2) throw new IllegalArgumentException(\"p has two children\");\n\n  // operate on child\n  // define a child, to hold the only one child. If no child, then it is null.\n  Node&lt;E&gt; child;\n  if (p.left != null) child = p.left;\n  else child = p.right;\n  if (child != null) child.parent = p.parent;\n  if (p == root) root = child;\n  else {\n    Node&lt;E&gt; parent = p.parent;\n    if (p == parent.left) parent.left = child;\n    else parent.right = child;\n    E temp = p.element;\n    p.parent = null;\n    p.left = null;\n    p.element = null;\n    size--;\n    return temp;\n  }\n}\ndepth() implementation\n\nWe will know the depth of Node p, if we know the depth of its parent.\nWhen p is the root, we knot its depth is 0.\nThe time complexity of the depth method is \\(\\mathcal{O}(d)\\), where \\(d\\) is the actual depth of the node. \n\npublic int depth(Node&lt;E&gt; p) {\n  if (p == root) return 0;\n  else return 1 + depth(p.parent);\n}\nheight() implementation\n\nThe method returns the height of the subtree rooted at p.\nThe height of a node is the maximum of the heights of its children plus 1.\nThe time complexity of the height method is \\(\\mathcal{O}(n)\\).\n\npublic int height(Node&lt;E&gt; p) {\n  int h = 0;\n  if (p.left != null) h = Math.max(h, 1 + height(p.left));\n  if (p.rght != null) h = Math.max(h, 1 + height(p.right));\n  return h;\n}\nAnalysis of Time Complexity\n\n\n\n\n\n\n\n\nMethod\nTime Complexity\n\n\n\n\nsize(), isEmpty()\n\\(\\mathcal{O}(1)\\)\n\n\nroot(), parent(), left(), right(), isInternal(), isExternal(), numChildren()\n\\(\\mathcal{O}(1)\\)\n\n\naddLeft(), addRight(), attach()\n\\(\\mathcal{O}(1)\\)\n\n\nremove(p)\n\\(\\mathcal{O}(1)\\)\n\n\ndepth(p)\n\\(\\mathcal{O}(d)\\)\n\n\nheight(p)\n\\(\\mathcal{O}(n)\\)\n\n\n\n\nIf we use an array-based implementation, the space complexity is \\(\\mathcal{O}(2^n)\\), where \\(n\\) is the number of nodes in the tree.\n\nOn the other hand, using a linked structure based implementation, the space complexity is \\(\\mathcal{O}(n)\\).\n\nData structure of General Trees\nThe following is a simple implementation of a general tree. \n\n\n\nTree Traversal Algorithms\n\nDepth first: visit the current subtree before the siblings\n\nPreorder: visit the subtree’s root, then the other part of the subtree. \n\nprotected void preorderSubtree(Node&lt;E&gt; p, List&lt;Node&lt;E&gt;&gt; record) {\n  record.add(p);\n  if (p.left != null) preorderSubtree(p.left, record);\n  if (p.right != null) preorderSubtree(p.right, record);\n}\n\nPostorder: visit the other part of the subtree, then subtree’s root. \n\nprotected void postorderSubtree(Node&lt;E&gt; p, List&lt;Node&lt;E&gt;&gt; record) {\n  if (p.left != null) postorderSubtree(p.left, record);\n  if (p.right != null) postorderSubtree(p.right, record);\n  record.add(p);\n}\n\nInorder (only for binary trees): visit left branch of the subtree, then subtree’s root, then the right branch of the subtree. \n\nprotected void inorderSubtree(Node&lt;E&gt; p, List&lt;Node&lt;E&gt;&gt; record) {\n  if (p.left != null) inorderSubtree(p.left, record);\n  record.add(p);\n  if (p.right != null) inorderSubtree(p.right, record);\n}\nBreath first: visit the nodes level by level (visit siblings before the current subtree) \n\nIn order to achieve breath first traversal, we will use a LinkedListQueue data structure.\nThe usage of queue structure is because the key idea of our traversal is first in, first out\n\nprotected void breathFirst(List&lt;Node&lt;E&gt;&gt; record) {\n  if (!isEmpty()) {\n    LinkedListQueue&lt;Node&lt;E&gt;&gt; queue = new LinkedListQueue&lt;&gt;();\n    queue.enqueue(root);\n    while (!queue.isEmpty()) {\n      Node&lt;E&gt; current = queue.dequeue();\n      record.add(current);\n      if (current.left != null) queue.enqueue(current.left);\n      if (current.right != null) queue.enqueue(current.right);\n    }\n  }\n}\n\n\n\nBinary Search Trees\n\nMotivation: Search an item from an item collection where items are constantly added or removed. The following functionality will be implemented:\n\nget(k): Returns the value v associated with key k, if such an entry exists; otherwise return null.\ninsert(k,v): associates value v with key k, replacing and returning any existing value if the map already contains an entry with key equal to k.\ndelete(k): removes the entry with key equal to k, if one exists, and returns its value; otherwise return null.\n\n\n\n\n\n\n\n\n\nWhy don’t we use heap or priority queue? - Using a heap, the function get(k) will be slow. - Using a priority queue, the function insert(k,v) and delete(k) will be slow.\n\n\n\n\n\nBinary Search Tree (BST)\n\nA binary search tree is a proper binary tree, where each internal position p stores a key-value pair (k,v) such that\n\nKeys stored in the left subtree of p are less than k.\nKeys stored in the right subtree of p are greater than k.\n\nTo ensure the tree is a proper binary tree, the external nodes are “dummy” (sentinel) nodes. They are fake notes (place-holder) that do not store any key-value pair.\n\n\n\n\n\n\n\n\nFigure 2: Dummy Nodes\n\n\n\n\nGenerally speaking, the time complexity to search for a key in a binary search tree is \\(\\mathcal{O}(h)\\), where \\(h\\) is the height of the tree.\nImplementing treeSearch(p, k)\n\nThe method will return the node containing key k.\nThe idea is to start from the given node p, and then compare the key k with the key of the current node.\nIf the key k is less than that of the current node, we will continue to search in the left subtree. (based on the property of BST)\nOtherwise, we will search the right subtree.\n\npublic Node&lt;Entry&lt;K,V&gt;&gt; treeSearch(Node&lt;Entry&lt;K,V&gt;&gt; p, K key) {\n// Base Cases:\nif (isExternal(p)) return p; // no such key since we are starting at a dummy node\nif (p.element.k == key) return p; // found!\n// Resursive Cases\nelse if (comp.compare(p.element.k, key) &gt; 0)\n  return treeSearch(p.left, key);\nelse \n  return treeSearch(p.right, key);\n}\nImplementing insert(k, v)\n\nThe method will insert the key-value pair (k,v) into the tree. If the key already exists, the value will be replaced.\nThe idea is to first determine the position to insert the key-value pair. So, we will use the treeSearch method to find the position.\n\npublic void insert(K key, V value) {\n// Step 1: find the node\nNode&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key);;\n// Step 2: operate on the node depending on the result\nif (!isExternal(p)) { // Situation 1: the key is found\n  p.element.v = value; // replace the value\n} else { // Situation 2: the key is not found, and we are at a dummy node\n  p.element = new Entry&lt;&gt;(key, value); // insert the key-value pair\n  // udpate the left child\n  addLeft(p, null);\n  // update the right child\n  addRight(p, null);\n}\n}\nImplementing delete(k)\n\nThe method will remove the key-value pair (k,v) from the tree and return the value corresponding to the key k.\nIf the key is not found, the method will return null.\nThere are three possible conditions of the node p:\n\np is a leaf node: we can simply remove the node.\np has only one child: we can remove the node and replace it with its child.\np has two children:\n\nStep 1: Find the node with key being closest to the target node: rightmost node of left-subtree (or leftmost node of right-subtree).\nStep 2: Replace the target node with the node with the closest key.\nStep 3: Delete the original place of the node with the closest key via the remove operation. ```java public void deleteHelper(Node&lt;Entry&lt;K,V&gt;&gt; p) { Node&lt;Entry&lt;K,V&gt;&gt; leaf = (isExternal(p.left) ? p.left : p.right); remove(leaf); remove(p); }\n\n\n\n\npublic Node&lt;Entry&lt;K,V&gt;&gt; treeMax(Node&lt;Entry&lt;K,V&gt;&gt; p) { if (isExternal(p.right)) return p; else treeMax(p.right); }\npublic void delete(K key) { Node&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key); if (isInternal(p)) { if (isExternal(p.left) || isExternal(p.right)) { // Situation 1: p is a leaf node // Situation 2: p has only one child deleteHelper(p); } else { // Situation 3: p has two children // find the rightmost node in the left subtree Node&lt;Entry&lt;K,V&gt;&gt; replacement = treeMax(p.left); // replace p.element = replacement.element; // remove deleteHelper(replacement); } } }\n- Time complexity in terms of $h$, the height of the tree\n\n| Method | Time Complexity |\n|:---:|:---:|\n|`treeSearch(p, k)`| $\\mathcal{O}(h)$ |\n|`insert(k, v)`| $\\mathcal{O}(h)$ |\n|`delete(k)`| $\\mathcal{O}(h)$ |\n  \n  - However, when the tree structure is different, the relationship between $h$ and $n$ (the number of nodes) is different. \n    - The worst case time complexity of the `delete` method is $\\mathcal{O}(n)$, where $n$ is the number of nodes in the tree.\n    - The best case time complexity of the `delete` method is $\\mathcal{O}(h)=\\mathcal{O}(\\log n)$, where $h$ is the height of the tree.\n- Rebalance Trees: \n  \n![Rebalance Trees](figs/RebalanceTree.png){#fig-rebalance-trees width=75%}\n\n- The basic operation for rebalancing is `rotate()`.\n  - Step 1: Link `b`'s parent as `a`'s parent.  \n  - Step 2:\n    - Relink `a` as `b`'s parent\n    - Relink `a`'s child as `b`'s child. \n  ![Rotate](figs/TreeRotation.png){#fig-rotate width=75%}\n```java\nprotected void relink(Node&lt;Entry&lt;K,V&gt;&gt; parent, Node&lt;Entry&lt;K,V&gt;&gt; child, boolean makeLeftChild) {\n  child.parent = parent;\n  if (makeLeftChild) parent.left = child;\n  else parent.right = child;\n}\n\npublic void rotate(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n  // We assue node a has parent as otherwise it is trivial to handle by wrapper. \n  Node&lt;Entry&lt;K,V&gt;&gt; q = p.parent;\n  Node&lt;Entry&lt;K,V&gt;&gt; grandparent = q.parent;\n  if (grandparent == null) {\n    // Corner case: parent is root\n    root = p;\n    p.parent = null;\n  } else {\n    // Step 1\n    relink(grandparent, p, q == grandparent.left);\n  }\n  // Step 2\n  if (p == q.left) {\n    relink(q, p.right, true);\n    relink(p, q, false);\n  } else {\n    relink(q, p.left, false);\n    relink(p, q, true);\n  }\n}\n\nWhen we are handling trinode resturction, there are two possible cases:\n\nSingle rotation \nDouble rotation \n\npublic Node&lt;Entry&lt;K,V&gt;&gt; restructure(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n// We assume node x has parent adn grandparent as otherwise it is trivial to handle by wrapper.\n// x will be the lowest node in trinodes.\nNode&lt;Entry&lt;K,V&gt;&gt; parent = p.parent;\nNode&lt;Entry&lt;K,V&gt;&gt; grandparent = parent.parent;\nif ((grandparent.left == parent) && (parent.left == p) || (grandparent.right == parent) && (parent.right == p)) {\n  rotate(parent);\n  return parent;\n} else {\n  rotate(p);\n  rotate(p);\n  return p;\n}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/4 Trees and Binary Search Trees.html#tree-terminology",
    "href": "notes/cs253/4 Trees and Binary Search Trees.html#tree-terminology",
    "title": "Trees and Binary Search Trees",
    "section": "",
    "text": "Root: The top node in a tree.\nInternal node: node with at least one child.\nExternal node (a.k.a. leaf): node with no children.\nAncestor of a node: parent, grandparent, great-grandparent, etc.\nDescendant of a node: child, grandchild, great-grandchild, etc.\nDepth of a node: number of ancestors.\nHeight of a node: maximum depth of any node.\nSubtree: tree consisting of a node and ALL its descendants.\nSiblings: children sharing the same parent.\nEdge: parent-child pair\nPath: sequence of nodes such that any two consecutive nodes in the sequence form an edge.\nThe relation between number of nodes \\(n\\) and number of edges \\(e\\) is given by \\(n=e+1\\). This is because every node except the root has exactly one incoming edge.\nBinary Trees: Each internal node has at most two children. We call these children the left and right child.\n\nProper Tree: Internal nodes must have two children.\n\nApplication 1: a binary tree associated with a decision process.\n\nInternal nodes: questions with yes/no answer\nExternal nodes: outcomes/decisions\n\nApplication 2: arithmetic expression tree\n\nInternal nodes: operators\nExternal nodes: operands\n\n\nPerfect Tree: All interior nodes have two children, and all leaves have the same depth.\n\nPerfect tree is a special case of proper tree.\n\nComplete Tree: All levels except the last are completed filled, and all nodes in the last level are as far left as possible."
  },
  {
    "objectID": "notes/cs253/4 Trees and Binary Search Trees.html#binary-tree-implementation",
    "href": "notes/cs253/4 Trees and Binary Search Trees.html#binary-tree-implementation",
    "title": "Trees and Binary Search Trees",
    "section": "",
    "text": "Array-based implementation\n\nIt is not efficient when the tree is not complete.\nIf we use array-based implementation, there must be some empty slots in the array if the tree is not complete.\n\nTherefore, we will be using a linked structure based tree. It will attain the following methods:\n\n    public void attach(p, t1, t2);\n    public E remove(p);\n    public int depth(p);\n    public int height(p);\n\n\n\nLinked Structure Based Tree\n\n\n\nThe following is a simple implementation of a binary tree.\n\npublic class LinkedBinaryTree&lt;E&gt; {\n    // Static nested class of Node\n    protected static class Node&lt;E&gt; {\n      public E element;\n      public Node&lt;E&gt; parent;\n      public Node&lt;E&gt; left;\n      public Node&lt;E&gt; right;\n      public Node(E e, Node&lt;E&gt; above, Node&lt;E&gt; leftChild, Node&lt;E&gt; rightChild) {\n        element = e;\n        parent = above;\n        left = leftChild;\n          ight = rightChild;\n      }\n    } // End of Node class\n\n    // Basic methods\n    protected Node&lt;E&gt; root = null;\n    private int size = 0;\n    public int size() { return size; }\n    public boolean isEmpty() { return size == 0; }\n    public Node&lt;E&gt; root() { return root; }\n    public LinkedBinaryTree() { }\n    public int numChildren(Node&lt;E&gt; p) {\n      int count = 0;\n      if (p.left != null) count++;\n      if (p.right != null) count++;\n      return count;\n    }\n    public boolean isInternal(Node&lt;E&gt; p) { return numChildren(p) &gt; 0;}\n    public boolean isExternal(Node&lt;E&gt; p) { return numChildren(p) == 0; }\n    public Node&lt;E&gt; addLeft(Node&lt;E&gt; p, E e) {\n      if (p.left != null) throw new IllegalArgumentException(\"p already has a left child\");\n      Node&lt;E&gt; child = new Node&lt;&gt;(e, p, null, null);\n      p.left = child;\n      size++;\n      return child;\n    }\n    public Node&lt;E&gt; addRight(Node&lt;E&gt; p, E e) {\n      if (p.right != null) throw new IllegalArgumentException(\"p already has a right child\");\n      Node&lt;E&gt; child = new Node&lt;&gt;(e, p, null, null);\n      p.right = child;\n      size++;\n      return child;\n    }\n\n    //  Major methods\n    public void attach(Node&lt;E&gt; p, LinkedBinaryTree&lt;E&gt; t1, LinkedBinaryTree&lt;E&gt; t2) {\n      // only hanld nodes with no children\n      if (numChildren(p) &gt; 0) throw new IllegalArgumentException(\"p is not a leaf\");\n      addLeft(p, t1.root.element);\n      addRight(p, t2.root.element);\n    }\n    public E remove(Node&lt;E&gt; p) { ... }\n    public int depth(Node&lt;E&gt; p) { ... }\n    public int height(Node&lt;E&gt; p) { ... }\n}\n\nThe following is an implementation of the remove method.\n\nThe time complexity of the remove method is \\(\\mathcal{O}(1)\\). \n\npublic E remove(Node&lt;E&gt; p) {\n  // only handle nodes with less than two children\n\n  // if two children\n  if (numChildren(p) == 2) throw new IllegalArgumentException(\"p has two children\");\n\n  // operate on child\n  // define a child, to hold the only one child. If no child, then it is null.\n  Node&lt;E&gt; child;\n  if (p.left != null) child = p.left;\n  else child = p.right;\n  if (child != null) child.parent = p.parent;\n  if (p == root) root = child;\n  else {\n    Node&lt;E&gt; parent = p.parent;\n    if (p == parent.left) parent.left = child;\n    else parent.right = child;\n    E temp = p.element;\n    p.parent = null;\n    p.left = null;\n    p.element = null;\n    size--;\n    return temp;\n  }\n}\ndepth() implementation\n\nWe will know the depth of Node p, if we know the depth of its parent.\nWhen p is the root, we knot its depth is 0.\nThe time complexity of the depth method is \\(\\mathcal{O}(d)\\), where \\(d\\) is the actual depth of the node. \n\npublic int depth(Node&lt;E&gt; p) {\n  if (p == root) return 0;\n  else return 1 + depth(p.parent);\n}\nheight() implementation\n\nThe method returns the height of the subtree rooted at p.\nThe height of a node is the maximum of the heights of its children plus 1.\nThe time complexity of the height method is \\(\\mathcal{O}(n)\\).\n\npublic int height(Node&lt;E&gt; p) {\n  int h = 0;\n  if (p.left != null) h = Math.max(h, 1 + height(p.left));\n  if (p.rght != null) h = Math.max(h, 1 + height(p.right));\n  return h;\n}\nAnalysis of Time Complexity\n\n\n\n\n\n\n\n\nMethod\nTime Complexity\n\n\n\n\nsize(), isEmpty()\n\\(\\mathcal{O}(1)\\)\n\n\nroot(), parent(), left(), right(), isInternal(), isExternal(), numChildren()\n\\(\\mathcal{O}(1)\\)\n\n\naddLeft(), addRight(), attach()\n\\(\\mathcal{O}(1)\\)\n\n\nremove(p)\nO(1)\n\n\ndepth(p)\n\\(\\mathcal{O}(d)\\)\n\n\nheight(p)\n\\(\\mathcal{O}(n)\\)\n\n\n\n\nIf we use an array-based implementation, the space complexity is \\(\\mathcal{O}(2^n)\\), where \\(n\\) is the number of nodes in the tree.\n\nOn the other hand, using a linked structure based implementation, the space complexity is \\(\\mathcal{O}(n)\\).\n\nData structure of General Trees\nThe following is a simple implementation of a general tree."
  },
  {
    "objectID": "notes/cs253/4 Trees and Binary Search Trees.html#tree-traversal-algorithms",
    "href": "notes/cs253/4 Trees and Binary Search Trees.html#tree-traversal-algorithms",
    "title": "Trees and Binary Search Trees",
    "section": "",
    "text": "Depth first: visit the current subtree before the siblings\n\nPreorder: visit the subtree’s root, then the other part of the subtree. \n\nprotected void preorderSubtree(Node&lt;E&gt; p, List&lt;Node&lt;E&gt;&gt; record) {\n  record.add(p);\n  if (p.left != null) preorderSubtree(p.left, record);\n  if (p.right != null) preorderSubtree(p.right, record);\n}\n\nPostorder: visit the other part of the subtree, then subtree’s root. \n\nprotected void postorderSubtree(Node&lt;E&gt; p, List&lt;Node&lt;E&gt;&gt; record) {\n  if (p.left != null) postorderSubtree(p.left, record);\n  if (p.right != null) postorderSubtree(p.right, record);\n  record.add(p);\n}\n\nInorder (only for binary trees): visit left branch of the subtree, then subtree’s root, then the right branch of the subtree. \n\nprotected void inorderSubtree(Node&lt;E&gt; p, List&lt;Node&lt;E&gt;&gt; record) {\n  if (p.left != null) inorderSubtree(p.left, record);\n  record.add(p);\n  if (p.right != null) inorderSubtree(p.right, record);\n}\nBreath first: visit the nodes level by level (visit siblings before the current subtree) \n\nIn order to achieve breath first traversal, we will use a LinkedListQueue data structure.\nThe usage of queue structure is because the key idea of our traversal is first in, first out\n\nprotected void breathFirst(List&lt;Node&lt;E&gt;&gt; record) {\n  if (!isEmpty()) {\n    LinkedListQueue&lt;Node&lt;E&gt;&gt; queue = new LinkedListQueue&lt;&gt;();\n    queue.enqueue(root);\n    while (!queue.isEmpty()) {\n      Node&lt;E&gt; current = queue.dequeue();\n      record.add(current);\n      if (current.left != null) queue.enqueue(current.left);\n      if (current.right != null) queue.enqueue(current.right);\n    }\n  }\n}"
  },
  {
    "objectID": "notes/cs253/4 Trees and Binary Search Trees.html#binary-search-trees",
    "href": "notes/cs253/4 Trees and Binary Search Trees.html#binary-search-trees",
    "title": "Trees and Binary Search Trees",
    "section": "",
    "text": "Motivation: Search an item from an item collection where items are constantly added or removed. The following functionality will be implemented:\n\nget(k): Returns the value v associated with key k, if such an entry exists; otherwise return null.\ninsert(k,v): associates value v with key k, replacing and returning any existing value if the map already contains an entry with key equal to k.\ndelete(k): removes the entry with key equal to k, if one exists, and returns its value; otherwise return null.\n\n\n!!!TIP Why don’t we use heap or priority queue? - Using a heap, the function get(k) will be slow. - Using a priority queue, the function insert(k,v) and delete(k) will be slow.\n\nBinary Search Tree (BST)\n\nA binary search tree is a proper binary tree, where each internal position p stores a key-value pair (k,v) such that\n\nKeys stored in the left subtree of p are less than k.\nKeys stored in the right subtree of p are greater than k.\n\nTo ensure the tree is a proper binary tree, the external nodes are “dummy” (sentinel) nodes. They are fake notes (place-holder) that do not store any key-value pair.\n\n\n\n\n\nDummy Nodes\n\n\n\nGenerally speaking, the time complexity to search for a key in a binary search tree is \\(\\mathcal{O}(h)\\), where \\(h\\) is the height of the tree.\nImplementing treeSearch(p, k)\n\nThe method will return the node containing key k.\nThe idea is to start from the given node p, and then compare the key k with the key of the current node.\nIf the key k is less than that of the current node, we will continue to search in the left subtree. (based on the property of BST)\nOtherwise, we will search the right subtree.\n\npublic Node&lt;Entry&lt;K,V&gt;&gt; treeSearch(Node&lt;Entry&lt;K,V&gt;&gt; p, K key) {\n// Base Cases:\nif (isExternal(p)) return p; // no such key since we are starting at a dummy node\nif (p.element.k == key) return p; // found!\n// Resursive Cases\nelse if (comp.compare(p.element.k, key) &gt; 0)\n  return treeSearch(p.left, key);\nelse \n  return treeSearch(p.right, key);\n}\nImplementing insert(k, v)\n\nThe method will insert the key-value pair (k,v) into the tree. If the key already exists, the value will be replaced.\nThe idea is to first determine the position to insert the key-value pair. So, we will use the treeSearch method to find the position.\n\npublic void insert(K key, V value) {\n// Step 1: find the node\nNode&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key);;\n// Step 2: operate on the node depending on the result\nif (!isExternal(p)) { // Situation 1: the key is found\n  p.element.v = value; // replace the value\n} else { // Situation 2: the key is not found, and we are at a dummy node\n  p.element = new Entry&lt;&gt;(key, value); // insert the key-value pair\n  // udpate the left child\n  addLeft(p, null);\n  // update the right child\n  addRight(p, null);\n}\n}\nImplementing delete(k)\n\nThe method will remove the key-value pair (k,v) from the tree and return the value corresponding to the key k.\nIf the key is not found, the method will return null.\nThere are three possible conditions of the node p:\n\np is a leaf node: we can simply remove the node.\np has only one child: we can remove the node and replace it with its child.\np has two children:\n\nStep 1: Find the node with key being closest to the target node: rightmost node of left-subtree (or leftmost node of right-subtree).\nStep 2: Replace the target node with the node with the closest key.\nStep 3: Delete the original place of the node with the closest key via the remove operation. ```java public void deleteHelper(Node&lt;Entry&lt;K,V&gt;&gt; p) { Node&lt;Entry&lt;K,V&gt;&gt; leaf = (isExternal(p.left) ? p.left : p.right); remove(leaf); remove(p); }\n\n\n\n\npublic Node&lt;Entry&lt;K,V&gt;&gt; treeMax(Node&lt;Entry&lt;K,V&gt;&gt; p) { if (isExternal(p.right)) return p; else treeMax(p.right); }\npublic void delete(K key) { Node&lt;Entry&lt;K,V&gt;&gt; p = treeSearch(root, key); if (isInternal(p)) { if (isExternal(p.left) || isExternal(p.right)) { // Situation 1: p is a leaf node // Situation 2: p has only one child deleteHelper(p); } else { // Situation 3: p has two children // find the rightmost node in the left subtree Node&lt;Entry&lt;K,V&gt;&gt; replacement = treeMax(p.left); // replace p.element = replacement.element; // remove deleteHelper(replacement); } } }\n- Time complexity in terms of $h$, the height of the tree\n\n| Method | Time Complexity |\n|:---:|:---:|\n|`treeSearch(p, k)`| $\\mathcal{O}(h)$ |\n|`insert(k, v)`| $\\mathcal{O}(h)$ |\n|`delete(k)`| $\\mathcal{O}(h)$ |\n  \n  - However, when the tree structure is different, the relationship between $h$ and $n$ (the number of nodes) is different. \n    - The worst case time complexity of the `delete` method is $\\mathcal{O}(n)$, where $n$ is the number of nodes in the tree.\n    - The best case time complexity of the `delete` method is $\\mathcal{O}(h)=\\mathcal{O}(\\log n)$, where $h$ is the height of the tree.\n- Rebalance Trees: \n  \n![Rebalance Trees](figs/RebalanceTree.png)\n\n- The basic operation for rebalancing is `rotate()`.\n  - Step 1: Link `b`'s parent as `a`'s parent.  \n  - Step 2:\n    - Relink `a` as `b`'s parent\n    - Relink `a`'s child as `b`'s child. \n  ![Rotate](figs/TreeRotation.png)\n```java\nprotected void relink(Node&lt;Entry&lt;K,V&gt;&gt; parent, Node&lt;Entry&lt;K,V&gt;&gt; child, boolean makeLeftChild) {\n  child.parent = parent;\n  if (makeLeftChild) parent.left = child;\n  else parent.right = child;\n}\n\npublic void rotate(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n  // We assue node a has parent as otherwise it is trivial to handle by wrapper. \n  Node&lt;Entry&lt;K,V&gt;&gt; q = p.parent;\n  Node&lt;Entry&lt;K,V&gt;&gt; grandparent = q.parent;\n  if (grandparent == null) {\n    // Corner case: parent is root\n    root = p;\n    p.parent = null;\n  } else {\n    // Step 1\n    relink(grandparent, p, q == grandparent.left);\n  }\n  // Step 2\n  if (p == q.left) {\n    relink(q, p.right, true);\n    relink(p, q, false);\n  } else {\n    relink(q, p.left, false);\n    relink(p, q, true);\n  }\n}\n\nWhen we are handling trinode resturction, there are two possible cases:\n\nSingle rotation \nDouble rotation \n\npublic Node&lt;Entry&lt;K,V&gt;&gt; restructure(Node&lt;Entry&lt;K,V&gt;&gt; p) {\n// We assume node x has parent adn grandparent as otherwise it is trivial to handle by wrapper.\n// x will be the lowest node in trinodes.\nNode&lt;Entry&lt;K,V&gt;&gt; parent = p.parent;\nNode&lt;Entry&lt;K,V&gt;&gt; grandparent = parent.parent;\nif ((grandparent.left == parent) && (parent.left == p) || (grandparent.right == parent) && (parent.right == p)) {\n  rotate(parent);\n  return parent;\n} else {\n  rotate(p);\n  rotate(p);\n  return p;\n}\n}"
  },
  {
    "objectID": "notes/cs253/11 Maximum Flow.html",
    "href": "notes/cs253/11 Maximum Flow.html",
    "title": "11 Maximum Flow",
    "section": "",
    "text": "Introduction\n\nMincut problem\n\nInput: An edge-weighted digraph (each edge has a positive capacity), source vertex \\(s\\), and target vertex \\(t\\). \n\n\n\n\n\n\n\n\n\nDefinition 1  \n\nA \\(st\\)-cut (aka. cut) is a partition of the vertices into two disjoint sets, with \\(s\\) in one set \\(A\\) and \\(t\\) is the other set \\(B\\).\nIts capacity is the sum of the capacities of the edges from \\(A\\) to \\(B\\).\n\n\n\n\n\n\n\nFigure 1: Cut Capacity\n\n\n\n\n\n\n\n\nMinimum \\(st\\)-ct (mincut) problem: Find a cut of minimum capacity.\nMaxflow problem:\n\nInput: An edge-weighted digraph (each edge has a positive capacity), source vertex \\(s\\), and target vertex \\(t\\).\n\n\n\n\n\n\n\n\n\nDefinition 2  \n\nA \\(st\\)-flow (aka. flow) is an assignment of values to the edges such that:\nCapacity constraint: \\(0\\leq\\text{edge's flow}\\leq\\text{edge's capacity}\\)\nLocal equilibrium: inflow = outflow at every vertex (except \\(s\\) and \\(t\\)).\n\n\n\n\n\n\n\nFigure 2: Flow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 3 The value of a flow is the inflow at \\(t\\) (we assume no edges point to \\(s\\) or from \\(t\\)).\n\n\n\n\n\n\nFigure 3: Value\n\n\n\n\n\n\n\n\nThe maximum flow problem is the find a flow of maximum value.\nEssentially, the mincut problem and the maxflow problem are dual (=equivalent).\n\n\n\nFord-Fulkerson Algorithm\n\nInitialization: Starts with a flow of value 0.\nAugmenting path: Find an undirected path from \\(s\\) to \\(t\\) such that:\n\nCan increase flow on forward edges (not full)  \nCan decrease flow on backward edge (not empty)  \n\nTermination: All paths from \\(s\\) to \\(t\\) are blocked either by a\n\nFull forward edge, or an\nEmpty backward edge.\n\n\n\n\n\n\n\nFigure 4: Termination of Maxflow\n\n\n\n\nAlgorithm (Ford-Fulkerson's Algorithm): \nINPUT: Edge-weighted digraph, source vertex s, target vertex t\nOUTPUT: Maximum flow\n\nStart with 0 flow\nwhile (there exists an augmenting path) {\n     1. find an augmenting path\n     2. compute the bottleneck capacity\n        1. increase flow on that path by bottleneck capacity\n}\n\n\nMaxflow-Mincut Theorem\n\n\n\n\n\n\n\nDefinition 4 The net flow across a cut \\((A,B)\\) is the sum of the flows on its edges from \\(A\\) to \\(B\\) minus the sum of the flows on its edges from \\(B\\) to \\(A\\).\n\n\n\n\n\n\nFigure 5: Net Flow\n\n\n\n\nIn this example, we use black nodes to represent the set \\(A\\) and white nodes to represent the set \\(B\\).\nTherefore, the sum of flows from \\(A\\) to \\(B\\) (bold black arrows) is \\(10+10+0+0+10+5=35\\), and the sum of flows from \\(B\\) to \\(A\\) (bold blue arrows) is \\(0+0+5+5=10\\).\nThe net flow across the cut is \\(35-10=25\\).\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1 (Flow-Value Lemma) Let \\(f\\) be any flow and let \\((A,B)\\) be any cut. Then, the net flow across \\((A,B)\\) equals the value of the flow \\(f\\).\n\nTo think of this lemma intuitively, we can consider the conservation of flow. More formally, we can prove it via induction\n\n\n\nProof.  (by Mathematical Induction). We will induct on the size of \\(B\\)\n\n\nBase Case: \\(B=\\{t\\}\\).\n\nInductive Steps: remains true by local equilibrium when moving any vertex from \\(A\\) to \\(B\\).\\(\\qquad\\blacksquare\\)\n\n\n\n\n\n\n\n\n\n\n\nCorollary 1 Outflow from \\(s\\) \\(=\\) the inflow to \\(t\\) \\(=\\) value of flow.\n\n\n\n\n\n\n\n\n\n\n\nExample 2 (Weak Duality) Let \\(f\\) be any flow and let \\((A,B)\\) be any cut. Then, the value of the flow \\(f\\) is \\(\\leq\\) the capacity of the cut \\((A,B)\\).\nProof.  Note that \\[\\begin{aligned}\\text{Value of flow }f &= \\text{net flow across cut }(A, B)&\\textit{Flow-value Lemma}\\\\&\\leq \\text{capacity of cut }(A, B) &\\textit{Flow bounded by capacity}.\\end{aligned}\\] The proof is complete. \\(\\qquad\\blacksquare\\) \n\n\n\n\n\n\n\n\n\n\n\nTheorem 1 (Augmenting path theorem) A flow \\(f\\) is a maxflow \\(\\iff\\) no augmenting paths.\n\n\n\n\n\n\n\n\n\n\n\nTheorem 2 (Maxflow-mincut theorem) Value of the maxflow \\(=\\) capacity of mincut.\n\n\n\n\n Proof. The following three conditions are equivalent for any flow \\(f\\):\n\n\nThere exists a cut whose capacity equals the value of the flow \\(f\\).\n\n\n\\(f\\) is a maxflow.\n\n\nThere is no augmenting path with respect to \\(f\\).\n\n\n\n1 \\(\\implies\\) 2: Suppose that \\((A,B)\\) is a cut with capacity equal to the value of \\(f\\). Then,\n\n\\[\n  \\begin{aligned}\n  \\text{value of any flow } f' &\\leq \\text{capacity of } (A,B) && \\textit{(by weak duality)} \\\\\n  &= \\text{value of } f && \\textit{(by assumption)}\n  \\end{aligned}\n  \\]\n\nThus, \\(f\\) is a maxflow. \\(\\quad\\square\\)\n\n\n2 \\(\\implies\\) 3: We will prove the contrapositive, i.e., \\(\\neg 3 \\implies \\neg 2\\). Suppose that there is an augmenting path with respect to \\(f\\). Then, we can improve the flow \\(f\\) by sending flow along this path, which implies that \\(f\\) is not a maxflow. \\(\\quad\\square\\)\n\n\n3 \\(\\implies\\) 1: Suppose that there is no augmenting path with respect to \\(f\\). Let \\((A,B)\\) be a cut where \\(A\\) is the set of vertices connected to \\(s\\) by an undirected path with no full forward or empty backward edges. By definition of cut, \\(s \\in A\\). Since there is no augmenting path, \\(t \\in B\\). Then,\n\n\\[\n  \\begin{aligned}\n  \\text{capacity of cut} &= \\text{net flow across cut} && \\textit{(forward edges full; backward edges empty)} \\\\\n  &= \\text{value of flow } f && \\textit{(flow-value lemma)}\n  \\end{aligned}\n  \\]\nWe complete the proof. \\(\\quad\\square\\) \n\nTo compute mincut \\((A,B)\\) from maxflow \\(f\\):\n\nBy augmenting path theorem, no augmenting paths with respect to \\(f\\).\nCompute \\(A=\\) set of vertices connected to \\(s\\) by an undirected path with no full forward or empty backward edges.\n\n\n\n\n\n\n\nFigure 6: Mincut from Maxflow\n\n\n\n\n\n\nJava Implementation of Ford-Fulkerson Algorithm\n\nAugmenting path revisit: it is a sequence of edges from \\(s\\) to \\(t\\), where each edge is:\n\neither “non-full forward edge”\nor “non-empty backward edge”.\n\nBottlenect capacity: the minimum capacity of the edges in the augmenting path.\nBad news: number of augmenting paths could be equal to the value of the maxflow.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/11 Maximum Flow.html#introduction",
    "href": "notes/cs253/11 Maximum Flow.html#introduction",
    "title": "Maximum Flow",
    "section": "",
    "text": "Mincut problem\n\nInput: An edge-weighted digraph (each edge has a positive capacity), source vertex \\(s\\), and target vertex \\(t\\). \n!!! note Definition - A \\(st\\)-cut (aka. cut) is a partition of the vertices into two disjoint sets, with \\(s\\) in one set \\(A\\) and \\(t\\) is the other set \\(B\\). - Its capacity is the sum of the capacities of the edges from \\(A\\) to \\(B\\). \nMinimum \\(st\\)-ct (mincut) problem: Find a cut of minimum capacity.\n\nMaxflow problem:\n\nInput: An edge-weighted digraph (each edge has a positive capacity), source vertex \\(s\\), and target vertex \\(t\\).\n\n!!! note Definition - A \\(st\\)-flow (aka. flow) is an assignment of values to the edges such that: - Capacity constraint: \\(0\\leq\\text{edge's flow}\\leq\\text{edge's capacity}\\) - Local equilibrium: inflow = outflow at every vertex (except \\(s\\) and \\(t\\)). \n!!! note Definition The value of a flow is the inflow at \\(t\\) (we assume no edges point to \\(s\\) or from \\(t\\)). \n\nThe maximum flow problem is the find a flow of maximum value.\n\nEssentially, the mincut problem and the maxflow problem are dual (=equivalent)."
  },
  {
    "objectID": "notes/cs253/11 Maximum Flow.html#ford-fulkerson-algorithm",
    "href": "notes/cs253/11 Maximum Flow.html#ford-fulkerson-algorithm",
    "title": "Maximum Flow",
    "section": "",
    "text": "Initialization: Starts with a flow of value 0.\nAugmenting path: Find an undirected path from \\(s\\) to \\(t\\) such that:\n\nCan increase flow on forward edges (not full)  \nCan decrease flow on backward edge (not empty)  \n\nTermination: All paths from \\(s\\) to \\(t\\) are blocked either by a\n\nFull forward edge, or an\nEmpty backward edge. \n\n\nAlgorithm (Ford-Fulkerson's Algorithm): \nINPUT: Edge-weighted digraph, source vertex s, target vertex t\nOUTPUT: Maximum flow\n\nStart with 0 flow\nwhile (there exists an augmenting path) {\n     1. find an augmenting path\n     2. compute the bottleneck capacity\n        3. increase flow on that path by bottleneck capacity\n}"
  },
  {
    "objectID": "notes/cs253/11 Maximum Flow.html#maxflow-mincut-theorem",
    "href": "notes/cs253/11 Maximum Flow.html#maxflow-mincut-theorem",
    "title": "Maximum Flow",
    "section": "",
    "text": "!!! note Definition The net flow across a cut \\((A,B)\\) is the sum of the flows on its edges from \\(A\\) to \\(B\\) minus the sum of the flows on its edges from \\(B\\) to \\(A\\).  - In this example, we use black nodes to represent the set \\(A\\) and white nodes to represent the set \\(B\\). - Therefore, the sum of flows from \\(A\\) to \\(B\\) (bold black arrows) is \\(10+10+0+0+10+5=35\\), and the sum of flows from \\(B\\) to \\(A\\) (bold blue arrows) is \\(0+0+5+5=10\\). - The net flow across the cut is \\(35-10=25\\).\n!!! example Flow-Value Lemma Let \\(f\\) be any flow and let \\((A,B)\\) be any cut. Then, the net flow across \\((A,B)\\) equals the value of the flow \\(f\\).\n\nTo think of this lemma intuitively, we can consider the conservation of flow. More formally, we can prove it via induction \n\nProof.  (by Mathematical Induction). We will induct on the size of \\(B\\)\n\n\nBase Case: \\(B=\\{t\\}\\).\n\nInductive Steps: remains true by local equilibrium when moving any vertex from \\(A\\) to \\(B\\).\\(\\qquad\\blacksquare\\)\n\n!!! done Corollary Outflow from \\(s\\) \\(=\\) the inflow to \\(t\\) \\(=\\) value of flow.\n!!! example Weak Duality Let \\(f\\) be any flow and let \\((A,B)\\) be any cut. Then, the value of the flow \\(f\\) is \\(\\leq\\) the capacity of the cut \\((A,B)\\).\nProof.  Note that \\[\\begin{aligned}\\text{Value of flow }f &= \\text{net flow across cut }(A, B)&\\textit{Flow-value Lemma}\\\\&\\leq \\text{capacity of cut }(A, B) &\\textit{Flow bounded by capacity}.\\end{aligned}\\] The proof is complete. \\(\\qquad\\blacksquare\\) \n!!! done Augmenting path theorem A flow \\(f\\) is a maxflow \\(\\iff\\) no augmenting paths.\n!!! done Maxflow-mincut theorem Value of the maxflow \\(=\\) capacity of mincut.\nProof.  The following three conditions are equivalent for any flow \\(f\\):\n\n\nThere exists a cut whose capacity equals the value of the flow \\(f\\).\n\n\\(f\\) is a maxflow.\n\nThere is no augmenting path with respect to \\(f\\).\n\nWe will then prove equivalence:\n\n[1$$2]: Suppose that \\((A,B)\\) is a cut with capacity equal to the value of \\(f\\). Then, \\[\\begin{aligned}\\text{value of any flow }f'&\\leq\\text{capacity of }(A,B)&\\textit{weka duality}\\\\&=\\text{value of }f&\\textit{by assumption}.\\end{aligned}\\] Thus, \\(f\\) is a maxflow.\\(\\quad\\square\\)\n\n\n[2$$3]: We will prove the contrapositive. i.e., \\(\\neg3\\implies\\neg2\\). Suppose that there is an augmenting path with respect to \\(f\\). Then, we can improve flow \\(f\\) by sending flow along this path, which implies that \\(f\\) is not a maxflow.\\(\\quad\\square\\)\n\n\n[3$$1]: Suppose that there is not augmenting path with respect to \\(f\\). Let \\((A,B)\\) be a cut where \\(A\\) is the set of vertices connected to \\(s\\) by an undirected path with no full forward or empty backward edges. By definition of cut, \\(s\\) is in \\(A\\). Since no augmenting path, \\(t\\) is in \\(B\\). Then, \\[\\begin{aligned}\\text{capaticy of cut}&=\\text{net flow across cut}&\\text{forward edges full; backward edges empty}\\\\&=\\text{value of flow }f&\\text{flow-value lemma}\\end{aligned}\\]\n\n - To compute mincut \\((A,B)\\) from maxflow \\(f\\): - By augmenting path theorem, no augmenting paths with respect to \\(f\\). - Compute \\(A=\\) set of vertices connected to \\(s\\) by an undirected path with no full forward or empty backward edges."
  },
  {
    "objectID": "notes/cs253/11 Maximum Flow.html#java-implementation-of-ford-fulkerson-algorithm",
    "href": "notes/cs253/11 Maximum Flow.html#java-implementation-of-ford-fulkerson-algorithm",
    "title": "11 Maximum Flow",
    "section": "Java Implementation of Ford-Fulkerson Algorithm",
    "text": "Java Implementation of Ford-Fulkerson Algorithm\n\nAugmenting path revisit: it is a sequence of edges from \\(s\\) to \\(t\\), where each edge is:\n\neither “non-full forward edge”\nor “non-empty backward edge”.\n\nBottlenect capacity: the minimum capacity of the edges in the augmenting path.\nBad news: number of augmenting paths could be equal to the value of the maxflow."
  },
  {
    "objectID": "notes/cs253/6 Graph Basics.html",
    "href": "notes/cs253/6 Graph Basics.html",
    "title": "6 Graph Basics",
    "section": "",
    "text": "Introduction to Graphs\n\nMotivation: DAG are effective abstraction of many real-world problems (Köningberg Bridge Problem)\n\nAdvantage 1: Removing irrelevant information for easier analysis.\nAdvantage 2: Getting general rules across any applications.\nSome applications of graph (graphs are ubiquitous):\n\nMolecular structure\nProtein\nBrain network\nSocial network\nRoad network\nIntegrated circuit\n\n\n\n\n\n\n\n\n\n\nDefinition 1 DAG is a pair of sets \\((V, E)\\), where \\(V\\) is a set of vertices and \\(E\\) is a set of edges, each edge is a pair of vertices.\n\n\n\n\n\nUndirected graph: An edge is a set of two vertices.\n\nAn edge between two vertices is denoted as (“an endpoint”, “the other endpoint”)\nAn edge between Vertices 0 and 1 is denoted as: (0,1)\n\nDirected graph: An edge is an ordered pair of vertices. \n\nAn directed edge from an origin vertex to a destination vertex is denoted as: (origin, destination).\nAn edge from Vertex 0 to Vertex 1 is denoted as: (0,1)\nAn edge from Vertices 2 to 0 is denoted as: (2,0)\n\nWeighted graph: Each edge has a weight. \n\nAn edge with weight from Vertex 0 to Vertex 1 is denoted as: (0,1,3)\nA weighted edge between Vertices 2 and 0 is denoted as: (2,0,4)\n\nRepresenting an undirected graph with a directed graph: \n\n\n\n\n\n\n\n\nDefinition 2 A circle is a path that starts and ends at the same vertex. If there is no circle in a graph, it is called an acyclic graph.\n\n\n\n\n\n\nFigure 1: Circle\n\n\n\n\n\n\n\n\nReal world example of acyclic graph: CS 253 knowledge dependency graph\n\n\n\n\n\n\n\n\nDefinition 3 An undirected graph is connected if, for any two vertices, there is a path between them.\n\n\n\n\n\n\nFigure 2: Connectivity\n\n\n\n\n\n\n\n\nA tree is a connected acyclic graph. \nA forest is a collection of trees. \n\n\n\n\n\n\n\n\nDefinition 4 A graph \\(G'=(V',E')\\) whose vertices and edges are subsets of the vertices and edges of \\(G=(V,E)\\), such that \\(V' \\subseteq V\\) and \\(E' \\subseteq E\\), is called a subgraph of \\(G\\).\n\n\n\n\n\n\nFigure 3: Subgraph\n\n\n\nNote that a graph itself is a subgraph of itself.\n\n\n\n\n\nA spanning subgraph of a graph \\(G\\) is a subgraph that contains all the vertices of \\(G\\). \n\nSuppose \\(G'=(V',E')\\) is a spanning subgraph of \\(G=(V,E)\\), then it must be that \\(V'=V\\) and \\(E' \\subseteq E\\).\n\nA tree \\(T=(V',E')\\) whose vertices are all the vertices of \\(G\\) and edges are a subset of the edges of \\(G\\) is called a spanning tree of \\(G\\). \n\nSuppose \\(T=(V',E')\\) is a spanning tree of \\(G=(V,E)\\), then it must be that \\(V'=V\\) and \\(E' \\subseteq E\\).\nMoreover, \\(T\\) must be a tree.\n\n\n\n\n\n\n\n\n\nDefinition 5  \n\nIn an undirected graph The degree of a vertex is the number of edges incident to it. We denote the degree of a vertex \\(v\\) as \\(d(v)\\).\nIn a directed graph, the in-degree of a vertex is the number of edges that point to it, and the out-degree of a vertex is the number of edges that point from it.\n\n\n\n\n\n\nJava implementatin of a graph:\n\n\n\nDAG Traversal\n\n\n\n\n\n\n\nDefinition 6 A path is a sequence of distinct edges which joins a sequence of distinct vertices. A closed path is called a cycle.\n\n\n\n\n\nIn directed graph, the edge in a path follows the same direction.\n\n\n\n\n\n\n\n\nDefinition 7 We say that \\(u\\) reaches \\(v\\) (aka. \\(v\\) is reachable from \\(u\\)) if there is a path from \\(u\\) to \\(v\\).\n\n\n\n\n\n\n\n\n\n\n\nDefinition 8  \n\nAn undirected graph is connected if, for any two vertices, there is a path between them.\nA directed graph is strongly connected if, for any two vertices \\(u\\) and \\(v\\), \\(u\\) reaches \\(v\\) and \\(v\\) reaches \\(u\\).\nA directed graph is weakly connected if replacing all of its directed edges with undirected edges produces a connected (undirected) graph. \n\n\n\n\n\n\nRelation between vertex degree and number of edges.\n\nLet \\(m\\) be the number of edges and \\(n\\) be the number of vertices.\nIn undirected graph, sum of degrees of all vertices is \\(2m\\).\n\n\\(0\\leq m\\leq\\dfrac{n(n-1)}{2}=\\mathcal{O}(n^2)\\)\n\nIn directed graph, sum of out-degree of all vertices = sum of in-degree of all vertices = \\(m\\).\n\n\\(0\\leq m\\leq n(n-1)=\\mathcal{O}(n^2)\\)\n\n\n\n\n\n\n\n\n\n\nDefinition 9 DAG traversal is A systematic procedure for exploring a graph by examining all of its vertices and edges.\n\n\n\n\n\nWe will discuss two graph traversal algorithms:\n\nBreadth-first search (BFS): explore all the neighbors of a vertex before moving on to the next level of neighbors. We visit vertices level by level.\nDepth-first search (DFS): Explore the graph by going as deep as possible along each branch before backtracking. \n\nDFS: \n\nAlgorithm Overview\n\nAlgorithm DFS(u):\n  for each u's outgoing edges e=(u,v), do {\n      if v is not visited, then {\n          record vertex v and its discovery edge e.\n          Recursively call DFS(v).\n      }\n  }\nBFS: \n\nAlgorithm Overview\n\nAlgorithm BFS(u)\n  initialize a recorder of visited vertices\n  for each level of vertices as long as nonempty {\n      for each vertex in the current level {\n          for each unvisited neighbor of current vertex {\n              add into recorder\n              add all its neighbors into next level\n          }\n      }\n  }\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/6 Graph Basics.html#introduction-to-graphs",
    "href": "notes/cs253/6 Graph Basics.html#introduction-to-graphs",
    "title": "DAG Basics",
    "section": "",
    "text": "Motivation: DAG are effective abstraction of many real-world problems (Köningberg Bridge Problem)\n\nAdvantage 1: Removing irrelevant information for easier analysis.\nAdvantage 2: Getting general rules across any applications.\nSome applications of graph (graphs are ubiquitous):\n\nMolecular structure\nProtein\nBrain network\nSocial network\nRoad network\nIntegrated circuit\n\n\n\n!!! note Definition DAG is a pair of sets \\((V, E)\\), where \\(V\\) is a set of vertices and \\(E\\) is a set of edges, each edge is a pair of vertices.\n\nUndirected graph: An edge is a set of two vertices. \n\nAn edge between two vertices is denoted as (“an endpoint”, “the other endpoint”)\nAn edge between Vertices 0 and 1 is denoted as: (0,1)\n\nDirected graph: An edge is an ordered pair of vertices. \n\nAn directed edge from an origin vertex to a destination vertex is denoted as: (origin, destination).\nAn edge from Vertex 0 to Vertex 1 is denoted as: (0,1)\nAn edge from Vertices 2 to 0 is denoted as: (2,0)\n\nWeighted graph: Each edge has a weight. \n\nAn edge with weight from Vertex 0 to Vertex 1 is denoted as: (0,1,3)\nA weighted edge between Vertices 2 and 0 is denoted as: (2,0,4)\n\nRepresenting an undirected graph with a directed graph: \n\n!!! note Definition A circle is a path that starts and ends at the same vertex. If there is no circle in a graph, it is called an acyclic graph. \n\nReal world example of acyclic graph: CS 253 knowledge dependency graph\n\n!!! note Definition An undirected graph is connected if, for any two vertices, there is a path between them. \n\nA tree is a connected acyclic graph. \nA forest is a collection of trees. \n\n!!! note Definition A graph \\(G'=(V',E')\\) whose vertices and edges are subsets of the vertices and edges of \\(G=(V,E)\\), such that \\(V' \\subseteq V\\) and \\(E' \\subseteq E\\), is called a subgraph of \\(G\\).  Note that a graph itself is a subgraph of itself.\n\nA spanning subgraph of a graph \\(G\\) is a subgraph that contains all the vertices of \\(G\\). \n\nSuppose \\(G'=(V',E')\\) is a spanning subgraph of \\(G=(V,E)\\), then it must be that \\(V'=V\\) and \\(E' \\subseteq E\\).\n\nA tree \\(T=(V',E')\\) whose vertices are all the vertices of \\(G\\) and edges are a subset of the edges of \\(G\\) is called a spanning tree of \\(G\\). \n\nSuppose \\(T=(V',E')\\) is a spanning tree of \\(G=(V,E)\\), then it must be that \\(V'=V\\) and \\(E' \\subseteq E\\).\nMoreover, \\(T\\) must be a tree.\n\n\n!!! note Definition - In an undirected graph The degree of a vertex is the number of edges incident to it. We denote the degree of a vertex \\(v\\) as \\(d(v)\\). - In a directed graph, the in-degree of a vertex is the number of edges that point to it, and the out-degree of a vertex is the number of edges that point from it.\n\nJava implementatin of a graph:"
  },
  {
    "objectID": "notes/cs253/6 Graph Basics.html#dag-traversal",
    "href": "notes/cs253/6 Graph Basics.html#dag-traversal",
    "title": "DAG Basics",
    "section": "",
    "text": "!!! note Definition A path is a sequence of distinct edges which joins a sequence of distinct vertices. A closed path is called a cycle. - In directed graph, the edge in a path follows the same direction.\n!!! note Definition We say that \\(u\\) reaches \\(v\\) (aka. \\(v\\) is reachable from \\(u\\)) if there is a path from \\(u\\) to \\(v\\).\n!!! note Definition - An undirected graph is connected if, for any two vertices, there is a path between them. - A directed graph is strongly connected if, for any two vertices \\(u\\) and \\(v\\), \\(u\\) reaches \\(v\\) and \\(v\\) reaches \\(u\\). - A directed graph is weakly connected if replacing all of its directed edges with undirected edges produces a connected (undirected) graph. \n\nRelation between vertex degree and number of edges.\n\nLet \\(m\\) be the number of edges and \\(n\\) be the number of vertices.\nIn undirected graph, sum of degrees of all vertices is \\(2m\\).\n\n\\(0\\leq m\\leq\\dfrac{n(n-1)}{2}=\\mathcal{O}(n^2)\\)\n\nIn directed graph, sum of out-degree of all vertices = sum of in-degree of all vertices = \\(m\\).\n\n\\(0\\leq m\\leq n(n-1)=\\mathcal{O}(n^2)\\)\n\n\n\n!!! note Definition DAG traversal is A systematic procedure for exploring a graph by examining all of its vertices and edges.\n\nWe will discuss two graph traversal algorithms:\n\nBreadth-first search (BFS): explore all the neighbors of a vertex before moving on to the next level of neighbors. We visit vertices level by level.\nDepth-first search (DFS): Explore the graph by going as deep as possible along each branch before backtracking. \n\nDFS: \n\nAlgorithm Overview\n\nAlgorithm DFS(u):\n  for each u's outgoing edges e=(u,v), do {\n      if v is not visited, then {\n          record vertex v and its discovery edge e.\n          Recursively call DFS(v).\n      }\n  }\nBFS: \n\nAlgorithm Overview\n\nAlgorithm BFS(u)\n  initialize a recorder of visited vertices\n  for each level of vertices as long as nonempty {\n      for each vertex in the current level {\n          for each unvisited neighbor of current vertex {\n              add into recorder\n              add all its neighbors into next level\n          }\n      }\n  }"
  },
  {
    "objectID": "notes/cs253/12 Tries.html",
    "href": "notes/cs253/12 Tries.html",
    "title": "12 Tries",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\n\nDefinition 1  \n\nA String is a sequence of characters.\n\nExamples:\n\nPython program\nHTML document\nDNA sequence\nDigitized image\n\n\nAn alphabet \\(\\mathbf{\\Sigma}\\) is the set of possible characters for a family of strings:\n\nExamples:\n\na, b, c, …, x, y, z\nASCII characters\nUnicode\n{0, 1}\n{A, T, C, G}\n\n\nWe denote the alphabet size by \\(|\\mathbf{\\Sigma}|\\).\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 2 Let \\(P\\) be a string of size \\(m\\).\n\nA substring \\(P[i\\dots j]\\) of \\(P\\) is the subsequence of \\(P\\) consisting of the characters with indices between \\(i\\) and \\(j\\).\nExample: “tire” is a substring of “retrieval” (with indices between \\(2\\) and \\(5\\)).\n\n\n\n\n\n\n\n\n\n\n\nPattern Matching Problem\n\n\n\nPattern Matching Problem: Given strings \\(\\mathbf{T}\\) (text) and \\(\\mathbf{P}\\) (query), the pattern matching problem consists of finding a substring of \\(\\mathbf{T}\\) equal to \\(\\mathbf{P}\\).\n\nApplications:\n\nText editors\nSearch engines\nBioinformatics\n\n\n\n\n\nPattern Matching: Brute-Force Method\n\nThe Brute-Force pattern matching algorithm compares the key \\(\\mathbf{P}\\) with the text \\(\\mathbf{T}\\) for each possible shift of \\(\\mathbf{P}\\) relative to \\(\\mathbf{T}\\) until either\n\na match is found, or\nall placements of the pattern have been tried.\n\n\n\n/**\n * This method finds the first occurrence of the query in the text.\n * @param text the text to search\n * @param query the query to search for\n * @return the index of the first occurrence of the query in the text, or -1 if the query is not found\n */\npublic static int findBrute(char[] text, char[] query) {\n    int n = text.length;\n    int m = query.length;\n    for (int i = 0; i &lt;= n - m; i++) { // test shift i of the pattern\n        int k = 0;\n        while ( k &lt; m && text[i + k] == query[k] )\n            k++;\n        if (k == m) return i; // match at i\n    }\n    return -1; // no match found\n}\n\nThe time complexity of the Brute-Force pattern matching algorithm is \\(\\mathcal{O}(nm)\\).\n\nIn real world, \\(n\\) is usually very large, so this algorithm is not efficient.\n\n\n\n\nTrie Data Structure\n\nThe standard trie for a set of strings \\(S\\) is an ordered tree such that:\n\nEach node but the root is labeled with a character\nThe children of a node are alphabetically ordered\nThe paths from the nodes (those with index numbers) to the root yield the strings in text.\n\n\n\n\n\n\n\n\nFigure 1: Trie Example\n\n\n\n\n\nImprovement on Trie: Compressed Trie\n\n\n\n\n\n\n\nDefinition 3 Let \\(P\\) be a string of size \\(m\\).\n\nA substring \\(P[i\\dots j]\\) of \\(P\\) is the subsequence of \\(P\\) consisting of the characters with indices between \\(i\\) and \\(j\\).\n\nExample: “tire” is a substring of “retrieval” (with indices between \\(2\\) and \\(5\\)).\n\nA prefix of \\(P\\) is a substring of the type \\(P[0\\dots i]\\)\n\nExample: “ret” is a prefix of “retrieval” (with indices between \\(0\\) and \\(2\\)).\n\nA suffix of \\(P\\) is a substring of the type \\(P[i\\dots m-1]\\)\n\n Example: “eval” is a suffix of “retrieval” (with indices between \\(5\\) and \\(8\\)).\n\n\n\n\n\n\n\nCompressed Tries\n\nProblem: the space complexity of a trie is \\(\\mathcal{O}(n|\\mathbf\\Sigma|)\\), where \\(n\\) is the number of strings in the trie. This is not efficient when \\(n\\) is large.\nWe can compress the trie by Compressing each chain of single-child nodes into a node.\n\nIn this case, each internal node has at least two children.\n\nClaim: The space complexity of a compressed trie is \\(\\mathcal{O}(s|\\mathbf{\\Sigma}|)\\), where \\(s\\) is the number of strings.\n\nProof.\n\nThe number of leaves is equal to the number of strings \\(s\\). Moreover, the number of internal nodes is no more than the number of leaves \\(s\\) because each internal node has multiple children. Therefore, the number of node is no more than \\(2s\\). Since each node has \\(\\mathcal{O}(|\\mathbf{\\Sigma}|)\\) space, the total space complexity should be \\(\\mathcal{O}(2s|\\mathbf{\\Sigma}|)\\sim\\mathcal{O}(s\\cdot|\\mathbf{\\Sigma}|).\\qquad\\blacksquare\\)\n\n\n\n\n\nSearch for Substring\n\nThe trie we built until now can only allow us to match the whole word or match the prefix.\n\n\n\n\n\n\n\n\nSuppose we want to search if a given key is a substring of the string “minimize.”\n\nThe Brute-Force algorithm will have \\(\\mathcal{O}(mn)\\) time complexity.\nTo speed up, we can enumerate all the suffixes of “minimize”: “e”, “ze”, “ize”, “mize”, “imize”, “nimize”, “inimize”, “minimize”.\nThen, we can organize them into a trie, and enjoy \\(\\mathcal{O}(m)\\) time complexity to search for the query.\nIf we can find the query to be a prefix of any suffix, then the query is a substring of the string.\n\n\n\n\n\n\nThough the time complexity is \\(\\mathcal{O}(m)\\), the space complexity is \\(\\mathcal{O}(m^2)\\), which is not efficient.\nSuffix trie: compact representation. \n\nThis way we enjoy linear space complexity as well.\n\n\n\n\nApplication of Tries: Data Compression by Huffman Coding\n\nCompression reduces the size of a file:\n\nTo save space when storing it\nTo save time when transmitting it\nMost files have lost of redundancy\n\nWho needs compression?\n\nMoore’s Law: number transistors on a chip doubles every 18 months\nParkinson’s Law: data expands to fill the space available for storage\nText, images, sound, video, etc.\n\nApplications:\n\nGeneric file compression:\n\nFiles: GZIP,BZIP,7z.\nArchivers: PKZIP.\nFile systems: NTFS, HFS+, ZFS.\n\nMultimedia.\n\nImages: GIF,JPEG.\nSound: MP3.\nVideo: MPEG, DivXTM, HDTV.\n\nCommunication.\n\nITU-T T4 Group 3 Fax.\nV.42bis modem.\nSkype.\n\nDatabases. Google, Facebook, ….\n\nString data with space efficiency:\n\nAll of the types of data we process with modern computer systems have something in common: They are ultimately represented in binary\nIf we can represent the data in fewer bits, we can save space.\nHowever, if we simply use, say, A:0, B:1, R:00, C:01, D:10, I:11, we will have ambiguity.\n\nThis is because some of the codes are prefixes of others.\nFor example, the code for “A” is a prefix of the code for “R”.\n\nWe need a code that is prefix-free.\n\nThis means that no code is a prefix of any other code.\nThis is also called a prefix code.\n\n\nPrefix-free codes: compression and expansion\n\nA binary trie representation\n\nOrdered children: 0 leads to left child, 1 leads to right child.\nEach leaf holds a character \n\n\nHuffman Enconding Trie Overview\n\nHow to obtain the best prefix-free code?\n\nFrequently-used characters with shorter code\nSo, they are closer to the root\nWe will use a bottom-up constructing algorithm to build a trie from least frequent to most frequent characters.\n\nStep 1: Get all the characters’ frequencies for string\n\nWe build \\(|\\mathbf{\\Sigma}|\\) singleton tries, namely trie with only one node.\n\nStep 2: Bottom-up construction from least frequent nodes\n\nIn each iteration, we pick up two lowest frequency tries and merge them into a single trie whose frequency is the sum of these two tries.\nWe iterate until all merged into a single trie.\n\n\n\n\n\n\n\n\n\n\n\n\nProposition 1 (Proposition) Huffman algorithm produces an optimal (no prefix-free code uses fewer bits) prefix-free code for a given set of character frequencies.\n\n\n\n\n\nTime complexity of Huffman algorithm:\n\n\\(\\mathcal{O}(|\\mathbf{\\Sigma}|\\cdot\\log|\\mathbf{\\Sigma}|)\\), where \\(|\\mathbf{\\Sigma}|\\) is the alphabet size (R in the code implementation).\n\nUsing Huffman encoding for data compression:\n\nDynamic model: Use a custom prefix-free code for each message.\nCompressing:\n\nRead message\nBuilt prefix-free code for message\nCompress message using prefix-free code\n\nUncompressing:\n\nRead compressed message and expand it using prefix-free code\n\n\nApplications of Huffman encoding:\n\nJPEG, MP3, MPEG, ZIP, etc.\nGoogle, Facebook, etc.\nCommunication systems: Skype, etc.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/12 Tries.html#introduction",
    "href": "notes/cs253/12 Tries.html#introduction",
    "title": "Tries",
    "section": "",
    "text": "!!! note Definition - A String is a sequence of characters. - Examples: - Python program - HTML document - DNA sequence - Digitized image - An alphabet \\(\\mathbf{\\Sigma}\\) is the set of possible characters for a family of strings: - Examples: - a, b, c, …, x, y, z - ASCII characters - Unicode - {0, 1} - {A, T, C, G} - We denote the alphabet size by \\(|\\mathbf{\\Sigma}|\\).\n!!! note Definition Let \\(P\\) be a string of size \\(m\\). - A substring \\(P[i\\dots j]\\) of \\(P\\) is the subsequence of \\(P\\) consisting of the characters with indices between \\(i\\) and \\(j\\). - Example: “tire” is a substring of “retrieval” (with indices between \\(2\\) and \\(5\\)).\n!!! question Problem Pattern Matching Problem: Given strings \\(\\mathbf{T}\\) (text) and \\(\\mathbf{P}\\) (query), the pattern matching problem consists of finding a substring of \\(\\mathbf{T}\\) equal to \\(\\mathbf{P}\\). - Applications: - Text editors - Search engines - Bioinformatics\n\nPattern Matching: Brute-Force Method\n\nThe Brute-Force pattern matching algorithm compares the key \\(\\mathbf{P}\\) with the text \\(\\mathbf{T}\\) for each possible shift of \\(\\mathbf{P}\\) relative to \\(\\mathbf{T}\\) until either\n\na match is found, or\nall placements of the pattern have been tried.\n\n\n\n/**\n * This method finds the first occurrence of the query in the text.\n * @param text the text to search\n * @param query the query to search for\n * @return the index of the first occurrence of the query in the text, or -1 if the query is not found\n */\npublic static int findBrute(char[] text, char[] query) {\n    int n = text.length;\n    int m = query.length;\n    for (int i = 0; i &lt;= n - m; i++) { // test shift i of the pattern\n        int k = 0;\n        while ( k &lt; m && text[i + k] == query[k] )\n            k++;\n        if (k == m) return i; // match at i\n    }\n    return -1; // no match found\n}\n\nThe time complexity of the Brute-Force pattern matching algorithm is \\(\\mathcal{O}(nm)\\).\n\nIn real world, \\(n\\) is usually very large, so this algorithm is not efficient."
  },
  {
    "objectID": "notes/cs253/12 Tries.html#trie-data-structure",
    "href": "notes/cs253/12 Tries.html#trie-data-structure",
    "title": "12 Tries",
    "section": "",
    "text": "The standard trie for a set of strings \\(S\\) is an ordered tree such that:\n\nEach node but the root is labeled with a character\nThe children of a node are alphabetically ordered\nThe paths from the nodes (those with index numbers) to the root yield the strings in text.\n\n\n\n\n\n\n\n\nFigure 1: Trie Example"
  },
  {
    "objectID": "notes/cs253/12 Tries.html#improvement-on-trie-compressed-trie",
    "href": "notes/cs253/12 Tries.html#improvement-on-trie-compressed-trie",
    "title": "12 Tries",
    "section": "Improvement on Trie: Compressed Trie",
    "text": "Improvement on Trie: Compressed Trie\n\n\n\n\n\n\n\nDefinition 3 Let \\(P\\) be a string of size \\(m\\).\n\nA substring \\(P[i\\dots j]\\) of \\(P\\) is the subsequence of \\(P\\) consisting of the characters with indices between \\(i\\) and \\(j\\).\n\nExample: “tire” is a substring of “retrieval” (with indices between \\(2\\) and \\(5\\)).\n\nA prefix of \\(P\\) is a substring of the type \\(P[0\\dots i]\\)\n\nExample: “ret” is a prefix of “retrieval” (with indices between \\(0\\) and \\(2\\)).\n\nA suffix of \\(P\\) is a substring of the type \\(P[i\\dots m-1]\\)\n\n Example: “eval” is a suffix of “retrieval” (with indices between \\(5\\) and \\(8\\)).\n\n\n\n\n\n\n\nCompressed Tries\n\nProblem: the space complexity of a trie is \\(\\mathcal{O}(n|\\mathbf\\Sigma|)\\), where \\(n\\) is the number of strings in the trie. This is not efficient when \\(n\\) is large.\nWe can compress the trie by Compressing each chain of single-child nodes into a node.\n\nIn this case, each internal node has at least two children.\n\nClaim: The space complexity of a compressed trie is \\(\\mathcal{O}(s|\\mathbf{\\Sigma}|)\\), where \\(s\\) is the number of strings.\n\nProof.\n\nThe number of leaves is equal to the number of strings \\(s\\). Moreover, the number of internal nodes is no more than the number of leaves \\(s\\) because each internal node has multiple children. Therefore, the number of node is no more than \\(2s\\). Since each node has \\(\\mathcal{O}(|\\mathbf{\\Sigma}|)\\) space, the total space complexity should be \\(\\mathcal{O}(2s|\\mathbf{\\Sigma}|)\\sim\\mathcal{O}(s\\cdot|\\mathbf{\\Sigma}|).\\qquad\\blacksquare\\)"
  },
  {
    "objectID": "notes/cs253/12 Tries.html#search-for-substring",
    "href": "notes/cs253/12 Tries.html#search-for-substring",
    "title": "12 Tries",
    "section": "",
    "text": "The trie we built until now can only allow us to match the whole word or match the prefix.\n\n\n\n\n\n\n\n\nSuppose we want to search if a given key is a substring of the string “minimize.” - The Brute-Force algorithm will have \\(\\mathcal{O}(mn)\\) time complexity. - To speed up, we can enumerate all the suffixes of “minimize”: “e”, “ze”, “ize”, “mize”, “imize”, “nimize”, “inimize”, “minimize”. - Then, we can organize them into a trie, and enjoy \\(\\mathcal{O}(m)\\) time complexity to search for the query. - If we can find the query to be a prefix of any suffix, then the query is a substring of the string.\n\n\n\n\n\nThough the time complexity is \\(\\mathcal{O}(m)\\), the space complexity is \\(\\mathcal{O}(m^2)\\), which is not efficient.\nSuffix trie: compact representation. \n\nThis way we enjoy linear space complexity as well."
  },
  {
    "objectID": "notes/cs253/12 Tries.html#application-of-tries-data-compression-by-huffman-coding",
    "href": "notes/cs253/12 Tries.html#application-of-tries-data-compression-by-huffman-coding",
    "title": "12 Tries",
    "section": "",
    "text": "Compression reduces the size of a file:\n\nTo save space when storing it\nTo save time when transmitting it\nMost files have lost of redundancy\n\nWho needs compression?\n\nMoore’s Law: number transistors on a chip doubles every 18 months\nParkinson’s Law: data expands to fill the space available for storage\nText, images, sound, video, etc.\n\nApplications:\n\nGeneric file compression:\n\nFiles: GZIP,BZIP,7z.\nArchivers: PKZIP.\nFile systems: NTFS, HFS+, ZFS.\n\nMultimedia.\n\nImages: GIF,JPEG.\nSound: MP3.\nVideo: MPEG, DivXTM, HDTV.\n\nCommunication.\n\nITU-T T4 Group 3 Fax.\nV.42bis modem.\nSkype.\n\nDatabases. Google, Facebook, ….\n\nString data with space efficiency:\n\nAll of the types of data we process with modern computer systems have something in common: They are ultimately represented in binary\nIf we can represent the data in fewer bits, we can save space.\nHowever, if we simply use, say, A:0, B:1, R:00, C:01, D:10, I:11, we will have ambiguity.\n\nThis is because some of the codes are prefixes of others.\nFor example, the code for “A” is a prefix of the code for “R”.\n\nWe need a code that is prefix-free.\n\nThis means that no code is a prefix of any other code.\nThis is also called a prefix code.\n\n\nPrefix-free codes: compression and expansion\n\nA binary trie representation\n\nOrdered children: 0 leads to left child, 1 leads to right child.\nEach leaf holds a character \n\n\nHuffman Enconding Trie Overview\n\nHow to obtain the best prefix-free code?\n\nFrequently-used characters with shorter code\nSo, they are closer to the root\nWe will use a bottom-up constructing algorithm to build a trie from least frequent to most frequent characters.\n\nStep 1: Get all the characters’ frequencies for string\n\nWe build \\(|\\mathbf{\\Sigma}|\\) singleton tries, namely trie with only one node.\n\nStep 2: Bottom-up construction from least frequent nodes\n\nIn each iteration, we pick up two lowest frequency tries and merge them into a single trie whose frequency is the sum of these two tries.\nWe iterate until all merged into a single trie.\n\n\n\n\n\n!!! done Proposition Huffman algorithm produces an optimal (no prefix-free code uses fewer bits) prefix-free code for a given set of character frequencies.\n\nTime complexity of Huffman algorithm:\n\n\\(\\mathcal{O}(|\\mathbf{\\Sigma}|\\cdot\\log|\\mathbf{\\Sigma}|)\\), where \\(|\\mathbf{\\Sigma}|\\) is the alphabet size (R in the code implementation).\n\nUsing Huffman encoding for data compression:\n\nDynamic model: Use a custom prefix-free code for each message.\nCompressing:\n\nRead message\nBuilt prefix-free code for message\nCompress message using prefix-free code\n\nUncompressing:\n\nRead compressed message and expand it using prefix-free code\n\n\nApplications of Huffman encoding:\n\nJPEG, MP3, MPEG, ZIP, etc.\nGoogle, Facebook, etc.\nCommunication systems: Skype, etc."
  },
  {
    "objectID": "notes/cs253/1 Array List.html",
    "href": "notes/cs253/1 Array List.html",
    "title": "1 Array List",
    "section": "",
    "text": "Array: sequenced collection of variables all of the same type.\nElement: each value stored in an array.\nArray length: maximum number of elements that can be stored in the array.\nIndex: uniquely refers to each element. Range: 0, 1, 2, …, length-1.\n\n\n\n\n\nArray declaration\n\nint[] myArray = {1, 3, 5, 6, 8, 9};\nint[] myArray new int[10];\nCar[] myArray new Car[6];\n// Illegal: \n// int[] myArray = new int[];\n\nArray must be initialized with a fixed length.\nArrayList declaration\n\nArrayList&lt;Integer&gt; myList = new ArrayList&lt;&gt;();\nArrayList&lt;Car&gt; myList = new ArrayList&lt;Car&gt;();\nArrayList&lt;Car&gt; myList = new ArrayList&lt;Car&gt;(6);\n\nSet an item to a value: time complexity = \\(\\mathcal{O}(1)\\).\n\n// Array:\nmyArray[4] = 30; // set item at index 4 to 30.\n// ArrayList:\nmyList.set(4, 30);\n\nGet the value of an item: time complexity = \\(\\mathcal{O}(1)\\).\n\nx = myArray[4]; // get item value at index 4.\nmyList.get(4);\n\n\n\n\nTime complexity analysis:\n\nAdd a new element at an index in ArrayList = \\(\\mathcal{O}(n)\\)\nRemove an element at an index in ArrayList = \\(\\mathcal{O}(n)\\)\nPush an element to the end of ArrayList = \\(\\mathcal{O}(1)\\). (No matter in the dynamic sized case or fixed sized case.)\n\n\n\n\n\n\n\n\nFigure 1: ArrayList"
  },
  {
    "objectID": "notes/cs253/1 Array List.html#definitions",
    "href": "notes/cs253/1 Array List.html#definitions",
    "title": "1 Array List",
    "section": "",
    "text": "Array: sequenced collection of variables all of the same type.\nElement: each value stored in an array.\nArray length: maximum number of elements that can be stored in the array.\nIndex: uniquely refers to each element. Range: 0, 1, 2, …, length-1."
  },
  {
    "objectID": "notes/cs253/1 Array List.html#array-vs.-arraylist-in-java",
    "href": "notes/cs253/1 Array List.html#array-vs.-arraylist-in-java",
    "title": "1 Array List",
    "section": "",
    "text": "Array declaration\n\nint[] myArray = {1, 3, 5, 6, 8, 9};\nint[] myArray new int[10];\nCar[] myArray new Car[6];\n// Illegal: \n// int[] myArray = new int[];\n\nArray must be initialized with a fixed length.\nArrayList declaration\n\nArrayList&lt;Integer&gt; myList = new ArrayList&lt;&gt;();\nArrayList&lt;Car&gt; myList = new ArrayList&lt;Car&gt;();\nArrayList&lt;Car&gt; myList = new ArrayList&lt;Car&gt;(6);\n\nSet an item to a value: time complexity = \\(\\mathcal{O}(1)\\).\n\n// Array:\nmyArray[4] = 30; // set item at index 4 to 30.\n// ArrayList:\nmyList.set(4, 30);\n\nGet the value of an item: time complexity = \\(\\mathcal{O}(1)\\).\n\nx = myArray[4]; // get item value at index 4.\nmyList.get(4);"
  },
  {
    "objectID": "notes/cs253/1 Array List.html#implementing-arraylist",
    "href": "notes/cs253/1 Array List.html#implementing-arraylist",
    "title": "1 Array List",
    "section": "",
    "text": "Time complexity analysis:\n\nAdd a new element at an index in ArrayList = \\(\\mathcal{O}(n)\\)\nRemove an element at an index in ArrayList = \\(\\mathcal{O}(n)\\)\nPush an element to the end of ArrayList = \\(\\mathcal{O}(1)\\). (No matter in the dynamic sized case or fixed sized case.)\n\n\n\n\n\n\n\n\nFigure 1: ArrayList"
  },
  {
    "objectID": "notes/cs253/7 Directed Acyclic Graph (DAG).html",
    "href": "notes/cs253/7 Directed Acyclic Graph (DAG).html",
    "title": "7 Directed Acyclic DAG (DAG)",
    "section": "",
    "text": "DAG and DFS recap\n\n\n\n\n\n\nFigure 1: DFS\n\n\n\n\n\nCycle Detection\nAlgorithm cycleDetection(u, ancestors):\n    for each of u's outgoing edges, e=(u,v), do {\n        if v is among ancestors, return true\n        if vertex v has not been visited, then {\n            record vertex v and its discovery edge e\n            add v to ancestors\n            if cycleDetection(v, ancestors) return true\n            remove v from ancestors\n        }\n    }\n\n\n\nTopological Sort\n\n\n\n\n\n\n\nDefinition 1 A topological ordering of a graph is an ordering \\(v_1,\\dots,v_n\\) of the vertices of the graph such that for every edge \\((v_i,v_j)\\) in the graph, it must be that \\(i&lt;j\\). - That is, any edge is always from a higher-ranked vertex to a lower-ranked one.\n\n\n\n\n\nClaim: A DAG always has topological ordering.\n\nA DAG always has at least one “source” vertex (that is, a vertex with no incoming edges).\nHence, we can give highest rank to this source vertex.\nSince the remaining subgraph is still a DAG, we still have a source vertex in it for which we can give the next highest rank, and so on.\nRepeat this process until all vertices are ranked. This gives a topological ordering.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/7 Directed Acyclic Graph (DAG).html#cycle-detection",
    "href": "notes/cs253/7 Directed Acyclic Graph (DAG).html#cycle-detection",
    "title": "Directed Acyclic DAG (DAG)",
    "section": "",
    "text": "Algorithm cycleDetection(u, ancestors):\n    for each of u's outgoing edges, e=(u,v), do {\n        if v is among ancestors, return true\n        if vertex v has not been visited, then {\n            record vertex v and its discovery edge e\n            add v to ancestors\n            if cycleDetection(v, ancestors) return true\n            remove v from ancestors\n        }\n    }"
  },
  {
    "objectID": "notes/cs253/7 Directed Acyclic Graph (DAG).html#topological-sort",
    "href": "notes/cs253/7 Directed Acyclic Graph (DAG).html#topological-sort",
    "title": "Directed Acyclic DAG (DAG)",
    "section": "",
    "text": "!!! note Definition A topological ordering of a graph is an ordering \\(v_1,\\dots,v_n\\) of the vertices of the graph such that for every edge \\((v_i,v_j)\\) in the graph, it must be that \\(i&lt;j\\). - That is, any edge is always from a higher-ranked vertex to a lower-ranked one.\n\nClaim: A DAG always has topological ordering.\n\nA DAG always has at least one “source” vertex (that is, a vertex with no incoming edges).\nHence, we can give highest rank to this source vertex.\nSince the remaining subgraph is still a DAG, we still have a source vertex in it for which we can give the next highest rank, and so on.\nRepeat this process until all vertices are ranked. This gives a topological ordering."
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html",
    "href": "notes/cs253/3 Priority Queues.html",
    "title": "3 Priority Queues and Heaps",
    "section": "",
    "text": "Definition 1 Priority Queue allows the removal of the elements that has first priority.\n\n\n\n\n\nIn priority queue, we have a key of an entry that indicates the priority (the smaller the key, the higher priority).\nWe also have a value of an entry that holds the element values.\n\npublic static class Entry&lt;K,V&gt; {\n    private K k;\n    private V v;\n    public Entry(K key, V, value) {\n        k = key;\n        v = value;\n    }\n}\n\nThe Priority Queue Abstract Data Type (ADT) is defined by the following interface:\n\npublic interface PriorityQueue&lt;K,V&gt; {\n    int size();\n    boolean isEmpty();\n\n    // Insert the entry into current priority queue.\n    Entry&lt;K,V&gt; insert(K key, V value);\n\n    // Return the entry with the smallest key\n    Entry&lt;K,V&gt; min();\n\n    // Pop out the entry with the smallest key\n    Entry&lt;K,V&gt; removeMin();\n}\n\nHow to tell “Priority”: the java’s java.util.Comparator interface\n\n&lt;0 designates that e1&lt;e2\n=0 designates that e1=e2\n&gt;0 designates that e1&gt;e2 ```java import java.util.*;\n\n\npublic class DefaultComparator implements Comparator { @Override public int compare(E e1, E e2) { return ((Comparable)e1).compareTo(e2); } }\n\n# Implementing Priority Queues using Linked Lists\n- Using Unsorted List\n```java\nimport java.until.*;\npublic class UnsortedPriorityQueue&lt;K,V&gt; {\n    protected static class Entry&lt;K,V&gt; {\n        public K k;\n        public V v;\n        public Entry(K key, V value) {\n            k = key;\n            v = value;\n        }\n    }\n\n    private int size = 0;\n    private Comparator&lt;K&gt; comp;\n    public UnsortedPriorityQueue(Comparator&lt;K&gt; c) {\n        comp = c;\n    }\n    public UnsortedPriorityQueue() {\n        this(new DefaultComparator&lt;K&gt;());\n    }\n\n    private DoublyLinkedList&lt;Entry&lt;K,V&gt;&gt; list = new DoublyLinkedList&lt;&gt;();\n\n    public DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; findMin(){...}\n    public Entry&lt;K,V&gt; insert(K key, V value) {...}\n    public Entry&lt;K,V&gt; min() {...}\n    public Entry&lt;K,V&gt; removeMin() {...}\n}\n\nIn this implementation of Priority Queue (PQ), we use a doubly linked list to store the entries.\n\nIf we use an array, we have \\(\\mathcal{O}(n)\\) time complexity when removing.\nIf we use a singly linked list, we have \\(\\mathcal{O}\n(n)\\) when deleting the minimum element.\n\nImplementation of findMin()\n\npublic DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; findMin() { // Time complexity = O(n)\n    DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; min = list.head.next;\n    DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; walk = list.head.next;\n\n    while (walk.next != null) {\n        if (comp.compare(walk.element.k, min.element.k) &lt; 0) {\n            min = walk;\n        }\n        walk = walk.next;\n    }\n    return min;\n}\n\nImplementation of insert(), min(), removeMin()\n\npublic Entry&lt;K,V&gt; min() { // Time complexity = O(n)\n    if (list.isEmpty()) \n        return null;\n    return findMin().element;\n\n}\n\npublic Entry&lt;K,V&gt; removeMin() { // Time complexity = O(n)\n    if (list.isEmpty())\n        return null;\n    return list.delete(findMin());;\n}\n\npublic Entry&lt;K,V&gt; insert(K key, V value) { // Time complexity = O(1)\n    Entry&lt;K,V&gt; newest = new Entry&lt;&gt;(key, value);\n    list.insert(newest, list.tail.previous, list.tail);\n    return newest;\n}\n\nUsing Sorted List\n\nimport java.util.*;\n\npublic class SortedPriorityQueue&lt;K,V&gt; {\n    protected static class Entry&lt;K,V&gt; {\n        public K k;\n        public V v;\n        public Entry(K key, V value) {\n            k = key;\n            v = value;\n        }\n    }\n\n    private int size = 0;\n    private Comparator&lt;K&gt; comp;\n    public SortedPriorityQueue(Comparator&lt;K&gt; c) {\n        comp = c;\n    }\n    public SortedPriorityQueue() {\n        this(new DefaultComparator&lt;K&gt;());\n    }\n    public boolean isEmpty() {\n        return size == 0;\n    }\n\n    private DoublyLinkedList&lt;Entry&lt;K,V&gt;&gt; list = new DoublyLinkedList&lt;&gt;();\n    public Entry&lt;K,V&gt; insert(K key, V value) {...}\n    public Entry&lt;K,V&gt; min() {...}\n    public Entry&lt;K,V&gt; removeMin() {...}\n}\n\nIn this implementation of PQ, we also used a doubly linked list.\n\nIf we use array, we will have \\(\\mathcal{O}(n)\\) time complexity when inserting because we need to shift the elements to maintain the sorting.\nIf we use singly linked list, we will only need one pointer, and hence we need less space than doubly linked list. However, we will have \\(\\mathcal{O}(n)\\) time complexity when inserting because we need to find the position to insert.\n\nImplementation of min() and removeMin()\n\npublic Entry&lt;K,V&gt; min() { // Time complexity = O(1)\n    if (list.isEmpty())\n        return null;\n    return list.head.next.element;\n}\n\npublic Entry&lt;K,V&gt; removeMin() { // Time complexity = O(1)\n    if (list.isEmpty())\n        return null;\n    return list.delete(list.head.next);\n}\n\nImplementation of insert()\n\npublic Entry&lt;K,V&gt; insert(K key, V value) {\n    Entry&lt;K,V&gt; newest = new Entry&lt;&gt;(key, value);\n    DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; walk = list.tail.previous;\n\n    while (walk.previous != null && comp.compare(newest.k, walk.element.k) &lt; 0) {\n        walk = walk.previous;\n    }\n    list.insert(newest, walk, walk.next);\n    return newest;\n}"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#introduction",
    "href": "notes/cs253/3 Priority Queues.html#introduction",
    "title": "Priority Queues",
    "section": "",
    "text": "!!! note Definition Priority Queue allows the removal of the elements that has first priority. - In priority queue, we have a key of an entry that indicates the priority (the smaller the key, the higher priority). - We also have a value of an entry that holds the element values.\npublic static class Entry&lt;K,V&gt; {\n    private K k;\n    private V v;\n    public Entry(K key, V, value) {\n        k = key;\n        v = value;\n    }\n}\n\nThe Priority Queue Abstract Data Type (ADT) is defined by the following interface:\n\npublic interface PriorityQueue&lt;K,V&gt; {\n    int size();\n    boolean isEmpty();\n\n    // Insert the entry into current priority queue.\n    Entry&lt;K,V&gt; insert(K key, V value);\n\n    // Return the entry with the smallest key\n    Entry&lt;K,V&gt; min();\n\n    // Pop out the entry with the smallest key\n    Entry&lt;K,V&gt; removeMin();\n}\n\nHow to tell “Priority”: the java’s java.util.Comparator interface\n\n&lt;0 designates that e1&lt;e2\n=0 designates that e1=e2\n&gt;0 designates that e1&gt;e2 ```java import java.util.*;\n\n\npublic class DefaultComparator implements Comparator { @Override public int compare(E e1, E e2) { return ((Comparable)e1).compareTo(e2); } }\n\n\n## Implementing Priority Queues using Linked Lists\n- Using Unsorted List\n```java\nimport java.until.*;\npublic class UnsortedPriorityQueue&lt;K,V&gt; {\n    protected static class Entry&lt;K,V&gt; {\n        public K k;\n        public V v;\n        public Entry(K key, V value) {\n            k = key;\n            v = value;\n        }\n    }\n\n    private int size = 0;\n    private Comparator&lt;K&gt; comp;\n    public UnsortedPriorityQueue(Comparator&lt;K&gt; c) {\n        comp = c;\n    }\n    public UnsortedPriorityQueue() {\n        this(new DefaultComparator&lt;K&gt;());\n    }\n\n    private DoublyLinkedList&lt;Entry&lt;K,V&gt;&gt; list = new DoublyLinkedList&lt;&gt;();\n\n    public DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; findMin(){...}\n    public Entry&lt;K,V&gt; insert(K key, V value) {...}\n    public Entry&lt;K,V&gt; min() {...}\n    public Entry&lt;K,V&gt; removeMin() {...}\n}\n\nIn this implementation of Priority Queue (PQ), we use a doubly linked list to store the entries.\n\nIf we use an array, we have \\(\\mathcal{O}(n)\\) time complexity when removing.\nIf we use a singly linked list, we have \\(\\mathcal{O}\n(n)\\) when deleting the minimum element.\n\nImplementation of findMin()\n\npublic DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; findMin() { // Time complexity = O(n)\n    DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; min = list.head.next;\n    DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; walk = list.head.next;\n\n    while (walk.next != null) {\n        if (comp.compare(walk.element.k, min.element.k) &lt; 0) {\n            min = walk;\n        }\n        walk = walk.next;\n    }\n    return min;\n}\n\nImplementation of insert(), min(), removeMin()\n\npublic Entry&lt;K,V&gt; min() { // Time complexity = O(n)\n    if (list.isEmpty()) \n        return null;\n    return findMin().element;\n\n}\n\npublic Entry&lt;K,V&gt; removeMin() { // Time complexity = O(n)\n    if (list.isEmpty())\n        return null;\n    return list.delete(findMin());;\n}\n\npublic Entry&lt;K,V&gt; insert(K key, V value) { // Time complexity = O(1)\n    Entry&lt;K,V&gt; newest = new Entry&lt;&gt;(key, value);\n    list.insert(newest, list.tail.previous, list.tail);\n    return newest;\n}\n\nUsing Sorted List\n\nimport java.util.*;\n\npublic class SortedPriorityQueue&lt;K,V&gt; {\n    protected static class Entry&lt;K,V&gt; {\n        public K k;\n        public V v;\n        public Entry(K key, V value) {\n            k = key;\n            v = value;\n        }\n    }\n\n    private int size = 0;\n    private Comparator&lt;K&gt; comp;\n    public SortedPriorityQueue(Comparator&lt;K&gt; c) {\n        comp = c;\n    }\n    public SortedPriorityQueue() {\n        this(new DefaultComparator&lt;K&gt;());\n    }\n    public boolean isEmpty() {\n        return size == 0;\n    }\n\n    private DoublyLinkedList&lt;Entry&lt;K,V&gt;&gt; list = new DoublyLinkedList&lt;&gt;();\n    public Entry&lt;K,V&gt; insert(K key, V value) {...}\n    public Entry&lt;K,V&gt; min() {...}\n    public Entry&lt;K,V&gt; removeMin() {...}\n}\n\nIn this implementation of PQ, we also used a doubly linked list.\n\nIf we use array, we will have \\(\\mathcal{O}(n)\\) time complexity when inserting because we need to shift the elements to maintain the sorting.\nIf we use singly linked list, we will only need one pointer, and hence we need less space than doubly linked list. However, we will have \\(\\mathcal{O}(n)\\) time complexity when inserting because we need to find the position to insert.\n\nImplementation of min() and removeMin()\n\npublic Entry&lt;K,V&gt; min() { // Time complexity = O(1)\n    if (list.isEmpty())\n        return null;\n    return list.head.next.element;\n}\n\npublic Entry&lt;K,V&gt; removeMin() { // Time complexity = O(1)\n    if (list.isEmpty())\n        return null;\n    return list.delete(list.head.next);\n}\n\nImplementation of insert()\n\npublic Entry&lt;K,V&gt; insert(K key, V value) {\n    Entry&lt;K,V&gt; newest = new Entry&lt;&gt;(key, value);\n    DoublyLinkedList.Node&lt;Entry&lt;K,V&gt;&gt; walk = list.tail.previous;\n\n    while (walk.previous != null && comp.compare(newest.k, walk.element.k) &lt; 0) {\n        walk = walk.previous;\n    }\n    list.insert(newest, walk, walk.next);\n    return newest;\n}"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#heaps",
    "href": "notes/cs253/3 Priority Queues.html#heaps",
    "title": "Priority Queues",
    "section": "",
    "text": "!!! defnition Tree - Root: the node without a parent. (e.g., A) - Internal node: a node with at least one child. (e.g., A, B, C, F) - External node: a node without any children. (e.g, D, E, I, J, K, G, H) - Ancestor of a node: parent, grandparent, grand- grandparent, etc. - Descendant of a node: child, grandchild, grand- grandchild, etc. - Depth of a node: the number of ancestors. - Height of a tree: the maximum depth of any node in the tree. (e.g, 3)\n\n\n\nTree Introduction\n\n\n!!! note Definition Binary Trees: Each internal node has at most two children. - We call the children of a node the left child and right child. - Different types of Binary Trees: - Perfect Binary Tree - All internal nodes have two children. - All external nodes have the same depth. - Number of nodes: \\(n=2^0+2^1+^2+\\cdots+2^h=2^{h+1}-1\\), where \\(h\\) is the height of the tree. - Complete Binary Tree - All levels except the last are completely filled - All nodes in the last level are as far left as possible - Number of nodes: \\[\n2^0+2^1+\\cdots+2^{h-1}\\leq n\\leq2^0+2^1+\\cdots+2^h \\\\\n\\implies 2^h-1\\leq n\\leq 2^{h+1}-1 \\\\\n\\implies \\log(n+1)-2\\leq h\\leq\\log(n+1).\n\\]\n\n\n\nDifferent Binary Trees\n\n\n\n\n\n!!! note Definition Heap: A heap is a binary tree storing keys at its nodes and satisfying the following properties: - Heap-Order: for every node (except root), its key is larger than or equal to its parent’s key. - Must be a complete binary tree.\n\nHeaps and Priority Queues\n\nWe can use a heap to implement a priority queue.\nWe store a (key, value) item at each node.\nWe can get the entry will minimal key in \\(\\mathcal{O}(1)\\).\nWe hope removeMin() and insert() can also be fast.\n\nHeap operation: insert()/swim()\n\nPlace the new entry just beyond the rightmost node at the bottom level of the tree. Swim until it becomes a heap.\n\nIf the current layer is full, add a new layer.\nWhen adding a new layer, the new layer must be added from left to right.\nIf the current node is smaller than its parent, swap them.\n\nTime complexity: what is really time-consuming here is the swap() operation. In total, we can at most swap \\(h\\) times (the number of layers), so the time complexity should be \\(\\mathcal{O}(h)=\\mathcal{O}(\\log n)\\).\n\nHeap operation: removeMin()/sink()\n\nCut and paste the heap’s last entry to its root. Sink until it becomes a heap.\n\nPull the last entry up to the root.\nCompare the new root with its children. Swap it with the smaller child if necessary.\nRepeat until we retain the heap-order property.\n\nTime complexity: it is the sawp() operation that is time-consuming. In total, we can at most swap \\(h\\) times (the number of layers), so the time complexity should also be \\(\\mathcal{O}(h)=\\mathcal{O}(\\log n)\\).\n\n\n\n\n\n\n\n\n\n\n\nMethod\nUnosrted List\nSorted List\nHeap\n\n\n\n\nsize()\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nisEmtpy()\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\ninsert()\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(\\log n)\\)\n\n\nmin()\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nremoveMin()\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(\\log n)\\)"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#implementing-priority-queues-using-heaps",
    "href": "notes/cs253/3 Priority Queues.html#implementing-priority-queues-using-heaps",
    "title": "Priority Queues",
    "section": "",
    "text": "Insert via a swim process\n\nWe insert the new entry at the end of the heap.\nWe then swim the new entry up the heap until it is in the correct position.\nThe time complexity is \\(\\mathcal{O}(\\log n)\\).\n\nRemoveMin via a sink process\n\nWe remove the root entry and replace it with the last entry in the heap.\nWe then sink the new root down the heap until it is in the correct position.\nThe time complexity is \\(\\mathcal{O}(\\log n)\\).\n\nInstead of really building a “tree” structure, we use array to implement a heap.\n\nThe root is at index 0.\nThe left child of a node at index \\(i\\) is at index \\(2i+1\\).\nThe right child of a node at index \\(i\\) is at index \\(2i+2\\).\nBased on the above, we can easily find the parent of a node at index \\(i\\) by using the formula \\(\\lfloor(i-1)/2\\rfloor\\). (or in java, simply use (i-1)/2 because it will automatically round down to the nearest integer.)\n\nThe following code builds the HeapPriorityQueue class.\n\nimport java.util.*;\n\npublic class HeapPriorityQueue&lt;K,V&gt; {\n    // Nested Entry class\n    protected static class Entry&lt;K,V&gt; {\n        public K k;\n        public V v;\n        public Entry(K key, V value) {\n            k = key;\n            v = value;\n        }\n    } // End of nested Entry class\n\n    protected ArrayList&lt;Entry&lt;K,V&gt;&gt; heap = new ArrayList&lt;&gt;();\n    private Comparator&lt;K&gt; comp;\n    public HeapPriorityQueue() {\n        this(new DefaultComparator&lt;K&gt;());\n    }\n    public HeapPriorityQueue(Comparator&lt;K&gt; c) {\n        comp = c;\n    }\n\n    protected int leftchild(int j) {\n        return 2 * j + 1;\n    }\n    protected int rightchild(int) {\n        return 2 * j + 2;\n    }\n    protected int parent(int j) {\n        return (j - 1) / 2;\n    }\n\n    protected boolean hasLeft(int j) {\n        return leftchild(j) &lt; heap.size();\n    }\n    protected boolean hasRight(int j) {\n        return rightchild(j) &lt; heap.size();\n    }\n\n    public int size() {\n        return heap.size();\n    }\n    public boolean isEmpty() {\n        return heap.isEmpty();\n    }\n\n    // Swap the entries at indices i and j of the array list\n    protected void swap(int i, int j) {\n        Entry&lt;K,V&gt; temp = heap.get(i);\n        heap.set(i, heap.get(j));\n        heap.set(j, temp);\n    }\n\n    public Entry&lt;K,V&gt; insert(K key, V value) {...}\n    public Entry&lt;K,V&gt; removeMin(){...}\n}\n\nThe following code implements the insert() based on the swim process.\n\npublic Entry&lt;K,V&gt; insert(K key, V value) {\n    Entry&lt;K,V&gt; newEntry = new Entry&lt;K,V&gt;(key, value);\n    // insert newEntry after the last entry in the heap\n    heap.add(newEntry);\n    // swim the new entry up to its proper position\n    swim(heap.size() - 1);\n    return newEntry;\n}\n\nprotected void swim(int j) {\n    // when j is the not the root, we need to compare it with its parent\n    while (j &gt; 0) {\n        // check if the current entry is smaller than its parent\n        if (comp.compare(heap.get(j).k, heap.get(parent(j)).k) &lt; 0) {\n            // swap them\n            swap(j, parent(j));\n            j = parent(j);\n        } else {\n            break;\n        }\n    }\n}\n\nThe following code implements the removeMin() based on the sink process.\n\npublic Entry&lt;K,V&gt; removeMin() {\n    if (size() == 0) return null;\n    // Step 1: move the last entry to the root\n    swap(0, heap.size() - 1);\n    // Step 2: remove the last entry (which is the smallest entry after step 1)\n    Entry&lt;K,V&gt; removed = heap.remove(size() - 1);\n    // Step 3: sink the new root down to its proper position\n    sink(0);\n    return removed;\n}\n\nprotected void sink(int j) {\n    while(hasLeft(j)) {\n        // to find a smaller child\n        int smallerChild = leftchild(j);\n\n        if (hasRight(j)) {\n            if (comp.compare(heap.get(smallerChild).k, heap.get(rightchild(j)).k) &gt; 0) {\n                // update smallerChild to the right child\n                smallerChild = rightchild(j);\n            }\n        }\n\n        // compare the smaller child with the current entry\n        if (comp.compare(heap.get(j).k, heap.get(smallerChild).k) &gt; 0) {\n            // swap them\n            swap(j, smallerChild);\n            j = smallerChild;\n        } else {\n            break;\n        }\n    }\n}"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#comparison-between-heaps-against-unsortedsorted-lists",
    "href": "notes/cs253/3 Priority Queues.html#comparison-between-heaps-against-unsortedsorted-lists",
    "title": "Priority Queues",
    "section": "",
    "text": "Sorting with Priority Queue\n\nInsert all the entries into priority queue\nRemoveMin all the entries from the priority queue\n\nGenerally, the code is as follows:\n\n// Sorts sequence S, using initially empty priority queue P to produce the order\npublic static &lt;E&gt; void pqSort(PositionalList&lt;E&gt; S, PriorityQueue&lt;E,?&gt; P) {\n    int n = S.size();\n\n    // Phase 1: insert\n    for (int j = 0; j &lt; n; j++) {\n        E element = S.remove(S.firt());\n        P.insert(element, null); // element is key, null value\n    }\n\n    // Phase 2: removeMin\n    for (int j = 0; j &lt; n; j++) {\n        E element = P.removeMin().getKey();\n        S.addLast(element); // the smallest key in P is next placed in S\n    }\n}\n\nSorting with priority queue using unsorted list\n\nThe time complexity of whole Phase 1 is \\(\\mathcal{O}(n)\\)\nThe time complexity of whole Phase 2 is \\(\\mathcal{O}(n^2)\\)\nThe total time complexity is \\(\\mathcal{O}(n^2)\\).\n\nSorting with priority queue using sorted list\n\nThe time complexity of whole Phase 1 is \\(\\mathcal{O}(n^2)\\)\nThe time complexity of whole Phase 2 is \\(\\mathcal{O}(n)\\)\nThe total time complexity is \\(\\mathcal{O}(n^2)\\).\n\nSorting with priority queue using heaps\n\nThe time complexity of whole Phase 1 is \\(\\mathcal{O}(n\\log n)\\)\nThe time complexity of whole Phase 2 is \\(\\mathcal{O}(n\\log n)\\)\nThe total time complexity is \\(\\mathcal{O}(n\\log n)\\).\n\nFurther saving memory: in-place sorting\n\nIn-place sorting: the sorting algorithm does not require any extra memory.\nTo achieve in-place sorting, we can use the same array to store the priority queue.\nEach time, we add one more element to the sorted part of the array. All the operations are done in the same array.\nAfter phase 1, the array is sorted.\nBy doing phase 2, we can get the descending order of the array."
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#adaptable-priority-queue",
    "href": "notes/cs253/3 Priority Queues.html#adaptable-priority-queue",
    "title": "Priority Queues",
    "section": "",
    "text": "In an adaptable priority queue, we can do the following operations:\n\nremove(e): Removes entry e from the priority queue.\nreplaceKey(e, k): replaces the key of existing entry e with a new key k.\nreplaceValue(e, v): replaces the value of existing entry e with a new value v.\n\nThis data structure requires the heap to be able to locate (=knowing the index of) a given entry efficiently. However, in order to match a key, in our older heap structure, it is not efficient.\n\nTo improve, we can use a hash table to store the index of each entry.\nAnother way is directly storing the index in the entry class.\nNote: the index of each location is fixed. That is, the root will always be with index 0, the left child of the root will always be with index 1, and the right child of the root will always be with index 2. After any operation, the index of each position will not change. Hence, we need to re-write the swap method as well. \n\nThe key idea here is that we empower the user to remove, replace the key, and replace the value of any entry in the priority queue. However, to enable that, the user are required to specify the entry location, by using the index of the entry.\nThe following code implements the AdaptableHeapPriorityQueue class.\n\nimport java.util.*;\n\npublic class HeapAdaptablePriorityQueue&lt;K,V&gt; extends HeapPriorityQueue&lt;K.V&gt; {\n    // Nested AdaptablePQEntry class\n    protected static class AdaptableEntry&lt;K,V&gt; extends Entry&lt;K,V&gt; {\n        private int index;\n        public AdaptableEntry(K key, V value, int j) {\n            super(key, value);\n            index = j;\n        }\n        public int getIndex() {\n            return index;\n        }\n        public void setIndex(int j) {\n            index = j;\n        }\n    } // End of nested AdaptablePQEntry class\n\n    public HeapAdaptablePriorityQueue(Comparator&lt;K&gt; c) {\n        super(c);\n    }\n    public HeapAdaptablePriorityQueue() {\n        super();\n    }\n    protected AdaptableEntry&lt;K,V&gt; validate(AdaptableEntry&lt;K,V&gt; entry) {\n        int j = entry.getIndex();\n        if (j &gt;= heap.size() || j&gt;= 0 || heap.get(j).k != entry.k || heap.get(j).v != entry.v) {\n            // verify that the entry is in the heap\n            throw new IllegalArgumentException(\"Invalid entry\");\n        }\n        return entry;\n    }\n\n    public void bubble(int j) {\n        if (j &gt; 0 && comp.compare(heap.get(j).k, heap.get(parent(j)).k) &lt; 0) {\n            // if the current entry is smaller than its parent, we need to swim it up\n            swim(j);\n        } else {\n            // if the current entry is larger than its parent, we need to sink it down\n            sink(j);\n        }\n    }\n\n    public void replaceKey(AdaptableEntry&lt;K,V&gt; entry, K key) {\n        // Time complexity = O(log n)\n        AdaptableEntry&lt;K,V&gt; locator = validate(entry);\n        heap.get(locator.index).k = key;\n        bubble(locator.index);\n    }\n    \n    @Override\n    // We need a new swap function to update the index of the entries\n    protected void swap(int i, int j) {\n        super.swap(i, j);\n        ((AdaptableEntry&lt;K,V&gt;) heap.get(i)).setIndex(j);\n        ((AdaptableEntry&lt;K,V&gt;) heap.get(j)).setIndex(i);\n    }\n\n    public void remove(AdaptableEntry&lt;K,V&gt; entry) {\n        // Time complexity = O(log n)\n        AdaptableEntry&lt;k,V&gt; locator = validate(entry);\n        int j = locator.getIndex();\n        swap(j, heap.size() - 1);\n        heap.remove(heap.size() - 1);\n        bubble(j);\n    }\n\n    public void replaceValue(AdaptableEntry&lt;K,V&gt; entry, V value) {\n        // Time complexity = O(1)\n        AdaptableEntry&lt;K,V&gt; locator = validate(entry);\n        heap.get(locator.getIndex()).v = value;\n    }\n}"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#final-remarks-bottom-up-heap-construction",
    "href": "notes/cs253/3 Priority Queues.html#final-remarks-bottom-up-heap-construction",
    "title": "Priority Queues",
    "section": "",
    "text": "If we have \\(n\\) entries and want to use them to use insert() to build a heap, the total time complexity is \\(\\mathcal{O}(n\\log n)\\).\n\nA simple proof is that the time complexity of insert() is \\(\\mathcal{O}(\\log n)\\), and we need to do it \\(n\\) times.\n\nTo improve, we can use a bottom-up approach to build a heap.\n\nWe start from the last internal node and do the sink() operation.\nWe then move to the second last internal node and do the sink() operation.\nWe repeat until we reach the root.\nThe time complexity to complete heap construction is \\(\\mathcal{O}(n)\\).  \n\nA simple proof of the time complexity is that: the maximal number of swapping operations is bounded by the number of edges in the tree, which is bounded by the number of entries in the tree. Hence, the time complexity is \\(\\mathcal{O}(n)\\)."
  },
  {
    "objectID": "notes/cs253/9 Union-find.html",
    "href": "notes/cs253/9 Union-find.html",
    "title": "9 Union-Find",
    "section": "",
    "text": "Introduction\n\n\n\n\n\n\n\nDefinition 1 An undirected graph is connected if, for any two vertices, there is a path between them.\n\nConnected components: maximal connected subgraphs.\n\n\n\n\n\n\nDynamic Connectivity Problem\n\nGiven a set of \\(n\\) nodes (vertices), support two operations:\n\nFind: Tell if two vertices have path(s) to each other. i.e., if they are in the same component.\nUnion: if two vertices are in different components, merge them into one component.\n\n\nApplications of dynamic connectivity problem:\n\nIdentify if a pair of “nodes” are connected via a path; if not, we can make them connected.\nThe “nodes” can be:\n\nComputers in a network\nPixels in a digital image\nFriends in a social network\nTransistors in a computer chip\nElements in a mathematical set\nVariable names in a Fortran program\netc.\n\n\nIf we use graph, there are some challenges to solve the dynamic connectivity problem:\n\nThe time complexity of graph traversal is \\(O(m+n)\\), which is too slow for large graphs.\nSince the graph is changing, we need to re-traverse it every time.\n\n\n\n\nUnion-Find Data Type\n\nIn the union-find data type, we implement the following two operations:\n\nfind(p): return the component containing the node p.\nunion(p, q): merge the components containing nodes p and q.\n\nGoal: design efficient data structure for union-find.\n\nNumber of nodes (vertices) \\(n\\) can be huge.\nNumber of union and find operations \\(k\\) can be huge.\nUnion and find operations may be intermixed. Namely, we want:\n\nUsually, we first tell if p and q are from the same component by calling find(p) and find(q).\nIf they are not, we call union(p, q) to merge their components.\n\n\nA further note on the data structure is that:\n\nEach vertex records the identity of the component\nThe identity can be used to locate the component\nWhen performing “union”, update each vertex’s records of their component.\n\nThe simplest structure is to use a sequence (e.g., a list, a map) for each component.\n\nfind(p): \\(\\mathcal{O}(1)\\) \nunion(p, q): \\(\\mathcal{O}(n_\\text{small})\\), \\(n_\\text{small}\\) is the size of the smaller component.\n\nStep 1: identify two nodes from different components \nStep 2: merge the two components (move all nodes from the smaller component to the larger one) \n\n\nAmortized time complexity of “union-find”:\n\nA union-find operation union-find(p, q):\n\nfind operation: Tell if p and q are from the same component by calling find(p) and find(q).\nunion operation: If they are not in the same component, we call union(p, q) to merge their components.\n\nWhat is the time complexity for executing union-find for \\(k\\) times?\n\nTime complexity of \\(k\\) find operations: \\(\\mathcal{O}(k)\\).\nTime complexity of \\(k\\) union operations: \\(\\mathcal{O}(n\\log n)\\).\n\n\\((\\text{maximial number of ``moves'' for each vertex})\\times(\\text{number of vertices})\\)\n\\((\\text{maximial number of ``moves'' for each vertex})=\\mathcal{O}(\\log n)\\): a vertex can only be moved at most \\(\\log n\\) times, as each time a vertex move, its component’s size (at least) doubles until \\(n\\).\n\\((\\text{number of vertices})=\\mathcal{O}(n)\\).\nHence, union is \\(\\mathcal{O}(n)\\) for each operation and \\(\\mathcal{O}(n\\log n)\\) for \\(k\\) operations.\n\nHence, union is very time-consuming due to many “moves”. Can we avoid many “moves?”\n\n\nAn alternative data structure to implement union-find: tree structure: a naïve implementation \n\nWe can further simplify the tree structure by using the root to represent the component.\n\nIn this case, we use a self-loop: that is, the root points to itself. \n\nfind(p): will simply be to trace back to the root from p.\n\nAlgorithm find(p):\n    if not yet reached the root:\n        return find(parent of p);\n    else: \n        return parent of p;\nAt this time, the time complexity of union is \\(\\mathcal{O}(1)\\).\nHowever, the time complexity of find is \\(\\mathcal{O}(\\text{depth})\\).\n\nTo reduce the time complexity of find, we can reduce the \\(\\text{depth}\\) of the tree.\n\nWe will use a technique of path compression. \n\nfind(p): will be to trace back to the root from p, and let the root to be the parent of all the traversed nodes.\n\nAlgorithm find(p):\n    if not yet reached the root:\n        parent of p &lt;- find(parent of p);\n    else: \n        return parent of p;\nNow, the time complexity of find is \\(\\mathcal{O}(\\text{depth}')\\), and we know \\(\\text{depth}'\\) is much smaller than \\(\\text{depth}\\).\n\n\nTime complexity of union-find by path compression\n\nWe conduct \\(k\\) series of union-find operations in a graph with \\(n\\) vertices.\n\nEach time find if the current pair of vertices are in the same component.\nIf not, then we union them into the same component.\n\nThe amortized time complexity of \\(k\\) series of union-find operations: \\(\\mathcal{O}(k\\log^* n)\\), where \\(\\log^*n\\)= log-star \\(n\\), the inverse of the tower-of-twos function.\n\n\n\n\n\n\n\n\n\n\n\nminimum \\(n\\)\n\\(2\\)\n\\(2^2=4\\)\n\\(2^{2^2}=16\\)\n\\(2^{2^{2^2}}=65,536\\)\n\\(2^{2^{2^{2^2}}}=2^65,536\\)\n\n\n\n\n\\(\\log^*n\\)\n\\(1\\)\n\\(2\\)\n\\(3\\)\n\\(4\\)\n\\(5\\)\n\n\n\n\nThis time complexity function is very slow-growing, and we can consider it as the constant time complexity. That is, \\(\\mathcal{O}(k\\log^* n)\\sim\\mathcal{O}(1)\\).\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/9 Union-find.html#introduction",
    "href": "notes/cs253/9 Union-find.html#introduction",
    "title": "9 Union-Find",
    "section": "",
    "text": "Definition 1 An undirected graph is connected if, for any two vertices, there is a path between them.\n\nConnected components: maximal connected subgraphs.\n\n\n\n\n\n\nDynamic Connectivity Problem\n\nGiven a set of \\(n\\) nodes (vertices), support two operations:\n\nFind: Tell if two vertices have path(s) to each other. i.e., if they are in the same component.\nUnion: if two vertices are in different components, merge them into one component.\n\n\nApplications of dynamic connectivity problem:\n\nIdentify if a pair of “nodes” are connected via a path; if not, we can make them connected.\nThe “nodes” can be:\n\nComputers in a network\nPixels in a digital image\nFriends in a social network\nTransistors in a computer chip\nElements in a mathematical set\nVariable names in a Fortran program\netc.\n\n\nIf we use graph, there are some challenges to solve the dynamic connectivity problem:\n\nThe time complexity of graph traversal is \\(O(m+n)\\), which is too slow for large graphs.\nSince the graph is changing, we need to re-traverse it every time."
  },
  {
    "objectID": "notes/cs253/9 Union-find.html#union-find-data-type",
    "href": "notes/cs253/9 Union-find.html#union-find-data-type",
    "title": "9 Union-Find",
    "section": "",
    "text": "In the union-find data type, we implement the following two operations:\n\nfind(p): return the component containing the node p.\nunion(p, q): merge the components containing nodes p and q.\n\nGoal: design efficient data structure for union-find.\n\nNumber of nodes (vertices) \\(n\\) can be huge.\nNumber of union and find operations \\(k\\) can be huge.\nUnion and find operations may be intermixed. Namely, we want:\n\nUsually, we first tell if p and q are from the same component by calling find(p) and find(q).\nIf they are not, we call union(p, q) to merge their components.\n\n\nA further note on the data structure is that:\n\nEach vertex records the identity of the component\nThe identity can be used to locate the component\nWhen performing “union”, update each vertex’s records of their component.\n\nThe simplest structure is to use a sequence (e.g., a list, a map) for each component.\n\nfind(p): \\(\\mathcal{O}(1)\\) \nunion(p, q): \\(\\mathcal{O}(n_\\text{small})\\), \\(n_\\text{small}\\) is the size of the smaller component.\n\nStep 1: identify two nodes from different components \nStep 2: merge the two components (move all nodes from the smaller component to the larger one) \n\n\nAmortized time complexity of “union-find”:\n\nA union-find operation union-find(p, q):\n\nfind operation: Tell if p and q are from the same component by calling find(p) and find(q).\nunion operation: If they are not in the same component, we call union(p, q) to merge their components.\n\nWhat is the time complexity for executing union-find for \\(k\\) times?\n\nTime complexity of \\(k\\) find operations: \\(\\mathcal{O}(k)\\).\nTime complexity of \\(k\\) union operations: \\(\\mathcal{O}(n\\log n)\\).\n\n\\((\\text{maximial number of ``moves'' for each vertex})\\times(\\text{number of vertices})\\)\n\\((\\text{maximial number of ``moves'' for each vertex})=\\mathcal{O}(\\log n)\\): a vertex can only be moved at most \\(\\log n\\) times, as each time a vertex move, its component’s size (at least) doubles until \\(n\\).\n\\((\\text{number of vertices})=\\mathcal{O}(n)\\).\nHence, union is \\(\\mathcal{O}(n)\\) for each operation and \\(\\mathcal{O}(n\\log n)\\) for \\(k\\) operations.\n\nHence, union is very time-consuming due to many “moves”. Can we avoid many “moves?”\n\n\nAn alternative data structure to implement union-find: tree structure: a naïve implementation \n\nWe can further simplify the tree structure by using the root to represent the component.\n\nIn this case, we use a self-loop: that is, the root points to itself. \n\nfind(p): will simply be to trace back to the root from p.\n\nAlgorithm find(p):\n    if not yet reached the root:\n        return find(parent of p);\n    else: \n        return parent of p;\nAt this time, the time complexity of union is \\(\\mathcal{O}(1)\\).\nHowever, the time complexity of find is \\(\\mathcal{O}(\\text{depth})\\).\n\nTo reduce the time complexity of find, we can reduce the \\(\\text{depth}\\) of the tree.\n\nWe will use a technique of path compression. \n\nfind(p): will be to trace back to the root from p, and let the root to be the parent of all the traversed nodes.\n\nAlgorithm find(p):\n    if not yet reached the root:\n        parent of p &lt;- find(parent of p);\n    else: \n        return parent of p;\nNow, the time complexity of find is \\(\\mathcal{O}(\\text{depth}')\\), and we know \\(\\text{depth}'\\) is much smaller than \\(\\text{depth}\\).\n\n\nTime complexity of union-find by path compression\n\nWe conduct \\(k\\) series of union-find operations in a graph with \\(n\\) vertices.\n\nEach time find if the current pair of vertices are in the same component.\nIf not, then we union them into the same component.\n\nThe amortized time complexity of \\(k\\) series of union-find operations: \\(\\mathcal{O}(k\\log^* n)\\), where \\(\\log^*n\\)= log-star \\(n\\), the inverse of the tower-of-twos function. |minimum \\(n\\)|\\(2\\)|\\(2^2=4\\)|\\(2^{2^2}=16\\)|\\(2^{2^{2^2}}=65,536\\)|\\(2^{2^{2^{2^2}}}=2^65,536\\)| |:—:|:—:|:—:|:—:|:—:|:—:| |\\(\\log^*n\\)|\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)|\n\nThis time complexity function is very slow-growing, and we can consider it as the constant time complexity. That is, \\(\\mathcal{O}(k\\log^* n)\\sim\\mathcal{O}(1)\\)."
  },
  {
    "objectID": "notes/cs253/8 Shortest Path.html",
    "href": "notes/cs253/8 Shortest Path.html",
    "title": "8 Shortest Path",
    "section": "",
    "text": "If the graph is not connected, we can still complete the graph traversal by calling DFS() method.\n\nAlgorithm\n    Randomly select a vertex from the unvisited vertices\n    Apply DFS\n    Repeat the process untill all vertices are visited\n\n\n\n\n\n\n\n\n\nDefinition 1  \n\nIn unweighted graphs, the length of a path is defined as the number of edges in this path.\nLength of the shortest path between two vertices is known as their distance.\n\n\n\n\n\n\nBFS can find the shortest paths.\n\nBFS is a process of “iteratively visiting the unvisited neighbors closest to source.”\nBFS tree records the shortest path from the starting vertex to all other vertices.\nExample: the BFS tree is marked in the blue and solid arrows in the following graph.\n\n\n\n\n\n\n\n\nFigure 1: BFS Tree\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 2  \n\nWe will consider non-negative weight in this lecture.\nThe weight of an edge \\(e=(u,v)\\) is denoted as \\(w(u,v)\\) or \\(w(e)\\).\nIn weighted graph, the length of a path \\(P\\) is the sum of the weights of the edges in \\(P=((v_0,v_1), (v_1,v_2),\\dots,(v_{k-1},v_k))\\): \\[w(P)=\\sum_{i=0}^{k-1}w(v_i,v_{i+1}).\\]\nDistance between two vertices denotes the length of the shortest path between them.\n\n\n\n\n\n\nIn a weigthed graph, the general idea of finding the shortest path is to:\n\nStart from a source vertex, initialize all the vertices’ distances to starting vertex as infinity\nVisit the univisted closest vertex\nUpdate the distance of the neighbors\nRepeat the process until all vertices are visited\n\nClaim: Through the process above, once a vertex is visited, its currently recorded distance is already the shortest distance to the starting vertex.\n\nProof (by contradiction).\n\nAssume the above claim is false: “Suppose the currently visited vertex \\(z\\) is the first one whose recorded distance is not the shortest path length.”\n\n\nThen, one of the following situation must happens:\n\n\nSituation 1: All vertices in the path are visited vertices.\n\n\nSituation 2:Shortest path goes through some unvisited vertices.\n\n\n\n\nIf situation 1 happens, assume vertex \\(v\\) is the predecessor of \\(z\\) in the shortest path, then we should have already examined this path while visiting \\(v\\) and its neighbors and recordes this as the distance. This leads to contradiction.\n\n\nIf situation 2 happens, then let’s assume vertex \\(y\\) is the first unvisted vertex in the shortest path and vertex \\(x\\) is \\(y\\)’s predecessor in the shortest path. So, vertex \\(x\\) is already visited before visiting \\(z\\) and \\(x\\)’s neighbor \\(y\\) has smaller distance to \\(s\\) (the source vertex) than \\(z\\), so \\(y\\) should be visited earlier than \\(z\\). This also leads to contradiction.\n\n\nBecause of the contradictions, the statement cannot be false. The proof is therefore completed. \\(\\qquad\\blacksquare\\)\n\n\n\nDijkstra’s Algorithm\n\nAlgorithm MST(s):\n  INPUT: start vertex s;\n  OUTPUT: all vertices' distances to s;\n\n  START:\n  Initialize all the vertices' distances to the starting vertex as infinity\n  while there is still unvisited vertex do {\n    1. visit the unvisited closest vertex;\n    2. update this vertex’s neighbors’ distances;\n  }"
  },
  {
    "objectID": "notes/cs253/8 Shortest Path.html#beyond-connected-graphs",
    "href": "notes/cs253/8 Shortest Path.html#beyond-connected-graphs",
    "title": "Shortest Path",
    "section": "",
    "text": "If the graph is not connected, we can still complete the graph traversal by calling DFS() method.\n\nAlgorithm\n    Randomly select a vertex from the unvisited vertices\n    Apply DFS\n    Repeat the process untill all vertices are visited"
  },
  {
    "objectID": "notes/cs253/8 Shortest Path.html#bfs-to-find-shortest-path-in-unweighted-graph",
    "href": "notes/cs253/8 Shortest Path.html#bfs-to-find-shortest-path-in-unweighted-graph",
    "title": "8 Shortest Path",
    "section": "",
    "text": "Definition 1  \n\nIn unweighted graphs, the length of a path is defined as the number of edges in this path.\nLength of the shortest path between two vertices is known as their distance.\n\n\n\n\n\n\nBFS can find the shortest paths.\n\nBFS is a process of “iteratively visiting the unvisited neighbors closest to source.”\nBFS tree records the shortest path from the starting vertex to all other vertices.\nExample: the BFS tree is marked in the blue and solid arrows in the following graph.\n\n\n\n\n\n\n\n\nFigure 1: BFS Tree"
  },
  {
    "objectID": "notes/cs253/8 Shortest Path.html#shortest-path-search-in-weighted-graph",
    "href": "notes/cs253/8 Shortest Path.html#shortest-path-search-in-weighted-graph",
    "title": "8 Shortest Path",
    "section": "",
    "text": "Definition 2  \n\nWe will consider non-negative weight in this lecture.\nThe weight of an edge \\(e=(u,v)\\) is denoted as \\(w(u,v)\\) or \\(w(e)\\).\nIn weighted graph, the length of a path \\(P\\) is the sum of the weights of the edges in \\(P=((v_0,v_1), (v_1,v_2),\\dots,(v_{k-1},v_k))\\): \\[w(P)=\\sum_{i=0}^{k-1}w(v_i,v_{i+1}).\\]\nDistance between two vertices denotes the length of the shortest path between them.\n\n\n\n\n\n\nIn a weigthed graph, the general idea of finding the shortest path is to:\n\nStart from a source vertex, initialize all the vertices’ distances to starting vertex as infinity\nVisit the univisted closest vertex\nUpdate the distance of the neighbors\nRepeat the process until all vertices are visited\n\nClaim: Through the process above, once a vertex is visited, its currently recorded distance is already the shortest distance to the starting vertex.\n\nProof (by contradiction).\n\nAssume the above claim is false: “Suppose the currently visited vertex \\(z\\) is the first one whose recorded distance is not the shortest path length.”\n\n\nThen, one of the following situation must happens:\n\n\nSituation 1: All vertices in the path are visited vertices.\n\n\nSituation 2:Shortest path goes through some unvisited vertices.\n\n\n\n\nIf situation 1 happens, assume vertex \\(v\\) is the predecessor of \\(z\\) in the shortest path, then we should have already examined this path while visiting \\(v\\) and its neighbors and recordes this as the distance. This leads to contradiction.\n\n\nIf situation 2 happens, then let’s assume vertex \\(y\\) is the first unvisted vertex in the shortest path and vertex \\(x\\) is \\(y\\)’s predecessor in the shortest path. So, vertex \\(x\\) is already visited before visiting \\(z\\) and \\(x\\)’s neighbor \\(y\\) has smaller distance to \\(s\\) (the source vertex) than \\(z\\), so \\(y\\) should be visited earlier than \\(z\\). This also leads to contradiction.\n\n\nBecause of the contradictions, the statement cannot be false. The proof is therefore completed. \\(\\qquad\\blacksquare\\)\n\n\n\nDijkstra’s Algorithm\n\nAlgorithm MST(s):\n  INPUT: start vertex s;\n  OUTPUT: all vertices' distances to s;\n\n  START:\n  Initialize all the vertices' distances to the starting vertex as infinity\n  while there is still unvisited vertex do {\n    1. visit the unvisited closest vertex;\n    2. update this vertex’s neighbors’ distances;\n  }"
  },
  {
    "objectID": "notes/cs253/0-Summary-of-Data-Structures/0 Summary of Data Structures.html",
    "href": "notes/cs253/0-Summary-of-Data-Structures/0 Summary of Data Structures.html",
    "title": "0 Summary of Data Structures",
    "section": "",
    "text": "Summary of Data Structures\n\n\n\n\n\n\nFigure 1: Summary of Data Structures\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/0 Summary of Data Structures.html",
    "href": "notes/cs253/0 Summary of Data Structures.html",
    "title": "0 Summary of Data Structures",
    "section": "",
    "text": "Summary of Data Structures\n\n\n\n\n\n\nFigure 1: Summary of Data Structures\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#tree-terminology",
    "href": "notes/cs253/3 Priority Queues.html#tree-terminology",
    "title": "3 Priority Queues and Heaps",
    "section": "Tree Terminology",
    "text": "Tree Terminology\n\n\n\n\n\n\n\nDefinition 2  \n\nRoot: the node without a parent. (e.g., A)\nInternal node: a node with at least one child. (e.g., A, B, C, F)\nExternal node: a node without any children. (e.g, D, E, I, J, K, G, H)\nAncestor of a node: parent, grandparent, grand- grandparent, etc.\nDescendant of a node: child, grandchild, grand- grandchild, etc.\nDepth of a node: the number of ancestors.\nHeight of a tree: the maximum depth of any node in the tree. (e.g, 3)\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Tree Introduction\n\n\n\n\n\n\n\n\n\n\nDefinition 3 Binary Trees: Each internal node has at most two children.\n\n\n\n\n\nWe call the children of a node the left child and right child.\nDifferent types of Binary Trees:\n\nPerfect Binary Tree\n\nAll internal nodes have two children.\nAll external nodes have the same depth.\nNumber of nodes: \\(n=2^0+2^1+^2+\\cdots+2^h=2^{h+1}-1\\), where \\(h\\) is the height of the tree.\n\nComplete Binary Tree\n\nAll levels except the last are completely filled\nAll nodes in the last level are as far left as possible\nNumber of nodes: \\[\n2^0+2^1+\\cdots+2^{h-1}\\leq n\\leq2^0+2^1+\\cdots+2^h \\\\\n\\implies 2^h-1\\leq n\\leq 2^{h+1}-1 \\\\\n\\implies \\log(n+1)-2\\leq h\\leq\\log(n+1).\n\\]\n\n\n\n\n\n\n\n\n\nFigure 2: Different Binary Trees"
  },
  {
    "objectID": "notes/cs253/3 Priority Queues.html#heap",
    "href": "notes/cs253/3 Priority Queues.html#heap",
    "title": "3 Priority Queues and Heaps",
    "section": "Heap",
    "text": "Heap\n\n\n\n\n\n\n\nDefinition 4 Heap: A heap is a binary tree storing keys at its nodes and satisfying the following properties: - Heap-Order: for every node (except root), its key is larger than or equal to its parent’s key. - Must be a complete binary tree.\n\n\n\n\n\nHeaps and Priority Queues\n\nWe can use a heap to implement a priority queue.\nWe store a (key, value) item at each node.\nWe can get the entry will minimal key in \\(\\mathcal{O}(1)\\).\nWe hope removeMin() and insert() can also be fast.\n\nHeap operation: insert()/swim()\n\nPlace the new entry just beyond the rightmost node at the bottom level of the tree. Swim until it becomes a heap.\n\nIf the current layer is full, add a new layer.\nWhen adding a new layer, the new layer must be added from left to right.\nIf the current node is smaller than its parent, swap them.\n\nTime complexity: what is really time-consuming here is the swap() operation. In total, we can at most swap \\(h\\) times (the number of layers), so the time complexity should be \\(\\mathcal{O}(h)=\\mathcal{O}(\\log n)\\).\n\nHeap operation: removeMin()/sink()\n\nCut and paste the heap’s last entry to its root. Sink until it becomes a heap.\n\nPull the last entry up to the root.\nCompare the new root with its children. Swap it with the smaller child if necessary.\nRepeat until we retain the heap-order property.\n\nTime complexity: it is the sawp() operation that is time-consuming. In total, we can at most swap \\(h\\) times (the number of layers), so the time complexity should also be \\(\\mathcal{O}(h)=\\mathcal{O}(\\log n)\\).\n\n\n\n\n\n\n\n\n\n\n\nMethod\nUnosrted List\nSorted List\nHeap\n\n\n\n\nsize()\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nisEmtpy()\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\ninsert()\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(\\log n)\\)\n\n\nmin()\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(1)\\)\n\n\nremoveMin()\n\\(\\mathcal{O}(n)\\)\n\\(\\mathcal{O}(1)\\)\n\\(\\mathcal{O}(\\log n)\\)"
  },
  {
    "objectID": "notes/cs253/4 Trees and Binary Search Trees.html#why-dont-we-use-heap-or-priority-queue",
    "href": "notes/cs253/4 Trees and Binary Search Trees.html#why-dont-we-use-heap-or-priority-queue",
    "title": "4 Trees and Binary Search Trees",
    "section": "Why don’t we use heap or priority queue?",
    "text": "Why don’t we use heap or priority queue?\n- Using a heap, the function `get(k)` will be slow.\n- Using a priority queue, the function `insert(k,v)`  and `delete(k)` will be slow."
  },
  {
    "objectID": "stats.html",
    "href": "stats.html",
    "title": "Site Analytics",
    "section": "",
    "text": "Note\n\n\n\nThis is a private analytics page. The data below shows visitor behavior and site performance metrics.\n\n\n\n\n\n\nLoading analytics data…\n\n\nNote: You’ll need to set up Google Analytics and replace the placeholder code below with your actual Analytics embed code.\n\n\n\n\n\n\n\n\nGo to Google Analytics\nCreate a new property for your website\nGet your GA4 Measurement ID (starts with “G-”)\nReplace GA_MEASUREMENT_ID in the tracking code below\n\n\n\n\nIf you prefer a simpler solution, you can use services like: - Umami Analytics (privacy-focused, self-hosted) - Plausible Analytics (privacy-focused, paid) - Simple Analytics (privacy-focused, paid)\n\n\n\n\n&lt;!-- Google Analytics --&gt;\n&lt;script async src=\"https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n  gtag('config', 'GA_MEASUREMENT_ID');\n&lt;/script&gt;\n\n&lt;!-- Custom tracking for specific events --&gt;\n&lt;script&gt;\n// Track page views\ngtag('event', 'page_view', {\n  page_title: document.title,\n  page_location: window.location.href\n});\n\n// Track external link clicks\ndocument.addEventListener('click', function(e) {\n  if (e.target.tagName === 'A' && e.target.href.startsWith('http') && !e.target.href.includes(window.location.hostname)) {\n    gtag('event', 'click', {\n      event_category: 'external_link',\n      event_label: e.target.href\n    });\n  }\n});\n\n// Track time on page\nlet startTime = Date.now();\nwindow.addEventListener('beforeunload', function() {\n  let timeOnPage = Math.round((Date.now() - startTime) / 1000);\n  gtag('event', 'timing_complete', {\n    name: 'time_on_page',\n    value: timeOnPage\n  });\n});\n&lt;/script&gt;\n\n\n\nThis analytics setup: - Tracks page views and user interactions - Monitors external link clicks - Measures time spent on pages - Collects anonymous usage data - Helps improve site design and content\nAll data is collected anonymously and used solely for improving the website experience.\n\nLast updated: July 2025"
  },
  {
    "objectID": "stats.html#google-analytics-integration",
    "href": "stats.html#google-analytics-integration",
    "title": "Site Analytics",
    "section": "",
    "text": "Loading analytics data…\n\n\nNote: You’ll need to set up Google Analytics and replace the placeholder code below with your actual Analytics embed code."
  },
  {
    "objectID": "stats.html#quick-setup-instructions",
    "href": "stats.html#quick-setup-instructions",
    "title": "Site Analytics",
    "section": "",
    "text": "Go to Google Analytics\nCreate a new property for your website\nGet your GA4 Measurement ID (starts with “G-”)\nReplace GA_MEASUREMENT_ID in the tracking code below\n\n\n\n\nIf you prefer a simpler solution, you can use services like: - Umami Analytics (privacy-focused, self-hosted) - Plausible Analytics (privacy-focused, paid) - Simple Analytics (privacy-focused, paid)"
  },
  {
    "objectID": "stats.html#custom-analytics-code",
    "href": "stats.html#custom-analytics-code",
    "title": "Site Analytics",
    "section": "",
    "text": "&lt;!-- Google Analytics --&gt;\n&lt;script async src=\"https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n  gtag('config', 'GA_MEASUREMENT_ID');\n&lt;/script&gt;\n\n&lt;!-- Custom tracking for specific events --&gt;\n&lt;script&gt;\n// Track page views\ngtag('event', 'page_view', {\n  page_title: document.title,\n  page_location: window.location.href\n});\n\n// Track external link clicks\ndocument.addEventListener('click', function(e) {\n  if (e.target.tagName === 'A' && e.target.href.startsWith('http') && !e.target.href.includes(window.location.hostname)) {\n    gtag('event', 'click', {\n      event_category: 'external_link',\n      event_label: e.target.href\n    });\n  }\n});\n\n// Track time on page\nlet startTime = Date.now();\nwindow.addEventListener('beforeunload', function() {\n  let timeOnPage = Math.round((Date.now() - startTime) / 1000);\n  gtag('event', 'timing_complete', {\n    name: 'time_on_page',\n    value: timeOnPage\n  });\n});\n&lt;/script&gt;"
  },
  {
    "objectID": "stats.html#privacy-notice",
    "href": "stats.html#privacy-notice",
    "title": "Site Analytics",
    "section": "",
    "text": "This analytics setup: - Tracks page views and user interactions - Monitors external link clicks - Measures time spent on pages - Collects anonymous usage data - Helps improve site design and content\nAll data is collected anonymously and used solely for improving the website experience.\n\nLast updated: July 2025"
  }
]